{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0.dev20181207\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['projects',\n",
       " 'envML',\n",
       " 'data',\n",
       " 'Flowers_pytorch_sgd_no_bias.ipynb',\n",
       " 'Flowers_pytorch_sgd2.ipynb',\n",
       " 'Flowers_pytorch_sgd_topScore.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'Untitled.ipynb']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t    Flowers_pytorch_sgd_no_bias.ipynb\tUntitled.ipynb\r\n",
      "envML\t\t\t    Flowers_pytorch_sgd_topScore.ipynb\r\n",
      "Flowers_pytorch_sgd2.ipynb  projects\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/flower_data/'\n",
    "PATH = data_dir\n",
    "\n",
    "train_dir = 'train'\n",
    "val_dir = 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Total Count:  102\n"
     ]
    }
   ],
   "source": [
    "# again, list total number of classes, and list them all\n",
    "# os.list dir sorting depends on OS dependent file indexing, so leaving it as it is\n",
    "\n",
    "classes = os.listdir(f'{data_dir}/{train_dir}')\n",
    "classes.sort()\n",
    "ClassesNumer = len(classes)\n",
    "print(\"Class Total Count: \", ClassesNumer)\n",
    "#print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    train_dir: transforms.Compose([\n",
    "        #transforms.Resize(224),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        #transforms.RandomRotation(degrees=90),\n",
    "        #transforms.RandomRotation(degrees=45),\n",
    "        transforms.ToTensor(),\n",
    "       # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]),\n",
    "    val_dir: transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "       # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),data_transforms[x]) for x in [train_dir, val_dir]}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=8) for x in [train_dir, val_dir]}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [train_dir, val_dir]}\n",
    "\n",
    "class_names = image_datasets[train_dir].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <torch.utils.data.dataloader.DataLoader object at 0x7f1a9ed73c50>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f1a93941e10>}\n",
      "{'train': 6551, 'valid': 818}\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(dataloaders)\n",
    "print(dataset_sizes)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 6551\n",
      "    Root Location: data/flower_data/train\n",
      "    Transforms (if any): Compose(\n",
      "                             RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
      "                             RandomHorizontalFlip(p=0.5)\n",
      "                             RandomVerticalFlip(p=0.5)\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "print(image_datasets[train_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('lr{}, Epoch {}/{}'.format(scheduler.get_lr(),epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [train_dir, val_dir]:\n",
    "            if phase == train_dir:\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == train_dir):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == train_dir:\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == val_dir and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and reset final fully connected layer\n",
    "\n",
    "model_ft = models.densenet201(pretrained='imagenet')\n",
    "#num_ftrs = model_ft.classifier.in_features\n",
    "#model_ft.classifier = nn.Linear(num_ftrs, ClassesNumer)\n",
    "model_ft.fc = nn.Linear( model_ft.classifier.out_features, ClassesNumer )\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer_ft = optim.Adam(model_ft.parameters(),lr=0.0005,amsgrad=True)\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.95)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every ? epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv0.weight True\n",
      "norm0.weight True\n",
      "norm0.bias True\n",
      "denseblock1.denselayer1.norm1.weight True\n",
      "denseblock1.denselayer1.norm1.bias True\n",
      "denseblock1.denselayer1.conv1.weight True\n",
      "denseblock1.denselayer1.norm2.weight True\n",
      "denseblock1.denselayer1.norm2.bias True\n",
      "denseblock1.denselayer1.conv2.weight True\n",
      "denseblock1.denselayer2.norm1.weight True\n",
      "denseblock1.denselayer2.norm1.bias True\n",
      "denseblock1.denselayer2.conv1.weight True\n",
      "denseblock1.denselayer2.norm2.weight True\n",
      "denseblock1.denselayer2.norm2.bias True\n",
      "denseblock1.denselayer2.conv2.weight True\n",
      "denseblock1.denselayer3.norm1.weight True\n",
      "denseblock1.denselayer3.norm1.bias True\n",
      "denseblock1.denselayer3.conv1.weight True\n",
      "denseblock1.denselayer3.norm2.weight True\n",
      "denseblock1.denselayer3.norm2.bias True\n",
      "denseblock1.denselayer3.conv2.weight True\n",
      "denseblock1.denselayer4.norm1.weight True\n",
      "denseblock1.denselayer4.norm1.bias True\n",
      "denseblock1.denselayer4.conv1.weight True\n",
      "denseblock1.denselayer4.norm2.weight True\n",
      "denseblock1.denselayer4.norm2.bias True\n",
      "denseblock1.denselayer4.conv2.weight True\n",
      "denseblock1.denselayer5.norm1.weight True\n",
      "denseblock1.denselayer5.norm1.bias True\n",
      "denseblock1.denselayer5.conv1.weight True\n",
      "denseblock1.denselayer5.norm2.weight True\n",
      "denseblock1.denselayer5.norm2.bias True\n",
      "denseblock1.denselayer5.conv2.weight True\n",
      "denseblock1.denselayer6.norm1.weight True\n",
      "denseblock1.denselayer6.norm1.bias True\n",
      "denseblock1.denselayer6.conv1.weight True\n",
      "denseblock1.denselayer6.norm2.weight True\n",
      "denseblock1.denselayer6.norm2.bias True\n",
      "denseblock1.denselayer6.conv2.weight True\n",
      "transition1.norm.weight True\n",
      "transition1.norm.bias True\n",
      "transition1.conv.weight True\n",
      "denseblock2.denselayer1.norm1.weight True\n",
      "denseblock2.denselayer1.norm1.bias True\n",
      "denseblock2.denselayer1.conv1.weight True\n",
      "denseblock2.denselayer1.norm2.weight True\n",
      "denseblock2.denselayer1.norm2.bias True\n",
      "denseblock2.denselayer1.conv2.weight True\n",
      "denseblock2.denselayer2.norm1.weight True\n",
      "denseblock2.denselayer2.norm1.bias True\n",
      "denseblock2.denselayer2.conv1.weight True\n",
      "denseblock2.denselayer2.norm2.weight True\n",
      "denseblock2.denselayer2.norm2.bias True\n",
      "denseblock2.denselayer2.conv2.weight True\n",
      "denseblock2.denselayer3.norm1.weight True\n",
      "denseblock2.denselayer3.norm1.bias True\n",
      "denseblock2.denselayer3.conv1.weight True\n",
      "denseblock2.denselayer3.norm2.weight True\n",
      "denseblock2.denselayer3.norm2.bias True\n",
      "denseblock2.denselayer3.conv2.weight True\n",
      "denseblock2.denselayer4.norm1.weight True\n",
      "denseblock2.denselayer4.norm1.bias True\n",
      "denseblock2.denselayer4.conv1.weight True\n",
      "denseblock2.denselayer4.norm2.weight True\n",
      "denseblock2.denselayer4.norm2.bias True\n",
      "denseblock2.denselayer4.conv2.weight True\n",
      "denseblock2.denselayer5.norm1.weight True\n",
      "denseblock2.denselayer5.norm1.bias True\n",
      "denseblock2.denselayer5.conv1.weight True\n",
      "denseblock2.denselayer5.norm2.weight True\n",
      "denseblock2.denselayer5.norm2.bias True\n",
      "denseblock2.denselayer5.conv2.weight True\n",
      "denseblock2.denselayer6.norm1.weight True\n",
      "denseblock2.denselayer6.norm1.bias True\n",
      "denseblock2.denselayer6.conv1.weight True\n",
      "denseblock2.denselayer6.norm2.weight True\n",
      "denseblock2.denselayer6.norm2.bias True\n",
      "denseblock2.denselayer6.conv2.weight True\n",
      "denseblock2.denselayer7.norm1.weight True\n",
      "denseblock2.denselayer7.norm1.bias True\n",
      "denseblock2.denselayer7.conv1.weight True\n",
      "denseblock2.denselayer7.norm2.weight True\n",
      "denseblock2.denselayer7.norm2.bias True\n",
      "denseblock2.denselayer7.conv2.weight True\n",
      "denseblock2.denselayer8.norm1.weight True\n",
      "denseblock2.denselayer8.norm1.bias True\n",
      "denseblock2.denselayer8.conv1.weight True\n",
      "denseblock2.denselayer8.norm2.weight True\n",
      "denseblock2.denselayer8.norm2.bias True\n",
      "denseblock2.denselayer8.conv2.weight True\n",
      "denseblock2.denselayer9.norm1.weight True\n",
      "denseblock2.denselayer9.norm1.bias True\n",
      "denseblock2.denselayer9.conv1.weight True\n",
      "denseblock2.denselayer9.norm2.weight True\n",
      "denseblock2.denselayer9.norm2.bias True\n",
      "denseblock2.denselayer9.conv2.weight True\n",
      "denseblock2.denselayer10.norm1.weight True\n",
      "denseblock2.denselayer10.norm1.bias True\n",
      "denseblock2.denselayer10.conv1.weight True\n",
      "denseblock2.denselayer10.norm2.weight True\n",
      "denseblock2.denselayer10.norm2.bias True\n",
      "denseblock2.denselayer10.conv2.weight True\n",
      "denseblock2.denselayer11.norm1.weight True\n",
      "denseblock2.denselayer11.norm1.bias True\n",
      "denseblock2.denselayer11.conv1.weight True\n",
      "denseblock2.denselayer11.norm2.weight True\n",
      "denseblock2.denselayer11.norm2.bias True\n",
      "denseblock2.denselayer11.conv2.weight True\n",
      "denseblock2.denselayer12.norm1.weight True\n",
      "denseblock2.denselayer12.norm1.bias True\n",
      "denseblock2.denselayer12.conv1.weight True\n",
      "denseblock2.denselayer12.norm2.weight True\n",
      "denseblock2.denselayer12.norm2.bias True\n",
      "denseblock2.denselayer12.conv2.weight True\n",
      "transition2.norm.weight True\n",
      "transition2.norm.bias True\n",
      "transition2.conv.weight True\n",
      "denseblock3.denselayer1.norm1.weight True\n",
      "denseblock3.denselayer1.norm1.bias True\n",
      "denseblock3.denselayer1.conv1.weight True\n",
      "denseblock3.denselayer1.norm2.weight True\n",
      "denseblock3.denselayer1.norm2.bias True\n",
      "denseblock3.denselayer1.conv2.weight True\n",
      "denseblock3.denselayer2.norm1.weight True\n",
      "denseblock3.denselayer2.norm1.bias True\n",
      "denseblock3.denselayer2.conv1.weight True\n",
      "denseblock3.denselayer2.norm2.weight True\n",
      "denseblock3.denselayer2.norm2.bias True\n",
      "denseblock3.denselayer2.conv2.weight True\n",
      "denseblock3.denselayer3.norm1.weight True\n",
      "denseblock3.denselayer3.norm1.bias True\n",
      "denseblock3.denselayer3.conv1.weight True\n",
      "denseblock3.denselayer3.norm2.weight True\n",
      "denseblock3.denselayer3.norm2.bias True\n",
      "denseblock3.denselayer3.conv2.weight True\n",
      "denseblock3.denselayer4.norm1.weight True\n",
      "denseblock3.denselayer4.norm1.bias True\n",
      "denseblock3.denselayer4.conv1.weight True\n",
      "denseblock3.denselayer4.norm2.weight True\n",
      "denseblock3.denselayer4.norm2.bias True\n",
      "denseblock3.denselayer4.conv2.weight True\n",
      "denseblock3.denselayer5.norm1.weight True\n",
      "denseblock3.denselayer5.norm1.bias True\n",
      "denseblock3.denselayer5.conv1.weight True\n",
      "denseblock3.denselayer5.norm2.weight True\n",
      "denseblock3.denselayer5.norm2.bias True\n",
      "denseblock3.denselayer5.conv2.weight True\n",
      "denseblock3.denselayer6.norm1.weight True\n",
      "denseblock3.denselayer6.norm1.bias True\n",
      "denseblock3.denselayer6.conv1.weight True\n",
      "denseblock3.denselayer6.norm2.weight True\n",
      "denseblock3.denselayer6.norm2.bias True\n",
      "denseblock3.denselayer6.conv2.weight True\n",
      "denseblock3.denselayer7.norm1.weight True\n",
      "denseblock3.denselayer7.norm1.bias True\n",
      "denseblock3.denselayer7.conv1.weight True\n",
      "denseblock3.denselayer7.norm2.weight True\n",
      "denseblock3.denselayer7.norm2.bias True\n",
      "denseblock3.denselayer7.conv2.weight True\n",
      "denseblock3.denselayer8.norm1.weight True\n",
      "denseblock3.denselayer8.norm1.bias True\n",
      "denseblock3.denselayer8.conv1.weight True\n",
      "denseblock3.denselayer8.norm2.weight True\n",
      "denseblock3.denselayer8.norm2.bias True\n",
      "denseblock3.denselayer8.conv2.weight True\n",
      "denseblock3.denselayer9.norm1.weight True\n",
      "denseblock3.denselayer9.norm1.bias True\n",
      "denseblock3.denselayer9.conv1.weight True\n",
      "denseblock3.denselayer9.norm2.weight True\n",
      "denseblock3.denselayer9.norm2.bias True\n",
      "denseblock3.denselayer9.conv2.weight True\n",
      "denseblock3.denselayer10.norm1.weight True\n",
      "denseblock3.denselayer10.norm1.bias True\n",
      "denseblock3.denselayer10.conv1.weight True\n",
      "denseblock3.denselayer10.norm2.weight True\n",
      "denseblock3.denselayer10.norm2.bias True\n",
      "denseblock3.denselayer10.conv2.weight True\n",
      "denseblock3.denselayer11.norm1.weight True\n",
      "denseblock3.denselayer11.norm1.bias True\n",
      "denseblock3.denselayer11.conv1.weight True\n",
      "denseblock3.denselayer11.norm2.weight True\n",
      "denseblock3.denselayer11.norm2.bias True\n",
      "denseblock3.denselayer11.conv2.weight True\n",
      "denseblock3.denselayer12.norm1.weight True\n",
      "denseblock3.denselayer12.norm1.bias True\n",
      "denseblock3.denselayer12.conv1.weight True\n",
      "denseblock3.denselayer12.norm2.weight True\n",
      "denseblock3.denselayer12.norm2.bias True\n",
      "denseblock3.denselayer12.conv2.weight True\n",
      "denseblock3.denselayer13.norm1.weight True\n",
      "denseblock3.denselayer13.norm1.bias True\n",
      "denseblock3.denselayer13.conv1.weight True\n",
      "denseblock3.denselayer13.norm2.weight True\n",
      "denseblock3.denselayer13.norm2.bias True\n",
      "denseblock3.denselayer13.conv2.weight True\n",
      "denseblock3.denselayer14.norm1.weight True\n",
      "denseblock3.denselayer14.norm1.bias True\n",
      "denseblock3.denselayer14.conv1.weight True\n",
      "denseblock3.denselayer14.norm2.weight True\n",
      "denseblock3.denselayer14.norm2.bias True\n",
      "denseblock3.denselayer14.conv2.weight True\n",
      "denseblock3.denselayer15.norm1.weight True\n",
      "denseblock3.denselayer15.norm1.bias True\n",
      "denseblock3.denselayer15.conv1.weight True\n",
      "denseblock3.denselayer15.norm2.weight True\n",
      "denseblock3.denselayer15.norm2.bias True\n",
      "denseblock3.denselayer15.conv2.weight True\n",
      "denseblock3.denselayer16.norm1.weight True\n",
      "denseblock3.denselayer16.norm1.bias True\n",
      "denseblock3.denselayer16.conv1.weight True\n",
      "denseblock3.denselayer16.norm2.weight True\n",
      "denseblock3.denselayer16.norm2.bias True\n",
      "denseblock3.denselayer16.conv2.weight True\n",
      "denseblock3.denselayer17.norm1.weight True\n",
      "denseblock3.denselayer17.norm1.bias True\n",
      "denseblock3.denselayer17.conv1.weight True\n",
      "denseblock3.denselayer17.norm2.weight True\n",
      "denseblock3.denselayer17.norm2.bias True\n",
      "denseblock3.denselayer17.conv2.weight True\n",
      "denseblock3.denselayer18.norm1.weight True\n",
      "denseblock3.denselayer18.norm1.bias True\n",
      "denseblock3.denselayer18.conv1.weight True\n",
      "denseblock3.denselayer18.norm2.weight True\n",
      "denseblock3.denselayer18.norm2.bias True\n",
      "denseblock3.denselayer18.conv2.weight True\n",
      "denseblock3.denselayer19.norm1.weight True\n",
      "denseblock3.denselayer19.norm1.bias True\n",
      "denseblock3.denselayer19.conv1.weight True\n",
      "denseblock3.denselayer19.norm2.weight True\n",
      "denseblock3.denselayer19.norm2.bias True\n",
      "denseblock3.denselayer19.conv2.weight True\n",
      "denseblock3.denselayer20.norm1.weight True\n",
      "denseblock3.denselayer20.norm1.bias True\n",
      "denseblock3.denselayer20.conv1.weight True\n",
      "denseblock3.denselayer20.norm2.weight True\n",
      "denseblock3.denselayer20.norm2.bias True\n",
      "denseblock3.denselayer20.conv2.weight True\n",
      "denseblock3.denselayer21.norm1.weight True\n",
      "denseblock3.denselayer21.norm1.bias True\n",
      "denseblock3.denselayer21.conv1.weight True\n",
      "denseblock3.denselayer21.norm2.weight True\n",
      "denseblock3.denselayer21.norm2.bias True\n",
      "denseblock3.denselayer21.conv2.weight True\n",
      "denseblock3.denselayer22.norm1.weight True\n",
      "denseblock3.denselayer22.norm1.bias True\n",
      "denseblock3.denselayer22.conv1.weight True\n",
      "denseblock3.denselayer22.norm2.weight True\n",
      "denseblock3.denselayer22.norm2.bias True\n",
      "denseblock3.denselayer22.conv2.weight True\n",
      "denseblock3.denselayer23.norm1.weight True\n",
      "denseblock3.denselayer23.norm1.bias True\n",
      "denseblock3.denselayer23.conv1.weight True\n",
      "denseblock3.denselayer23.norm2.weight True\n",
      "denseblock3.denselayer23.norm2.bias True\n",
      "denseblock3.denselayer23.conv2.weight True\n",
      "denseblock3.denselayer24.norm1.weight True\n",
      "denseblock3.denselayer24.norm1.bias True\n",
      "denseblock3.denselayer24.conv1.weight True\n",
      "denseblock3.denselayer24.norm2.weight True\n",
      "denseblock3.denselayer24.norm2.bias True\n",
      "denseblock3.denselayer24.conv2.weight True\n",
      "denseblock3.denselayer25.norm1.weight True\n",
      "denseblock3.denselayer25.norm1.bias True\n",
      "denseblock3.denselayer25.conv1.weight True\n",
      "denseblock3.denselayer25.norm2.weight True\n",
      "denseblock3.denselayer25.norm2.bias True\n",
      "denseblock3.denselayer25.conv2.weight True\n",
      "denseblock3.denselayer26.norm1.weight True\n",
      "denseblock3.denselayer26.norm1.bias True\n",
      "denseblock3.denselayer26.conv1.weight True\n",
      "denseblock3.denselayer26.norm2.weight True\n",
      "denseblock3.denselayer26.norm2.bias True\n",
      "denseblock3.denselayer26.conv2.weight True\n",
      "denseblock3.denselayer27.norm1.weight True\n",
      "denseblock3.denselayer27.norm1.bias True\n",
      "denseblock3.denselayer27.conv1.weight True\n",
      "denseblock3.denselayer27.norm2.weight True\n",
      "denseblock3.denselayer27.norm2.bias True\n",
      "denseblock3.denselayer27.conv2.weight True\n",
      "denseblock3.denselayer28.norm1.weight True\n",
      "denseblock3.denselayer28.norm1.bias True\n",
      "denseblock3.denselayer28.conv1.weight True\n",
      "denseblock3.denselayer28.norm2.weight True\n",
      "denseblock3.denselayer28.norm2.bias True\n",
      "denseblock3.denselayer28.conv2.weight True\n",
      "denseblock3.denselayer29.norm1.weight True\n",
      "denseblock3.denselayer29.norm1.bias True\n",
      "denseblock3.denselayer29.conv1.weight True\n",
      "denseblock3.denselayer29.norm2.weight True\n",
      "denseblock3.denselayer29.norm2.bias True\n",
      "denseblock3.denselayer29.conv2.weight True\n",
      "denseblock3.denselayer30.norm1.weight True\n",
      "denseblock3.denselayer30.norm1.bias True\n",
      "denseblock3.denselayer30.conv1.weight True\n",
      "denseblock3.denselayer30.norm2.weight True\n",
      "denseblock3.denselayer30.norm2.bias True\n",
      "denseblock3.denselayer30.conv2.weight True\n",
      "denseblock3.denselayer31.norm1.weight True\n",
      "denseblock3.denselayer31.norm1.bias True\n",
      "denseblock3.denselayer31.conv1.weight True\n",
      "denseblock3.denselayer31.norm2.weight True\n",
      "denseblock3.denselayer31.norm2.bias True\n",
      "denseblock3.denselayer31.conv2.weight True\n",
      "denseblock3.denselayer32.norm1.weight True\n",
      "denseblock3.denselayer32.norm1.bias True\n",
      "denseblock3.denselayer32.conv1.weight True\n",
      "denseblock3.denselayer32.norm2.weight True\n",
      "denseblock3.denselayer32.norm2.bias True\n",
      "denseblock3.denselayer32.conv2.weight True\n",
      "denseblock3.denselayer33.norm1.weight True\n",
      "denseblock3.denselayer33.norm1.bias True\n",
      "denseblock3.denselayer33.conv1.weight True\n",
      "denseblock3.denselayer33.norm2.weight True\n",
      "denseblock3.denselayer33.norm2.bias True\n",
      "denseblock3.denselayer33.conv2.weight True\n",
      "denseblock3.denselayer34.norm1.weight True\n",
      "denseblock3.denselayer34.norm1.bias True\n",
      "denseblock3.denselayer34.conv1.weight True\n",
      "denseblock3.denselayer34.norm2.weight True\n",
      "denseblock3.denselayer34.norm2.bias True\n",
      "denseblock3.denselayer34.conv2.weight True\n",
      "denseblock3.denselayer35.norm1.weight True\n",
      "denseblock3.denselayer35.norm1.bias True\n",
      "denseblock3.denselayer35.conv1.weight True\n",
      "denseblock3.denselayer35.norm2.weight True\n",
      "denseblock3.denselayer35.norm2.bias True\n",
      "denseblock3.denselayer35.conv2.weight True\n",
      "denseblock3.denselayer36.norm1.weight True\n",
      "denseblock3.denselayer36.norm1.bias True\n",
      "denseblock3.denselayer36.conv1.weight True\n",
      "denseblock3.denselayer36.norm2.weight True\n",
      "denseblock3.denselayer36.norm2.bias True\n",
      "denseblock3.denselayer36.conv2.weight True\n",
      "denseblock3.denselayer37.norm1.weight True\n",
      "denseblock3.denselayer37.norm1.bias True\n",
      "denseblock3.denselayer37.conv1.weight True\n",
      "denseblock3.denselayer37.norm2.weight True\n",
      "denseblock3.denselayer37.norm2.bias True\n",
      "denseblock3.denselayer37.conv2.weight True\n",
      "denseblock3.denselayer38.norm1.weight True\n",
      "denseblock3.denselayer38.norm1.bias True\n",
      "denseblock3.denselayer38.conv1.weight True\n",
      "denseblock3.denselayer38.norm2.weight True\n",
      "denseblock3.denselayer38.norm2.bias True\n",
      "denseblock3.denselayer38.conv2.weight True\n",
      "denseblock3.denselayer39.norm1.weight True\n",
      "denseblock3.denselayer39.norm1.bias True\n",
      "denseblock3.denselayer39.conv1.weight True\n",
      "denseblock3.denselayer39.norm2.weight True\n",
      "denseblock3.denselayer39.norm2.bias True\n",
      "denseblock3.denselayer39.conv2.weight True\n",
      "denseblock3.denselayer40.norm1.weight True\n",
      "denseblock3.denselayer40.norm1.bias True\n",
      "denseblock3.denselayer40.conv1.weight True\n",
      "denseblock3.denselayer40.norm2.weight True\n",
      "denseblock3.denselayer40.norm2.bias True\n",
      "denseblock3.denselayer40.conv2.weight True\n",
      "denseblock3.denselayer41.norm1.weight True\n",
      "denseblock3.denselayer41.norm1.bias True\n",
      "denseblock3.denselayer41.conv1.weight True\n",
      "denseblock3.denselayer41.norm2.weight True\n",
      "denseblock3.denselayer41.norm2.bias True\n",
      "denseblock3.denselayer41.conv2.weight True\n",
      "denseblock3.denselayer42.norm1.weight True\n",
      "denseblock3.denselayer42.norm1.bias True\n",
      "denseblock3.denselayer42.conv1.weight True\n",
      "denseblock3.denselayer42.norm2.weight True\n",
      "denseblock3.denselayer42.norm2.bias True\n",
      "denseblock3.denselayer42.conv2.weight True\n",
      "denseblock3.denselayer43.norm1.weight True\n",
      "denseblock3.denselayer43.norm1.bias True\n",
      "denseblock3.denselayer43.conv1.weight True\n",
      "denseblock3.denselayer43.norm2.weight True\n",
      "denseblock3.denselayer43.norm2.bias True\n",
      "denseblock3.denselayer43.conv2.weight True\n",
      "denseblock3.denselayer44.norm1.weight True\n",
      "denseblock3.denselayer44.norm1.bias True\n",
      "denseblock3.denselayer44.conv1.weight True\n",
      "denseblock3.denselayer44.norm2.weight True\n",
      "denseblock3.denselayer44.norm2.bias True\n",
      "denseblock3.denselayer44.conv2.weight True\n",
      "denseblock3.denselayer45.norm1.weight True\n",
      "denseblock3.denselayer45.norm1.bias True\n",
      "denseblock3.denselayer45.conv1.weight True\n",
      "denseblock3.denselayer45.norm2.weight True\n",
      "denseblock3.denselayer45.norm2.bias True\n",
      "denseblock3.denselayer45.conv2.weight True\n",
      "denseblock3.denselayer46.norm1.weight True\n",
      "denseblock3.denselayer46.norm1.bias True\n",
      "denseblock3.denselayer46.conv1.weight True\n",
      "denseblock3.denselayer46.norm2.weight True\n",
      "denseblock3.denselayer46.norm2.bias True\n",
      "denseblock3.denselayer46.conv2.weight True\n",
      "denseblock3.denselayer47.norm1.weight True\n",
      "denseblock3.denselayer47.norm1.bias True\n",
      "denseblock3.denselayer47.conv1.weight True\n",
      "denseblock3.denselayer47.norm2.weight True\n",
      "denseblock3.denselayer47.norm2.bias True\n",
      "denseblock3.denselayer47.conv2.weight True\n",
      "denseblock3.denselayer48.norm1.weight True\n",
      "denseblock3.denselayer48.norm1.bias True\n",
      "denseblock3.denselayer48.conv1.weight True\n",
      "denseblock3.denselayer48.norm2.weight True\n",
      "denseblock3.denselayer48.norm2.bias True\n",
      "denseblock3.denselayer48.conv2.weight True\n",
      "transition3.norm.weight True\n",
      "transition3.norm.bias True\n",
      "transition3.conv.weight True\n",
      "denseblock4.denselayer1.norm1.weight True\n",
      "denseblock4.denselayer1.norm1.bias True\n",
      "denseblock4.denselayer1.conv1.weight True\n",
      "denseblock4.denselayer1.norm2.weight True\n",
      "denseblock4.denselayer1.norm2.bias True\n",
      "denseblock4.denselayer1.conv2.weight True\n",
      "denseblock4.denselayer2.norm1.weight True\n",
      "denseblock4.denselayer2.norm1.bias True\n",
      "denseblock4.denselayer2.conv1.weight True\n",
      "denseblock4.denselayer2.norm2.weight True\n",
      "denseblock4.denselayer2.norm2.bias True\n",
      "denseblock4.denselayer2.conv2.weight True\n",
      "denseblock4.denselayer3.norm1.weight True\n",
      "denseblock4.denselayer3.norm1.bias True\n",
      "denseblock4.denselayer3.conv1.weight True\n",
      "denseblock4.denselayer3.norm2.weight True\n",
      "denseblock4.denselayer3.norm2.bias True\n",
      "denseblock4.denselayer3.conv2.weight True\n",
      "denseblock4.denselayer4.norm1.weight True\n",
      "denseblock4.denselayer4.norm1.bias True\n",
      "denseblock4.denselayer4.conv1.weight True\n",
      "denseblock4.denselayer4.norm2.weight True\n",
      "denseblock4.denselayer4.norm2.bias True\n",
      "denseblock4.denselayer4.conv2.weight True\n",
      "denseblock4.denselayer5.norm1.weight True\n",
      "denseblock4.denselayer5.norm1.bias True\n",
      "denseblock4.denselayer5.conv1.weight True\n",
      "denseblock4.denselayer5.norm2.weight True\n",
      "denseblock4.denselayer5.norm2.bias True\n",
      "denseblock4.denselayer5.conv2.weight True\n",
      "denseblock4.denselayer6.norm1.weight True\n",
      "denseblock4.denselayer6.norm1.bias True\n",
      "denseblock4.denselayer6.conv1.weight True\n",
      "denseblock4.denselayer6.norm2.weight True\n",
      "denseblock4.denselayer6.norm2.bias True\n",
      "denseblock4.denselayer6.conv2.weight True\n",
      "denseblock4.denselayer7.norm1.weight True\n",
      "denseblock4.denselayer7.norm1.bias True\n",
      "denseblock4.denselayer7.conv1.weight True\n",
      "denseblock4.denselayer7.norm2.weight True\n",
      "denseblock4.denselayer7.norm2.bias True\n",
      "denseblock4.denselayer7.conv2.weight True\n",
      "denseblock4.denselayer8.norm1.weight True\n",
      "denseblock4.denselayer8.norm1.bias True\n",
      "denseblock4.denselayer8.conv1.weight True\n",
      "denseblock4.denselayer8.norm2.weight True\n",
      "denseblock4.denselayer8.norm2.bias True\n",
      "denseblock4.denselayer8.conv2.weight True\n",
      "denseblock4.denselayer9.norm1.weight True\n",
      "denseblock4.denselayer9.norm1.bias True\n",
      "denseblock4.denselayer9.conv1.weight True\n",
      "denseblock4.denselayer9.norm2.weight True\n",
      "denseblock4.denselayer9.norm2.bias True\n",
      "denseblock4.denselayer9.conv2.weight True\n",
      "denseblock4.denselayer10.norm1.weight True\n",
      "denseblock4.denselayer10.norm1.bias True\n",
      "denseblock4.denselayer10.conv1.weight True\n",
      "denseblock4.denselayer10.norm2.weight True\n",
      "denseblock4.denselayer10.norm2.bias True\n",
      "denseblock4.denselayer10.conv2.weight True\n",
      "denseblock4.denselayer11.norm1.weight True\n",
      "denseblock4.denselayer11.norm1.bias True\n",
      "denseblock4.denselayer11.conv1.weight True\n",
      "denseblock4.denselayer11.norm2.weight True\n",
      "denseblock4.denselayer11.norm2.bias True\n",
      "denseblock4.denselayer11.conv2.weight True\n",
      "denseblock4.denselayer12.norm1.weight True\n",
      "denseblock4.denselayer12.norm1.bias True\n",
      "denseblock4.denselayer12.conv1.weight True\n",
      "denseblock4.denselayer12.norm2.weight True\n",
      "denseblock4.denselayer12.norm2.bias True\n",
      "denseblock4.denselayer12.conv2.weight True\n",
      "denseblock4.denselayer13.norm1.weight True\n",
      "denseblock4.denselayer13.norm1.bias True\n",
      "denseblock4.denselayer13.conv1.weight True\n",
      "denseblock4.denselayer13.norm2.weight True\n",
      "denseblock4.denselayer13.norm2.bias True\n",
      "denseblock4.denselayer13.conv2.weight True\n",
      "denseblock4.denselayer14.norm1.weight True\n",
      "denseblock4.denselayer14.norm1.bias True\n",
      "denseblock4.denselayer14.conv1.weight True\n",
      "denseblock4.denselayer14.norm2.weight True\n",
      "denseblock4.denselayer14.norm2.bias True\n",
      "denseblock4.denselayer14.conv2.weight True\n",
      "denseblock4.denselayer15.norm1.weight True\n",
      "denseblock4.denselayer15.norm1.bias True\n",
      "denseblock4.denselayer15.conv1.weight True\n",
      "denseblock4.denselayer15.norm2.weight True\n",
      "denseblock4.denselayer15.norm2.bias True\n",
      "denseblock4.denselayer15.conv2.weight True\n",
      "denseblock4.denselayer16.norm1.weight True\n",
      "denseblock4.denselayer16.norm1.bias True\n",
      "denseblock4.denselayer16.conv1.weight True\n",
      "denseblock4.denselayer16.norm2.weight True\n",
      "denseblock4.denselayer16.norm2.bias True\n",
      "denseblock4.denselayer16.conv2.weight True\n",
      "denseblock4.denselayer17.norm1.weight True\n",
      "denseblock4.denselayer17.norm1.bias True\n",
      "denseblock4.denselayer17.conv1.weight True\n",
      "denseblock4.denselayer17.norm2.weight True\n",
      "denseblock4.denselayer17.norm2.bias True\n",
      "denseblock4.denselayer17.conv2.weight True\n",
      "denseblock4.denselayer18.norm1.weight True\n",
      "denseblock4.denselayer18.norm1.bias True\n",
      "denseblock4.denselayer18.conv1.weight True\n",
      "denseblock4.denselayer18.norm2.weight True\n",
      "denseblock4.denselayer18.norm2.bias True\n",
      "denseblock4.denselayer18.conv2.weight True\n",
      "denseblock4.denselayer19.norm1.weight True\n",
      "denseblock4.denselayer19.norm1.bias True\n",
      "denseblock4.denselayer19.conv1.weight True\n",
      "denseblock4.denselayer19.norm2.weight True\n",
      "denseblock4.denselayer19.norm2.bias True\n",
      "denseblock4.denselayer19.conv2.weight True\n",
      "denseblock4.denselayer20.norm1.weight True\n",
      "denseblock4.denselayer20.norm1.bias True\n",
      "denseblock4.denselayer20.conv1.weight True\n",
      "denseblock4.denselayer20.norm2.weight True\n",
      "denseblock4.denselayer20.norm2.bias True\n",
      "denseblock4.denselayer20.conv2.weight True\n",
      "denseblock4.denselayer21.norm1.weight True\n",
      "denseblock4.denselayer21.norm1.bias True\n",
      "denseblock4.denselayer21.conv1.weight True\n",
      "denseblock4.denselayer21.norm2.weight True\n",
      "denseblock4.denselayer21.norm2.bias True\n",
      "denseblock4.denselayer21.conv2.weight True\n",
      "denseblock4.denselayer22.norm1.weight True\n",
      "denseblock4.denselayer22.norm1.bias True\n",
      "denseblock4.denselayer22.conv1.weight True\n",
      "denseblock4.denselayer22.norm2.weight True\n",
      "denseblock4.denselayer22.norm2.bias True\n",
      "denseblock4.denselayer22.conv2.weight True\n",
      "denseblock4.denselayer23.norm1.weight True\n",
      "denseblock4.denselayer23.norm1.bias True\n",
      "denseblock4.denselayer23.conv1.weight True\n",
      "denseblock4.denselayer23.norm2.weight True\n",
      "denseblock4.denselayer23.norm2.bias True\n",
      "denseblock4.denselayer23.conv2.weight True\n",
      "denseblock4.denselayer24.norm1.weight True\n",
      "denseblock4.denselayer24.norm1.bias True\n",
      "denseblock4.denselayer24.conv1.weight True\n",
      "denseblock4.denselayer24.norm2.weight True\n",
      "denseblock4.denselayer24.norm2.bias True\n",
      "denseblock4.denselayer24.conv2.weight True\n",
      "denseblock4.denselayer25.norm1.weight True\n",
      "denseblock4.denselayer25.norm1.bias True\n",
      "denseblock4.denselayer25.conv1.weight True\n",
      "denseblock4.denselayer25.norm2.weight True\n",
      "denseblock4.denselayer25.norm2.bias True\n",
      "denseblock4.denselayer25.conv2.weight True\n",
      "denseblock4.denselayer26.norm1.weight True\n",
      "denseblock4.denselayer26.norm1.bias True\n",
      "denseblock4.denselayer26.conv1.weight True\n",
      "denseblock4.denselayer26.norm2.weight True\n",
      "denseblock4.denselayer26.norm2.bias True\n",
      "denseblock4.denselayer26.conv2.weight True\n",
      "denseblock4.denselayer27.norm1.weight True\n",
      "denseblock4.denselayer27.norm1.bias True\n",
      "denseblock4.denselayer27.conv1.weight True\n",
      "denseblock4.denselayer27.norm2.weight True\n",
      "denseblock4.denselayer27.norm2.bias True\n",
      "denseblock4.denselayer27.conv2.weight True\n",
      "denseblock4.denselayer28.norm1.weight True\n",
      "denseblock4.denselayer28.norm1.bias True\n",
      "denseblock4.denselayer28.conv1.weight True\n",
      "denseblock4.denselayer28.norm2.weight True\n",
      "denseblock4.denselayer28.norm2.bias True\n",
      "denseblock4.denselayer28.conv2.weight True\n",
      "denseblock4.denselayer29.norm1.weight True\n",
      "denseblock4.denselayer29.norm1.bias True\n",
      "denseblock4.denselayer29.conv1.weight True\n",
      "denseblock4.denselayer29.norm2.weight True\n",
      "denseblock4.denselayer29.norm2.bias True\n",
      "denseblock4.denselayer29.conv2.weight True\n",
      "denseblock4.denselayer30.norm1.weight True\n",
      "denseblock4.denselayer30.norm1.bias True\n",
      "denseblock4.denselayer30.conv1.weight True\n",
      "denseblock4.denselayer30.norm2.weight True\n",
      "denseblock4.denselayer30.norm2.bias True\n",
      "denseblock4.denselayer30.conv2.weight True\n",
      "denseblock4.denselayer31.norm1.weight True\n",
      "denseblock4.denselayer31.norm1.bias True\n",
      "denseblock4.denselayer31.conv1.weight True\n",
      "denseblock4.denselayer31.norm2.weight True\n",
      "denseblock4.denselayer31.norm2.bias True\n",
      "denseblock4.denselayer31.conv2.weight True\n",
      "denseblock4.denselayer32.norm1.weight True\n",
      "denseblock4.denselayer32.norm1.bias True\n",
      "denseblock4.denselayer32.conv1.weight True\n",
      "denseblock4.denselayer32.norm2.weight True\n",
      "denseblock4.denselayer32.norm2.bias True\n",
      "denseblock4.denselayer32.conv2.weight True\n",
      "norm5.weight True\n",
      "norm5.bias True\n",
      "weight True\n",
      "bias True\n",
      "weight True\n",
      "bias True\n"
     ]
    }
   ],
   "source": [
    "# To view which layers are freeze and which layers are not freezed:\n",
    "for name, child in model_ft.named_children():\n",
    "  for name_2, params in child.named_parameters():\n",
    "    print(name_2, params.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/59\n",
      "----------\n",
      "train Loss: 2.5873 Acc: 0.5479\n",
      "valid Loss: 0.3518 Acc: 0.9132\n",
      "\n",
      "Epoch 1/59\n",
      "----------\n",
      "train Loss: 0.5017 Acc: 0.8800\n",
      "valid Loss: 0.2399 Acc: 0.9352\n",
      "\n",
      "Epoch 2/59\n",
      "----------\n",
      "train Loss: 0.3368 Acc: 0.9174\n",
      "valid Loss: 0.1921 Acc: 0.9523\n",
      "\n",
      "Epoch 3/59\n",
      "----------\n",
      "train Loss: 0.2523 Acc: 0.9383\n",
      "valid Loss: 0.1283 Acc: 0.9694\n",
      "\n",
      "Epoch 4/59\n",
      "----------\n",
      "train Loss: 0.2052 Acc: 0.9483\n",
      "valid Loss: 0.1093 Acc: 0.9719\n",
      "\n",
      "Epoch 5/59\n",
      "----------\n",
      "train Loss: 0.1722 Acc: 0.9560\n",
      "valid Loss: 0.1051 Acc: 0.9756\n",
      "\n",
      "Epoch 6/59\n",
      "----------\n",
      "train Loss: 0.1666 Acc: 0.9574\n",
      "valid Loss: 0.0942 Acc: 0.9817\n",
      "\n",
      "Epoch 7/59\n",
      "----------\n",
      "train Loss: 0.1484 Acc: 0.9637\n",
      "valid Loss: 0.0919 Acc: 0.9780\n",
      "\n",
      "Epoch 8/59\n",
      "----------\n",
      "train Loss: 0.1342 Acc: 0.9653\n",
      "valid Loss: 0.0939 Acc: 0.9817\n",
      "\n",
      "Epoch 9/59\n",
      "----------\n",
      "train Loss: 0.1376 Acc: 0.9660\n",
      "valid Loss: 0.0802 Acc: 0.9780\n",
      "\n",
      "Epoch 10/59\n",
      "----------\n",
      "train Loss: 0.1109 Acc: 0.9742\n",
      "valid Loss: 0.0863 Acc: 0.9817\n",
      "\n",
      "Epoch 11/59\n",
      "----------\n",
      "train Loss: 0.1182 Acc: 0.9711\n",
      "valid Loss: 0.0780 Acc: 0.9841\n",
      "\n",
      "Epoch 12/59\n",
      "----------\n",
      "train Loss: 0.1122 Acc: 0.9718\n",
      "valid Loss: 0.0944 Acc: 0.9804\n",
      "\n",
      "Epoch 13/59\n",
      "----------\n",
      "train Loss: 0.1094 Acc: 0.9748\n",
      "valid Loss: 0.0712 Acc: 0.9878\n",
      "\n",
      "Epoch 14/59\n",
      "----------\n",
      "train Loss: 0.1083 Acc: 0.9734\n",
      "valid Loss: 0.0727 Acc: 0.9853\n",
      "\n",
      "Epoch 15/59\n",
      "----------\n",
      "train Loss: 0.0976 Acc: 0.9756\n",
      "valid Loss: 0.0766 Acc: 0.9792\n",
      "\n",
      "Epoch 16/59\n",
      "----------\n",
      "train Loss: 0.1015 Acc: 0.9753\n",
      "valid Loss: 0.0749 Acc: 0.9841\n",
      "\n",
      "Epoch 17/59\n",
      "----------\n",
      "train Loss: 0.0923 Acc: 0.9760\n",
      "valid Loss: 0.0780 Acc: 0.9841\n",
      "\n",
      "Epoch 18/59\n",
      "----------\n",
      "train Loss: 0.0919 Acc: 0.9773\n",
      "valid Loss: 0.0675 Acc: 0.9841\n",
      "\n",
      "Epoch 19/59\n",
      "----------\n",
      "train Loss: 0.0815 Acc: 0.9782\n",
      "valid Loss: 0.0606 Acc: 0.9829\n",
      "\n",
      "Epoch 20/59\n",
      "----------\n",
      "train Loss: 0.0823 Acc: 0.9785\n",
      "valid Loss: 0.0764 Acc: 0.9866\n",
      "\n",
      "Epoch 21/59\n",
      "----------\n",
      "train Loss: 0.0849 Acc: 0.9792\n",
      "valid Loss: 0.0690 Acc: 0.9853\n",
      "\n",
      "Epoch 22/59\n",
      "----------\n",
      "train Loss: 0.0762 Acc: 0.9808\n",
      "valid Loss: 0.0742 Acc: 0.9866\n",
      "\n",
      "Epoch 23/59\n",
      "----------\n",
      "train Loss: 0.0856 Acc: 0.9792\n",
      "valid Loss: 0.0651 Acc: 0.9841\n",
      "\n",
      "Epoch 24/59\n",
      "----------\n",
      "train Loss: 0.0689 Acc: 0.9832\n",
      "valid Loss: 0.0616 Acc: 0.9878\n",
      "\n",
      "Epoch 25/59\n",
      "----------\n",
      "train Loss: 0.0684 Acc: 0.9826\n",
      "valid Loss: 0.0601 Acc: 0.9878\n",
      "\n",
      "Epoch 26/59\n",
      "----------\n",
      "train Loss: 0.0636 Acc: 0.9840\n",
      "valid Loss: 0.0699 Acc: 0.9853\n",
      "\n",
      "Epoch 27/59\n",
      "----------\n",
      "train Loss: 0.0698 Acc: 0.9820\n",
      "valid Loss: 0.0604 Acc: 0.9853\n",
      "\n",
      "Epoch 28/59\n",
      "----------\n",
      "train Loss: 0.0702 Acc: 0.9829\n",
      "valid Loss: 0.0624 Acc: 0.9853\n",
      "\n",
      "Epoch 29/59\n",
      "----------\n",
      "train Loss: 0.0657 Acc: 0.9832\n",
      "valid Loss: 0.0688 Acc: 0.9853\n",
      "\n",
      "Epoch 30/59\n",
      "----------\n",
      "train Loss: 0.0603 Acc: 0.9857\n",
      "valid Loss: 0.0641 Acc: 0.9878\n",
      "\n",
      "Epoch 31/59\n",
      "----------\n",
      "train Loss: 0.0572 Acc: 0.9849\n",
      "valid Loss: 0.0615 Acc: 0.9890\n",
      "\n",
      "Epoch 32/59\n",
      "----------\n",
      "train Loss: 0.0507 Acc: 0.9879\n",
      "valid Loss: 0.0577 Acc: 0.9902\n",
      "\n",
      "Epoch 33/59\n",
      "----------\n",
      "train Loss: 0.0494 Acc: 0.9879\n",
      "valid Loss: 0.0567 Acc: 0.9890\n",
      "\n",
      "Epoch 34/59\n",
      "----------\n",
      "train Loss: 0.0486 Acc: 0.9882\n",
      "valid Loss: 0.0598 Acc: 0.9878\n",
      "\n",
      "Epoch 35/59\n",
      "----------\n",
      "train Loss: 0.0543 Acc: 0.9869\n",
      "valid Loss: 0.0569 Acc: 0.9866\n",
      "\n",
      "Epoch 36/59\n",
      "----------\n",
      "train Loss: 0.0512 Acc: 0.9873\n",
      "valid Loss: 0.0572 Acc: 0.9866\n",
      "\n",
      "Epoch 37/59\n",
      "----------\n",
      "train Loss: 0.0459 Acc: 0.9895\n",
      "valid Loss: 0.0579 Acc: 0.9841\n",
      "\n",
      "Epoch 38/59\n",
      "----------\n",
      "train Loss: 0.0510 Acc: 0.9878\n",
      "valid Loss: 0.0535 Acc: 0.9878\n",
      "\n",
      "Epoch 39/59\n",
      "----------\n",
      "train Loss: 0.0506 Acc: 0.9869\n",
      "valid Loss: 0.0563 Acc: 0.9853\n",
      "\n",
      "Epoch 40/59\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-64f99964beaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-86ad53e9c08a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DenseLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mthreshold\u001b[0;34m(input, threshold, value, inplace)\u001b[0m\n\u001b[1;32m    836\u001b[0m     \"\"\"\n\u001b[1;32m    837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze all layers first\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Then unfreeze last classification layer only for feature extract\n",
    "for param in model_ft.classifier.parameters():\n",
    "    param.requires_grad = True    \n",
    "\n",
    "    \n",
    "# To view which layers are freeze and which layers are not freezed:\n",
    "for name, child in model_ft.named_children():\n",
    "  for name_2, params in child.named_parameters():\n",
    "    print(name_2, params.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0001, momentum=0.7)\n",
    "# Decay LR by a factor of 0.1 every ? epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.01)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serve that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.95, nesterov=True)\n",
    "# Decay LR by a factor of 0.1 every ? epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.01)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UnFreeze all layers first\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True \n",
    "\n",
    "# To view which layers are freeze and which layers are not freezed:\n",
    "for name, child in model_ft.named_children():\n",
    "  for name_2, params in child.named_parameters():\n",
    "    print(name_2, params.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serve that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every ? epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.01)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
