{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FLowers- PyTorch_ResNet152_full.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"iSzXrx5dwzbn","colab_type":"text"},"cell_type":"markdown","source":["# PyTorch Transfer Learning\n","\n"," 1.   Freezing all the layers except the final one\n"," 2.   Freezing the first few layers\n"," 3.   Fine-tuning the entire network.\n","\n","The following pre-trained models are available on PyTorch\n","\n"," *   resnet18, resnet34, resnet50, resnet101, resnet152\n"," *   squeezenet1_0, squeezenet1_1\n"," *   Alexnet\n"," *   inception_v3\n"," *   Densenet121, Densenet169, Densenet201\n"," *   Vgg11, vgg13, vgg16, vgg19, vgg11_bn. vgg13_bn, vgg16_bn, vgg19_bn"]},{"metadata":{"id":"q3dZyuJT2Hef","colab_type":"code","outputId":"213826f3-18bc-433b-e25d-0c3a57b6d28f","executionInfo":{"status":"ok","timestamp":1544165403046,"user_tz":-120,"elapsed":1810,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import sys\n","sys.version"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'3.6.7 (default, Oct 22 2018, 11:32:17) \\n[GCC 8.2.0]'"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"2chHgWpW2PuM","colab_type":"code","colab":{}},"cell_type":"code","source":["# http://pytorch.org/\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n","#import torch"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6TZ2slC60HQe","colab_type":"code","outputId":"2139828c-0813-4955-c929-2b1c1feac911","executionInfo":{"status":"ok","timestamp":1544165413745,"user_tz":-120,"elapsed":12492,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"cell_type":"code","source":["!pip install Pillow\n","!pip install image"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (5.3.0)\n","Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (5.3.0)\n","Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.4)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.7)\n"],"name":"stdout"}]},{"metadata":{"id":"3Vm3WE_k2PsY","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7Xqgc2xH2Pp2","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import print_function, division\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","\n","plt.ion()   # interactive mode"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oeyRHeaZap5i","colab_type":"code","outputId":"5876aef2-385b-4a3c-c40f-e29b0b0772ed","executionInfo":{"status":"ok","timestamp":1544165414052,"user_tz":-120,"elapsed":12769,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import torch\n","print(torch.__version__)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["0.4.1\n"],"name":"stdout"}]},{"metadata":{"id":"N6m_x749aq3Z","colab_type":"code","outputId":"d746a504-67ba-4f8b-cf9c-4fe9964d9e30","executionInfo":{"status":"ok","timestamp":1544165415712,"user_tz":-120,"elapsed":14420,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"rhTqGutGawuR","colab_type":"code","outputId":"a4254d51-8cc7-48fb-b042-dcaca3233ae6","executionInfo":{"status":"ok","timestamp":1544165415715,"user_tz":-120,"elapsed":14416,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["torch.cuda.is_available()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"71-yIy-Qa2vD","colab_type":"text"},"cell_type":"markdown","source":["### Get Data"]},{"metadata":{"id":"zKBom-zdjALm","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"VODxlKvN2PkW","colab_type":"code","colab":{}},"cell_type":"code","source":["DATASET_ZIP_FILE = 'flower_data.zip'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HtkfN9N72PiZ","colab_type":"code","colab":{}},"cell_type":"code","source":["from zipfile import ZipFile\n","files = os.listdir()\n","if not DATASET_ZIP_FILE in files:\n","  !curl --header 'Host: s3.amazonaws.com' --user-agent 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:63.0) Gecko/20100101 Firefox/63.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --header 'Upgrade-Insecure-Requests: 1' 'https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip' --output 'flower_data.zip'  \n","  '''\n","  !pip install kaggle\n","  from google.colab import files\n","  files.upload()\n","  !mkdir -p ~/.kaggle\n","  !cp kaggle.json ~/.kaggle/\n","  #this permissions change avoids a warnong on Kaggle tool startup\n","  !chmod 600 ~/.kaggle/kaggle.json  \n","  !kaggle datasets download -d moltean/fruits\n","  '''\n","  !ls\n","  with ZipFile(DATASET_ZIP_FILE, 'r') as zipF:\n","    zipF.extractall()\n","    print('UnZip Done')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ObSloe2q5kni","colab_type":"code","colab":{}},"cell_type":"code","source":["data_dir = 'flower_data/'\n","PATH = data_dir\n","\n","train_dir = 'train'\n","val_dir = 'valid'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8OydrR4kASL1","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 16"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TZXIBRhKIfvW","colab_type":"code","outputId":"575f828e-2fe1-4d87-c8a6-9e77de28fd01","executionInfo":{"status":"ok","timestamp":1544165415722,"user_tz":-120,"elapsed":14383,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# again, list total number of classes, and list them all\n","# os.list dir sorting depends on OS dependent file indexing, so leaving it as it is\n","\n","classes = os.listdir(f'{data_dir}/{train_dir}')\n","classes.sort()\n","ClassesNumer = len(classes)\n","print(\"Class Total Count: \", ClassesNumer)\n","#print(classes)\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Class Total Count:  102\n"],"name":"stdout"}]},{"metadata":{"id":"7DJkVbgh2Per","colab_type":"code","colab":{}},"cell_type":"code","source":["# Data augmentation and normalization for training\n","# Just normalization for validation\n","data_transforms = {\n","    train_dir: transforms.Compose([\n","        #transforms.Resize(224),\n","        transforms.RandomResizedCrop(224),\n","        #transforms.RandomHorizontalFlip(),\n","        #transforms.RandomVerticalFlip(),\n","        #transforms.RandomRotation(degrees=90),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","       # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ]),\n","    val_dir: transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ]),\n","}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f-QuAcbp5pcb","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),data_transforms[x]) for x in [train_dir, val_dir]}\n","\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=4) for x in [train_dir, val_dir]}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in [train_dir, val_dir]}\n","\n","class_names = image_datasets[train_dir].classes\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xVOoYMKDnupW","colab_type":"code","outputId":"f41b15eb-f400-4761-d939-09e420c3a275","executionInfo":{"status":"ok","timestamp":1544165415726,"user_tz":-120,"elapsed":14371,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["print(dataloaders)\n","print(dataset_sizes)\n","print(device)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["{'train': <torch.utils.data.dataloader.DataLoader object at 0x7f4875174208>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f4870907da0>}\n","{'train': 6552, 'valid': 818}\n","cuda:0\n"],"name":"stdout"}]},{"metadata":{"id":"nLxdE7ezmGAJ","colab_type":"code","outputId":"1b616182-6331-4143-a166-b1a7b73e5f29","executionInfo":{"status":"ok","timestamp":1544165415727,"user_tz":-120,"elapsed":14365,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"cell_type":"code","source":["print(image_datasets[train_dir])\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Dataset ImageFolder\n","    Number of datapoints: 6552\n","    Root Location: flower_data/train\n","    Transforms (if any): Compose(\n","                             RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n","                             ToTensor()\n","                             Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","                         )\n","    Target Transforms (if any): None\n"],"name":"stdout"}]},{"metadata":{"id":"KQa91SiQ57N9","colab_type":"code","outputId":"4c2f822e-fb41-4a4f-ebfc-1aa7e1e683b7","executionInfo":{"status":"ok","timestamp":1544165415727,"user_tz":-120,"elapsed":14359,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["'''\n","#Let’s visualize a few training images so as to understand the data augmentations.\n","def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","\n","\n","# Get a batch of training data\n","inputs, classes = next(iter(dataloaders[train_dir]))\n","\n","# Make a grid from batch\n","out = torchvision.utils.make_grid(inputs)\n","\n","imshow(out, title=[class_names[x] for x in classes])\n","'''"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n#Let’s visualize a few training images so as to understand the data augmentations.\\ndef imshow(inp, title=None):\\n    \"\"\"Imshow for Tensor.\"\"\"\\n    inp = inp.numpy().transpose((1, 2, 0))\\n    mean = np.array([0.485, 0.456, 0.406])\\n    std = np.array([0.229, 0.224, 0.225])\\n    inp = std * inp + mean\\n    inp = np.clip(inp, 0, 1)\\n    plt.imshow(inp)\\n    if title is not None:\\n        plt.title(title)\\n    plt.pause(0.001)  # pause a bit so that plots are updated\\n\\n\\n# Get a batch of training data\\ninputs, classes = next(iter(dataloaders[train_dir]))\\n\\n# Make a grid from batch\\nout = torchvision.utils.make_grid(inputs)\\n\\nimshow(out, title=[class_names[x] for x in classes])\\n'"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"W2I2k8qg6G52","colab_type":"text"},"cell_type":"markdown","source":["###Training the model\n","\n","Now, let’s write a general function to train a model. Here, we will illustrate:\n","\n","    Scheduling the learning rate\n","    Saving the best model\n","\n","In the following, parameter ''scheduler'' is an LR scheduler object from ''torch.optim.lr_scheduler''."]},{"metadata":{"id":"ESnZJ2a36L9u","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in [train_dir, val_dir]:\n","            if phase == train_dir:\n","                scheduler.step()\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == train_dir):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == train_dir:\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == val_dir and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4blz3fsMoybs","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load a pretrained model and reset final fully connected layer\n","model_ft = models.resnet152(pretrained=True)\n","num_ftrs = model_ft.fc.in_features\n","#model_ft.fc = nn.Linear(num_ftrs, 2)\n","model_ft.fc = nn.Linear(num_ftrs, ClassesNumer)\n","\n","model_ft = model_ft.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# Observe that all parameters are being optimized\n","#optimizer_ft = optim.Adam(model_ft.parameters(),lr=0.001,amsgrad=True)\n","optimizer_ft = optim.Adagrad(model_ft.parameters(),lr=0.01,lr_decay=0.0001)\n","\n","# Decay LR by a factor of 0.1 every 7 epochs\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NyJ7ZfZ_nzst","colab_type":"code","outputId":"d95b0bd4-ae2d-41c5-9379-ea72211cdedd","executionInfo":{"status":"ok","timestamp":1544165420938,"user_tz":-120,"elapsed":19551,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}},"colab":{"base_uri":"https://localhost:8080/","height":7956}},"cell_type":"code","source":["#Freeze all layers first\n","#for param in model_ft.parameters():\n","#    param.requires_grad = False\n","    \n","# Then unfreeze last classification layer only for feature extract\n","#for param in model_ft.fc.parameters():\n","#    param.requires_grad = True    \n","\n","    \n","# To view which layers are freeze and which layers are not freezed:\n","for name, child in model_ft.named_children():\n","  for name_2, params in child.named_parameters():\n","    print(name_2, params.requires_grad)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["weight True\n","weight True\n","bias True\n","0.conv1.weight True\n","0.bn1.weight True\n","0.bn1.bias True\n","0.conv2.weight True\n","0.bn2.weight True\n","0.bn2.bias True\n","0.conv3.weight True\n","0.bn3.weight True\n","0.bn3.bias True\n","0.downsample.0.weight True\n","0.downsample.1.weight True\n","0.downsample.1.bias True\n","1.conv1.weight True\n","1.bn1.weight True\n","1.bn1.bias True\n","1.conv2.weight True\n","1.bn2.weight True\n","1.bn2.bias True\n","1.conv3.weight True\n","1.bn3.weight True\n","1.bn3.bias True\n","2.conv1.weight True\n","2.bn1.weight True\n","2.bn1.bias True\n","2.conv2.weight True\n","2.bn2.weight True\n","2.bn2.bias True\n","2.conv3.weight True\n","2.bn3.weight True\n","2.bn3.bias True\n","0.conv1.weight True\n","0.bn1.weight True\n","0.bn1.bias True\n","0.conv2.weight True\n","0.bn2.weight True\n","0.bn2.bias True\n","0.conv3.weight True\n","0.bn3.weight True\n","0.bn3.bias True\n","0.downsample.0.weight True\n","0.downsample.1.weight True\n","0.downsample.1.bias True\n","1.conv1.weight True\n","1.bn1.weight True\n","1.bn1.bias True\n","1.conv2.weight True\n","1.bn2.weight True\n","1.bn2.bias True\n","1.conv3.weight True\n","1.bn3.weight True\n","1.bn3.bias True\n","2.conv1.weight True\n","2.bn1.weight True\n","2.bn1.bias True\n","2.conv2.weight True\n","2.bn2.weight True\n","2.bn2.bias True\n","2.conv3.weight True\n","2.bn3.weight True\n","2.bn3.bias True\n","3.conv1.weight True\n","3.bn1.weight True\n","3.bn1.bias True\n","3.conv2.weight True\n","3.bn2.weight True\n","3.bn2.bias True\n","3.conv3.weight True\n","3.bn3.weight True\n","3.bn3.bias True\n","4.conv1.weight True\n","4.bn1.weight True\n","4.bn1.bias True\n","4.conv2.weight True\n","4.bn2.weight True\n","4.bn2.bias True\n","4.conv3.weight True\n","4.bn3.weight True\n","4.bn3.bias True\n","5.conv1.weight True\n","5.bn1.weight True\n","5.bn1.bias True\n","5.conv2.weight True\n","5.bn2.weight True\n","5.bn2.bias True\n","5.conv3.weight True\n","5.bn3.weight True\n","5.bn3.bias True\n","6.conv1.weight True\n","6.bn1.weight True\n","6.bn1.bias True\n","6.conv2.weight True\n","6.bn2.weight True\n","6.bn2.bias True\n","6.conv3.weight True\n","6.bn3.weight True\n","6.bn3.bias True\n","7.conv1.weight True\n","7.bn1.weight True\n","7.bn1.bias True\n","7.conv2.weight True\n","7.bn2.weight True\n","7.bn2.bias True\n","7.conv3.weight True\n","7.bn3.weight True\n","7.bn3.bias True\n","0.conv1.weight True\n","0.bn1.weight True\n","0.bn1.bias True\n","0.conv2.weight True\n","0.bn2.weight True\n","0.bn2.bias True\n","0.conv3.weight True\n","0.bn3.weight True\n","0.bn3.bias True\n","0.downsample.0.weight True\n","0.downsample.1.weight True\n","0.downsample.1.bias True\n","1.conv1.weight True\n","1.bn1.weight True\n","1.bn1.bias True\n","1.conv2.weight True\n","1.bn2.weight True\n","1.bn2.bias True\n","1.conv3.weight True\n","1.bn3.weight True\n","1.bn3.bias True\n","2.conv1.weight True\n","2.bn1.weight True\n","2.bn1.bias True\n","2.conv2.weight True\n","2.bn2.weight True\n","2.bn2.bias True\n","2.conv3.weight True\n","2.bn3.weight True\n","2.bn3.bias True\n","3.conv1.weight True\n","3.bn1.weight True\n","3.bn1.bias True\n","3.conv2.weight True\n","3.bn2.weight True\n","3.bn2.bias True\n","3.conv3.weight True\n","3.bn3.weight True\n","3.bn3.bias True\n","4.conv1.weight True\n","4.bn1.weight True\n","4.bn1.bias True\n","4.conv2.weight True\n","4.bn2.weight True\n","4.bn2.bias True\n","4.conv3.weight True\n","4.bn3.weight True\n","4.bn3.bias True\n","5.conv1.weight True\n","5.bn1.weight True\n","5.bn1.bias True\n","5.conv2.weight True\n","5.bn2.weight True\n","5.bn2.bias True\n","5.conv3.weight True\n","5.bn3.weight True\n","5.bn3.bias True\n","6.conv1.weight True\n","6.bn1.weight True\n","6.bn1.bias True\n","6.conv2.weight True\n","6.bn2.weight True\n","6.bn2.bias True\n","6.conv3.weight True\n","6.bn3.weight True\n","6.bn3.bias True\n","7.conv1.weight True\n","7.bn1.weight True\n","7.bn1.bias True\n","7.conv2.weight True\n","7.bn2.weight True\n","7.bn2.bias True\n","7.conv3.weight True\n","7.bn3.weight True\n","7.bn3.bias True\n","8.conv1.weight True\n","8.bn1.weight True\n","8.bn1.bias True\n","8.conv2.weight True\n","8.bn2.weight True\n","8.bn2.bias True\n","8.conv3.weight True\n","8.bn3.weight True\n","8.bn3.bias True\n","9.conv1.weight True\n","9.bn1.weight True\n","9.bn1.bias True\n","9.conv2.weight True\n","9.bn2.weight True\n","9.bn2.bias True\n","9.conv3.weight True\n","9.bn3.weight True\n","9.bn3.bias True\n","10.conv1.weight True\n","10.bn1.weight True\n","10.bn1.bias True\n","10.conv2.weight True\n","10.bn2.weight True\n","10.bn2.bias True\n","10.conv3.weight True\n","10.bn3.weight True\n","10.bn3.bias True\n","11.conv1.weight True\n","11.bn1.weight True\n","11.bn1.bias True\n","11.conv2.weight True\n","11.bn2.weight True\n","11.bn2.bias True\n","11.conv3.weight True\n","11.bn3.weight True\n","11.bn3.bias True\n","12.conv1.weight True\n","12.bn1.weight True\n","12.bn1.bias True\n","12.conv2.weight True\n","12.bn2.weight True\n","12.bn2.bias True\n","12.conv3.weight True\n","12.bn3.weight True\n","12.bn3.bias True\n","13.conv1.weight True\n","13.bn1.weight True\n","13.bn1.bias True\n","13.conv2.weight True\n","13.bn2.weight True\n","13.bn2.bias True\n","13.conv3.weight True\n","13.bn3.weight True\n","13.bn3.bias True\n","14.conv1.weight True\n","14.bn1.weight True\n","14.bn1.bias True\n","14.conv2.weight True\n","14.bn2.weight True\n","14.bn2.bias True\n","14.conv3.weight True\n","14.bn3.weight True\n","14.bn3.bias True\n","15.conv1.weight True\n","15.bn1.weight True\n","15.bn1.bias True\n","15.conv2.weight True\n","15.bn2.weight True\n","15.bn2.bias True\n","15.conv3.weight True\n","15.bn3.weight True\n","15.bn3.bias True\n","16.conv1.weight True\n","16.bn1.weight True\n","16.bn1.bias True\n","16.conv2.weight True\n","16.bn2.weight True\n","16.bn2.bias True\n","16.conv3.weight True\n","16.bn3.weight True\n","16.bn3.bias True\n","17.conv1.weight True\n","17.bn1.weight True\n","17.bn1.bias True\n","17.conv2.weight True\n","17.bn2.weight True\n","17.bn2.bias True\n","17.conv3.weight True\n","17.bn3.weight True\n","17.bn3.bias True\n","18.conv1.weight True\n","18.bn1.weight True\n","18.bn1.bias True\n","18.conv2.weight True\n","18.bn2.weight True\n","18.bn2.bias True\n","18.conv3.weight True\n","18.bn3.weight True\n","18.bn3.bias True\n","19.conv1.weight True\n","19.bn1.weight True\n","19.bn1.bias True\n","19.conv2.weight True\n","19.bn2.weight True\n","19.bn2.bias True\n","19.conv3.weight True\n","19.bn3.weight True\n","19.bn3.bias True\n","20.conv1.weight True\n","20.bn1.weight True\n","20.bn1.bias True\n","20.conv2.weight True\n","20.bn2.weight True\n","20.bn2.bias True\n","20.conv3.weight True\n","20.bn3.weight True\n","20.bn3.bias True\n","21.conv1.weight True\n","21.bn1.weight True\n","21.bn1.bias True\n","21.conv2.weight True\n","21.bn2.weight True\n","21.bn2.bias True\n","21.conv3.weight True\n","21.bn3.weight True\n","21.bn3.bias True\n","22.conv1.weight True\n","22.bn1.weight True\n","22.bn1.bias True\n","22.conv2.weight True\n","22.bn2.weight True\n","22.bn2.bias True\n","22.conv3.weight True\n","22.bn3.weight True\n","22.bn3.bias True\n","23.conv1.weight True\n","23.bn1.weight True\n","23.bn1.bias True\n","23.conv2.weight True\n","23.bn2.weight True\n","23.bn2.bias True\n","23.conv3.weight True\n","23.bn3.weight True\n","23.bn3.bias True\n","24.conv1.weight True\n","24.bn1.weight True\n","24.bn1.bias True\n","24.conv2.weight True\n","24.bn2.weight True\n","24.bn2.bias True\n","24.conv3.weight True\n","24.bn3.weight True\n","24.bn3.bias True\n","25.conv1.weight True\n","25.bn1.weight True\n","25.bn1.bias True\n","25.conv2.weight True\n","25.bn2.weight True\n","25.bn2.bias True\n","25.conv3.weight True\n","25.bn3.weight True\n","25.bn3.bias True\n","26.conv1.weight True\n","26.bn1.weight True\n","26.bn1.bias True\n","26.conv2.weight True\n","26.bn2.weight True\n","26.bn2.bias True\n","26.conv3.weight True\n","26.bn3.weight True\n","26.bn3.bias True\n","27.conv1.weight True\n","27.bn1.weight True\n","27.bn1.bias True\n","27.conv2.weight True\n","27.bn2.weight True\n","27.bn2.bias True\n","27.conv3.weight True\n","27.bn3.weight True\n","27.bn3.bias True\n","28.conv1.weight True\n","28.bn1.weight True\n","28.bn1.bias True\n","28.conv2.weight True\n","28.bn2.weight True\n","28.bn2.bias True\n","28.conv3.weight True\n","28.bn3.weight True\n","28.bn3.bias True\n","29.conv1.weight True\n","29.bn1.weight True\n","29.bn1.bias True\n","29.conv2.weight True\n","29.bn2.weight True\n","29.bn2.bias True\n","29.conv3.weight True\n","29.bn3.weight True\n","29.bn3.bias True\n","30.conv1.weight True\n","30.bn1.weight True\n","30.bn1.bias True\n","30.conv2.weight True\n","30.bn2.weight True\n","30.bn2.bias True\n","30.conv3.weight True\n","30.bn3.weight True\n","30.bn3.bias True\n","31.conv1.weight True\n","31.bn1.weight True\n","31.bn1.bias True\n","31.conv2.weight True\n","31.bn2.weight True\n","31.bn2.bias True\n","31.conv3.weight True\n","31.bn3.weight True\n","31.bn3.bias True\n","32.conv1.weight True\n","32.bn1.weight True\n","32.bn1.bias True\n","32.conv2.weight True\n","32.bn2.weight True\n","32.bn2.bias True\n","32.conv3.weight True\n","32.bn3.weight True\n","32.bn3.bias True\n","33.conv1.weight True\n","33.bn1.weight True\n","33.bn1.bias True\n","33.conv2.weight True\n","33.bn2.weight True\n","33.bn2.bias True\n","33.conv3.weight True\n","33.bn3.weight True\n","33.bn3.bias True\n","34.conv1.weight True\n","34.bn1.weight True\n","34.bn1.bias True\n","34.conv2.weight True\n","34.bn2.weight True\n","34.bn2.bias True\n","34.conv3.weight True\n","34.bn3.weight True\n","34.bn3.bias True\n","35.conv1.weight True\n","35.bn1.weight True\n","35.bn1.bias True\n","35.conv2.weight True\n","35.bn2.weight True\n","35.bn2.bias True\n","35.conv3.weight True\n","35.bn3.weight True\n","35.bn3.bias True\n","0.conv1.weight True\n","0.bn1.weight True\n","0.bn1.bias True\n","0.conv2.weight True\n","0.bn2.weight True\n","0.bn2.bias True\n","0.conv3.weight True\n","0.bn3.weight True\n","0.bn3.bias True\n","0.downsample.0.weight True\n","0.downsample.1.weight True\n","0.downsample.1.bias True\n","1.conv1.weight True\n","1.bn1.weight True\n","1.bn1.bias True\n","1.conv2.weight True\n","1.bn2.weight True\n","1.bn2.bias True\n","1.conv3.weight True\n","1.bn3.weight True\n","1.bn3.bias True\n","2.conv1.weight True\n","2.bn1.weight True\n","2.bn1.bias True\n","2.conv2.weight True\n","2.bn2.weight True\n","2.bn2.bias True\n","2.conv3.weight True\n","2.bn3.weight True\n","2.bn3.bias True\n","weight True\n","bias True\n"],"name":"stdout"}]},{"metadata":{"id":"HnHcjSFon07q","colab_type":"code","outputId":"cbbe4bf9-f8f5-4340-9a57-09f7e7731400","executionInfo":{"status":"ok","timestamp":1544176825149,"user_tz":-120,"elapsed":1383636,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}},"colab":{"base_uri":"https://localhost:8080/","height":2346}},"cell_type":"code","source":["# Train and evaluate\n","model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=27)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Epoch 0/26\n","----------\n","train Loss: 4.1040 Acc: 0.0809\n","valid Loss: 3.6028 Acc: 0.1174\n","\n","Epoch 1/26\n","----------\n","train Loss: 3.3704 Acc: 0.1725\n","valid Loss: 3.2219 Acc: 0.2200\n","\n","Epoch 2/26\n","----------\n","train Loss: 2.9138 Acc: 0.2593\n","valid Loss: 2.6933 Acc: 0.3350\n","\n","Epoch 3/26\n","----------\n","train Loss: 2.6057 Acc: 0.3283\n","valid Loss: 3.1842 Acc: 0.3802\n","\n","Epoch 4/26\n","----------\n","train Loss: 2.3121 Acc: 0.3898\n","valid Loss: 2.2296 Acc: 0.4108\n","\n","Epoch 5/26\n","----------\n","train Loss: 2.0517 Acc: 0.4504\n","valid Loss: 2.0417 Acc: 0.5122\n","\n","Epoch 6/26\n","----------\n","train Loss: 1.8620 Acc: 0.5085\n","valid Loss: 1.8719 Acc: 0.5587\n","\n","Epoch 7/26\n","----------\n","train Loss: 1.6859 Acc: 0.5504\n","valid Loss: 1.5880 Acc: 0.6100\n","\n","Epoch 8/26\n","----------\n","train Loss: 1.5707 Acc: 0.5717\n","valid Loss: 2.3804 Acc: 0.6467\n","\n","Epoch 9/26\n","----------\n","train Loss: 1.4213 Acc: 0.6168\n","valid Loss: 2.1668 Acc: 0.6369\n","\n","Epoch 10/26\n","----------\n","train Loss: 1.3404 Acc: 0.6377\n","valid Loss: 1.1928 Acc: 0.7054\n","\n","Epoch 11/26\n","----------\n","train Loss: 1.1803 Acc: 0.6865\n","valid Loss: 1.1076 Acc: 0.7262\n","\n","Epoch 12/26\n","----------\n","train Loss: 1.0930 Acc: 0.7065\n","valid Loss: 1.0237 Acc: 0.7115\n","\n","Epoch 13/26\n","----------\n","train Loss: 0.9775 Acc: 0.7306\n","valid Loss: 0.9396 Acc: 0.7763\n","\n","Epoch 14/26\n","----------\n","train Loss: 0.9233 Acc: 0.7431\n","valid Loss: 0.8682 Acc: 0.7971\n","\n","Epoch 15/26\n","----------\n","train Loss: 0.8317 Acc: 0.7705\n","valid Loss: 0.9893 Acc: 0.7897\n","\n","Epoch 16/26\n","----------\n","train Loss: 0.7635 Acc: 0.7882\n","valid Loss: 1.4477 Acc: 0.8117\n","\n","Epoch 17/26\n","----------\n","train Loss: 0.7350 Acc: 0.8024\n","valid Loss: 2.1000 Acc: 0.7958\n","\n","Epoch 18/26\n","----------\n","train Loss: 0.6507 Acc: 0.8213\n","valid Loss: 0.9146 Acc: 0.8289\n","\n","Epoch 19/26\n","----------\n","train Loss: 0.6414 Acc: 0.8216\n","valid Loss: 0.6637 Acc: 0.8460\n","\n","Epoch 20/26\n","----------\n","train Loss: 0.5327 Acc: 0.8581\n","valid Loss: 0.5215 Acc: 0.8875\n","\n","Epoch 21/26\n","----------\n","train Loss: 0.4885 Acc: 0.8719\n","valid Loss: 0.5882 Acc: 0.8729\n","\n","Epoch 22/26\n","----------\n","train Loss: 0.4728 Acc: 0.8753\n","valid Loss: 0.6523 Acc: 0.8765\n","\n","Epoch 23/26\n","----------\n","train Loss: 0.4835 Acc: 0.8736\n","valid Loss: 0.8564 Acc: 0.8753\n","\n","Epoch 24/26\n","----------\n","train Loss: 0.4588 Acc: 0.8752\n","valid Loss: 0.8914 Acc: 0.8704\n","\n","Epoch 25/26\n","----------\n","train Loss: 0.4458 Acc: 0.8811\n","valid Loss: 0.6567 Acc: 0.8729\n","\n","Epoch 26/26\n","----------\n","train Loss: 0.4401 Acc: 0.8799\n","valid Loss: 0.6869 Acc: 0.8753\n","\n","Training complete in 190m 4s\n","Best val Acc: 0.887531\n"],"name":"stdout"}]},{"metadata":{"id":"o5tbnrqan_Lb","colab_type":"code","colab":{}},"cell_type":"code","source":["# Then unfreeze all layers\n","#for param in model_ft.parameters():\n","#    param.requires_grad = True  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"k0FIBuSmTw2T","colab_type":"code","colab":{}},"cell_type":"code","source":["# To view which layers are freeze and which layers are not freezed:#\n","#for name, child in model_ft.named_children():\n","#  for name_2, params in child.named_parameters():\n","#    print(name_2, params.requires_grad)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mkB0YGrVo_W2","colab_type":"code","colab":{}},"cell_type":"code","source":["#criterion = nn.CrossEntropyLoss()\n","# Observe that all parameters are being optimized\n","#optimizer_ft = optim.Adam(model_ft.parameters(),lr=0.001)\n","# Decay LR by a factor of 0.1 every 7 epochs\n","#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n","# Train and evaluate\n","#model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"56QxGVfrooPS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"b74cb38f-68e4-48bc-9966-9bd2d1be28aa","executionInfo":{"status":"ok","timestamp":1544176825154,"user_tz":-120,"elapsed":33,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}}},"cell_type":"code","source":["\"\"\"\n","# Generic function to display predictions for a few images\n","def visualize_model(model, num_images=6):\n","    was_training = model.training\n","    model.eval()\n","    images_so_far = 0\n","    fig = plt.figure()\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders[val_dir]):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for j in range(inputs.size()[0]):\n","                images_so_far += 1\n","                ax = plt.subplot(num_images//2, 2, images_so_far)\n","                ax.axis('off')\n","                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n","                imshow(inputs.cpu().data[j])\n","\n","                if images_so_far == num_images:\n","                    model.train(mode=was_training)\n","                    return\n","        model.train(mode=was_training)\n","\"\"\"        "],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n# Generic function to display predictions for a few images\\ndef visualize_model(model, num_images=6):\\n    was_training = model.training\\n    model.eval()\\n    images_so_far = 0\\n    fig = plt.figure()\\n\\n    with torch.no_grad():\\n        for i, (inputs, labels) in enumerate(dataloaders[val_dir]):\\n            inputs = inputs.to(device)\\n            labels = labels.to(device)\\n\\n            outputs = model(inputs)\\n            _, preds = torch.max(outputs, 1)\\n\\n            for j in range(inputs.size()[0]):\\n                images_so_far += 1\\n                ax = plt.subplot(num_images//2, 2, images_so_far)\\n                ax.axis('off')\\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\\n                imshow(inputs.cpu().data[j])\\n\\n                if images_so_far == num_images:\\n                    model.train(mode=was_training)\\n                    return\\n        model.train(mode=was_training)\\n\""]},"metadata":{"tags":[]},"execution_count":25}]},{"metadata":{"id":"B3dIzw68pvki","colab_type":"code","colab":{}},"cell_type":"code","source":["#visualize_model(model_ft)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iA-AzcBFqmaV","colab_type":"text"},"cell_type":"markdown","source":["ConvNet as fixed feature extractor: Training only the last fully connected layer\n","----------------------\n","Here, we need to freeze all the network except the final layer. We need\n","to set ``requires_grad == False`` to freeze the parameters so that the\n","gradients are not computed in ``backward()``.\n","\n","You can read more about this in the documentation\n","`here <http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__.\n","\n","\n"]},{"metadata":{"id":"7swiKQi6rUeI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":7956},"outputId":"08faca3d-ac14-4c82-b79b-e51e42cd424c","executionInfo":{"status":"ok","timestamp":1544176825476,"user_tz":-120,"elapsed":328,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}}},"cell_type":"code","source":["#Freeze all layers first\n","for param in model_ft.parameters():\n","    param.requires_grad = False\n","    \n","# Then unfreeze last classification layer only for feature extract\n","for param in model_ft.fc.parameters():\n","    param.requires_grad = True    \n","\n","    \n","# To view which layers are freeze and which layers are not freezed:\n","for name, child in model_ft.named_children():\n","  for name_2, params in child.named_parameters():\n","    print(name_2, params.requires_grad)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["weight False\n","weight False\n","bias False\n","0.conv1.weight False\n","0.bn1.weight False\n","0.bn1.bias False\n","0.conv2.weight False\n","0.bn2.weight False\n","0.bn2.bias False\n","0.conv3.weight False\n","0.bn3.weight False\n","0.bn3.bias False\n","0.downsample.0.weight False\n","0.downsample.1.weight False\n","0.downsample.1.bias False\n","1.conv1.weight False\n","1.bn1.weight False\n","1.bn1.bias False\n","1.conv2.weight False\n","1.bn2.weight False\n","1.bn2.bias False\n","1.conv3.weight False\n","1.bn3.weight False\n","1.bn3.bias False\n","2.conv1.weight False\n","2.bn1.weight False\n","2.bn1.bias False\n","2.conv2.weight False\n","2.bn2.weight False\n","2.bn2.bias False\n","2.conv3.weight False\n","2.bn3.weight False\n","2.bn3.bias False\n","0.conv1.weight False\n","0.bn1.weight False\n","0.bn1.bias False\n","0.conv2.weight False\n","0.bn2.weight False\n","0.bn2.bias False\n","0.conv3.weight False\n","0.bn3.weight False\n","0.bn3.bias False\n","0.downsample.0.weight False\n","0.downsample.1.weight False\n","0.downsample.1.bias False\n","1.conv1.weight False\n","1.bn1.weight False\n","1.bn1.bias False\n","1.conv2.weight False\n","1.bn2.weight False\n","1.bn2.bias False\n","1.conv3.weight False\n","1.bn3.weight False\n","1.bn3.bias False\n","2.conv1.weight False\n","2.bn1.weight False\n","2.bn1.bias False\n","2.conv2.weight False\n","2.bn2.weight False\n","2.bn2.bias False\n","2.conv3.weight False\n","2.bn3.weight False\n","2.bn3.bias False\n","3.conv1.weight False\n","3.bn1.weight False\n","3.bn1.bias False\n","3.conv2.weight False\n","3.bn2.weight False\n","3.bn2.bias False\n","3.conv3.weight False\n","3.bn3.weight False\n","3.bn3.bias False\n","4.conv1.weight False\n","4.bn1.weight False\n","4.bn1.bias False\n","4.conv2.weight False\n","4.bn2.weight False\n","4.bn2.bias False\n","4.conv3.weight False\n","4.bn3.weight False\n","4.bn3.bias False\n","5.conv1.weight False\n","5.bn1.weight False\n","5.bn1.bias False\n","5.conv2.weight False\n","5.bn2.weight False\n","5.bn2.bias False\n","5.conv3.weight False\n","5.bn3.weight False\n","5.bn3.bias False\n","6.conv1.weight False\n","6.bn1.weight False\n","6.bn1.bias False\n","6.conv2.weight False\n","6.bn2.weight False\n","6.bn2.bias False\n","6.conv3.weight False\n","6.bn3.weight False\n","6.bn3.bias False\n","7.conv1.weight False\n","7.bn1.weight False\n","7.bn1.bias False\n","7.conv2.weight False\n","7.bn2.weight False\n","7.bn2.bias False\n","7.conv3.weight False\n","7.bn3.weight False\n","7.bn3.bias False\n","0.conv1.weight False\n","0.bn1.weight False\n","0.bn1.bias False\n","0.conv2.weight False\n","0.bn2.weight False\n","0.bn2.bias False\n","0.conv3.weight False\n","0.bn3.weight False\n","0.bn3.bias False\n","0.downsample.0.weight False\n","0.downsample.1.weight False\n","0.downsample.1.bias False\n","1.conv1.weight False\n","1.bn1.weight False\n","1.bn1.bias False\n","1.conv2.weight False\n","1.bn2.weight False\n","1.bn2.bias False\n","1.conv3.weight False\n","1.bn3.weight False\n","1.bn3.bias False\n","2.conv1.weight False\n","2.bn1.weight False\n","2.bn1.bias False\n","2.conv2.weight False\n","2.bn2.weight False\n","2.bn2.bias False\n","2.conv3.weight False\n","2.bn3.weight False\n","2.bn3.bias False\n","3.conv1.weight False\n","3.bn1.weight False\n","3.bn1.bias False\n","3.conv2.weight False\n","3.bn2.weight False\n","3.bn2.bias False\n","3.conv3.weight False\n","3.bn3.weight False\n","3.bn3.bias False\n","4.conv1.weight False\n","4.bn1.weight False\n","4.bn1.bias False\n","4.conv2.weight False\n","4.bn2.weight False\n","4.bn2.bias False\n","4.conv3.weight False\n","4.bn3.weight False\n","4.bn3.bias False\n","5.conv1.weight False\n","5.bn1.weight False\n","5.bn1.bias False\n","5.conv2.weight False\n","5.bn2.weight False\n","5.bn2.bias False\n","5.conv3.weight False\n","5.bn3.weight False\n","5.bn3.bias False\n","6.conv1.weight False\n","6.bn1.weight False\n","6.bn1.bias False\n","6.conv2.weight False\n","6.bn2.weight False\n","6.bn2.bias False\n","6.conv3.weight False\n","6.bn3.weight False\n","6.bn3.bias False\n","7.conv1.weight False\n","7.bn1.weight False\n","7.bn1.bias False\n","7.conv2.weight False\n","7.bn2.weight False\n","7.bn2.bias False\n","7.conv3.weight False\n","7.bn3.weight False\n","7.bn3.bias False\n","8.conv1.weight False\n","8.bn1.weight False\n","8.bn1.bias False\n","8.conv2.weight False\n","8.bn2.weight False\n","8.bn2.bias False\n","8.conv3.weight False\n","8.bn3.weight False\n","8.bn3.bias False\n","9.conv1.weight False\n","9.bn1.weight False\n","9.bn1.bias False\n","9.conv2.weight False\n","9.bn2.weight False\n","9.bn2.bias False\n","9.conv3.weight False\n","9.bn3.weight False\n","9.bn3.bias False\n","10.conv1.weight False\n","10.bn1.weight False\n","10.bn1.bias False\n","10.conv2.weight False\n","10.bn2.weight False\n","10.bn2.bias False\n","10.conv3.weight False\n","10.bn3.weight False\n","10.bn3.bias False\n","11.conv1.weight False\n","11.bn1.weight False\n","11.bn1.bias False\n","11.conv2.weight False\n","11.bn2.weight False\n","11.bn2.bias False\n","11.conv3.weight False\n","11.bn3.weight False\n","11.bn3.bias False\n","12.conv1.weight False\n","12.bn1.weight False\n","12.bn1.bias False\n","12.conv2.weight False\n","12.bn2.weight False\n","12.bn2.bias False\n","12.conv3.weight False\n","12.bn3.weight False\n","12.bn3.bias False\n","13.conv1.weight False\n","13.bn1.weight False\n","13.bn1.bias False\n","13.conv2.weight False\n","13.bn2.weight False\n","13.bn2.bias False\n","13.conv3.weight False\n","13.bn3.weight False\n","13.bn3.bias False\n","14.conv1.weight False\n","14.bn1.weight False\n","14.bn1.bias False\n","14.conv2.weight False\n","14.bn2.weight False\n","14.bn2.bias False\n","14.conv3.weight False\n","14.bn3.weight False\n","14.bn3.bias False\n","15.conv1.weight False\n","15.bn1.weight False\n","15.bn1.bias False\n","15.conv2.weight False\n","15.bn2.weight False\n","15.bn2.bias False\n","15.conv3.weight False\n","15.bn3.weight False\n","15.bn3.bias False\n","16.conv1.weight False\n","16.bn1.weight False\n","16.bn1.bias False\n","16.conv2.weight False\n","16.bn2.weight False\n","16.bn2.bias False\n","16.conv3.weight False\n","16.bn3.weight False\n","16.bn3.bias False\n","17.conv1.weight False\n","17.bn1.weight False\n","17.bn1.bias False\n","17.conv2.weight False\n","17.bn2.weight False\n","17.bn2.bias False\n","17.conv3.weight False\n","17.bn3.weight False\n","17.bn3.bias False\n","18.conv1.weight False\n","18.bn1.weight False\n","18.bn1.bias False\n","18.conv2.weight False\n","18.bn2.weight False\n","18.bn2.bias False\n","18.conv3.weight False\n","18.bn3.weight False\n","18.bn3.bias False\n","19.conv1.weight False\n","19.bn1.weight False\n","19.bn1.bias False\n","19.conv2.weight False\n","19.bn2.weight False\n","19.bn2.bias False\n","19.conv3.weight False\n","19.bn3.weight False\n","19.bn3.bias False\n","20.conv1.weight False\n","20.bn1.weight False\n","20.bn1.bias False\n","20.conv2.weight False\n","20.bn2.weight False\n","20.bn2.bias False\n","20.conv3.weight False\n","20.bn3.weight False\n","20.bn3.bias False\n","21.conv1.weight False\n","21.bn1.weight False\n","21.bn1.bias False\n","21.conv2.weight False\n","21.bn2.weight False\n","21.bn2.bias False\n","21.conv3.weight False\n","21.bn3.weight False\n","21.bn3.bias False\n","22.conv1.weight False\n","22.bn1.weight False\n","22.bn1.bias False\n","22.conv2.weight False\n","22.bn2.weight False\n","22.bn2.bias False\n","22.conv3.weight False\n","22.bn3.weight False\n","22.bn3.bias False\n","23.conv1.weight False\n","23.bn1.weight False\n","23.bn1.bias False\n","23.conv2.weight False\n","23.bn2.weight False\n","23.bn2.bias False\n","23.conv3.weight False\n","23.bn3.weight False\n","23.bn3.bias False\n","24.conv1.weight False\n","24.bn1.weight False\n","24.bn1.bias False\n","24.conv2.weight False\n","24.bn2.weight False\n","24.bn2.bias False\n","24.conv3.weight False\n","24.bn3.weight False\n","24.bn3.bias False\n","25.conv1.weight False\n","25.bn1.weight False\n","25.bn1.bias False\n","25.conv2.weight False\n","25.bn2.weight False\n","25.bn2.bias False\n","25.conv3.weight False\n","25.bn3.weight False\n","25.bn3.bias False\n","26.conv1.weight False\n","26.bn1.weight False\n","26.bn1.bias False\n","26.conv2.weight False\n","26.bn2.weight False\n","26.bn2.bias False\n","26.conv3.weight False\n","26.bn3.weight False\n","26.bn3.bias False\n","27.conv1.weight False\n","27.bn1.weight False\n","27.bn1.bias False\n","27.conv2.weight False\n","27.bn2.weight False\n","27.bn2.bias False\n","27.conv3.weight False\n","27.bn3.weight False\n","27.bn3.bias False\n","28.conv1.weight False\n","28.bn1.weight False\n","28.bn1.bias False\n","28.conv2.weight False\n","28.bn2.weight False\n","28.bn2.bias False\n","28.conv3.weight False\n","28.bn3.weight False\n","28.bn3.bias False\n","29.conv1.weight False\n","29.bn1.weight False\n","29.bn1.bias False\n","29.conv2.weight False\n","29.bn2.weight False\n","29.bn2.bias False\n","29.conv3.weight False\n","29.bn3.weight False\n","29.bn3.bias False\n","30.conv1.weight False\n","30.bn1.weight False\n","30.bn1.bias False\n","30.conv2.weight False\n","30.bn2.weight False\n","30.bn2.bias False\n","30.conv3.weight False\n","30.bn3.weight False\n","30.bn3.bias False\n","31.conv1.weight False\n","31.bn1.weight False\n","31.bn1.bias False\n","31.conv2.weight False\n","31.bn2.weight False\n","31.bn2.bias False\n","31.conv3.weight False\n","31.bn3.weight False\n","31.bn3.bias False\n","32.conv1.weight False\n","32.bn1.weight False\n","32.bn1.bias False\n","32.conv2.weight False\n","32.bn2.weight False\n","32.bn2.bias False\n","32.conv3.weight False\n","32.bn3.weight False\n","32.bn3.bias False\n","33.conv1.weight False\n","33.bn1.weight False\n","33.bn1.bias False\n","33.conv2.weight False\n","33.bn2.weight False\n","33.bn2.bias False\n","33.conv3.weight False\n","33.bn3.weight False\n","33.bn3.bias False\n","34.conv1.weight False\n","34.bn1.weight False\n","34.bn1.bias False\n","34.conv2.weight False\n","34.bn2.weight False\n","34.bn2.bias False\n","34.conv3.weight False\n","34.bn3.weight False\n","34.bn3.bias False\n","35.conv1.weight False\n","35.bn1.weight False\n","35.bn1.bias False\n","35.conv2.weight False\n","35.bn2.weight False\n","35.bn2.bias False\n","35.conv3.weight False\n","35.bn3.weight False\n","35.bn3.bias False\n","0.conv1.weight False\n","0.bn1.weight False\n","0.bn1.bias False\n","0.conv2.weight False\n","0.bn2.weight False\n","0.bn2.bias False\n","0.conv3.weight False\n","0.bn3.weight False\n","0.bn3.bias False\n","0.downsample.0.weight False\n","0.downsample.1.weight False\n","0.downsample.1.bias False\n","1.conv1.weight False\n","1.bn1.weight False\n","1.bn1.bias False\n","1.conv2.weight False\n","1.bn2.weight False\n","1.bn2.bias False\n","1.conv3.weight False\n","1.bn3.weight False\n","1.bn3.bias False\n","2.conv1.weight False\n","2.bn1.weight False\n","2.bn1.bias False\n","2.conv2.weight False\n","2.bn2.weight False\n","2.bn2.bias False\n","2.conv3.weight False\n","2.bn3.weight False\n","2.bn3.bias False\n","weight True\n","bias True\n"],"name":"stdout"}]},{"metadata":{"id":"32aVznr8rdQF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":816},"outputId":"00c047b7-cc66-41c6-fd15-b6033908cc37","executionInfo":{"status":"ok","timestamp":1544179620308,"user_tz":-120,"elapsed":1475860,"user":{"displayName":"Remis Norvilis","photoUrl":"","userId":"11201126552541546565"}}},"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","# Decay LR by a factor of 0.1 every 7 epochs\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n","# Observe that all parameters are being optimized\n","#optimizer_ft = optim.Adam(model_ft.parameters(),lr=0.001,amsgrad=True)\n","optimizer_ft = optim.Adagrad(model_ft.parameters(),lr=0.001,lr_decay=0.0001)\n","#train\n","model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=9)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Epoch 0/8\n","----------\n","train Loss: 0.4350 Acc: 0.8777\n","valid Loss: 0.6525 Acc: 0.8790\n","\n","Epoch 1/8\n","----------\n","train Loss: 0.4259 Acc: 0.8793\n","valid Loss: 0.7185 Acc: 0.8802\n","\n","Epoch 2/8\n","----------\n","train Loss: 0.4251 Acc: 0.8817\n","valid Loss: 0.8072 Acc: 0.8863\n","\n","Epoch 3/8\n","----------\n","train Loss: 0.4276 Acc: 0.8837\n","valid Loss: 0.7578 Acc: 0.8765\n","\n","Epoch 4/8\n","----------\n","train Loss: 0.4335 Acc: 0.8756\n","valid Loss: 0.6761 Acc: 0.8875\n","\n","Epoch 5/8\n","----------\n","train Loss: 0.4195 Acc: 0.8852\n","valid Loss: 0.8384 Acc: 0.8619\n","\n","Epoch 6/8\n","----------\n","train Loss: 0.4447 Acc: 0.8797\n","valid Loss: 0.6950 Acc: 0.8741\n","\n","Epoch 7/8\n","----------\n","train Loss: 0.4483 Acc: 0.8762\n","valid Loss: 0.5868 Acc: 0.8778\n","\n","Epoch 8/8\n","----------\n","train Loss: 0.4192 Acc: 0.8790\n","valid Loss: 0.8325 Acc: 0.8704\n","\n","Training complete in 24m 35s\n","Best val Acc: 0.887531\n"],"name":"stdout"}]},{"metadata":{"id":"2SZpPLHMrnvp","colab_type":"code","colab":{}},"cell_type":"code","source":["#visualize_model(model_conv)\n","\n","#plt.ioff()\n","#plt.show()"],"execution_count":0,"outputs":[]}]}