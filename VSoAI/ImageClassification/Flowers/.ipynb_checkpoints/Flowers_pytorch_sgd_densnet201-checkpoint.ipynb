{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0.dev20181207\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flowers_pytorch_sgd_densnet201.ipynb',\n",
       " 'projects',\n",
       " 'envML',\n",
       " 'data',\n",
       " 'Flowers_pytorch_sgd2.ipynb',\n",
       " 'Flowers_pytorch_sgd_topScore.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'Untitled.ipynb']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t\t      Flowers_pytorch_sgd_topScore.ipynb\r\n",
      "envML\t\t\t\t      projects\r\n",
      "Flowers_pytorch_sgd2.ipynb\t      Untitled.ipynb\r\n",
      "Flowers_pytorch_sgd_densnet201.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/flower_data/'\n",
    "PATH = data_dir\n",
    "\n",
    "train_dir = 'train'\n",
    "val_dir = 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Total Count:  102\n"
     ]
    }
   ],
   "source": [
    "# again, list total number of classes, and list them all\n",
    "# os.list dir sorting depends on OS dependent file indexing, so leaving it as it is\n",
    "\n",
    "classes = os.listdir(f'{data_dir}/{train_dir}')\n",
    "classes.sort()\n",
    "ClassesNumer = len(classes)\n",
    "print(\"Class Total Count: \", ClassesNumer)\n",
    "#print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_transforms = {\\n    train_dir: transforms.Compose([\\n        #transforms.Resize(224),\\n        transforms.RandomResizedCrop(224),\\n        transforms.RandomHorizontalFlip(),\\n        transforms.RandomVerticalFlip(),\\n        #transforms.RandomRotation(degrees=90),\\n        transforms.ToTensor(),\\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\\n       # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\\n    ]),\\n    val_dir: transforms.Compose([\\n        transforms.Resize(224),\\n        transforms.CenterCrop(224),\\n        transforms.ToTensor(),\\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\\n        #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\\n    ]),\\n}\\n'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "'''\n",
    "data_transforms = {\n",
    "    train_dir: transforms.Compose([\n",
    "        #transforms.Resize(224),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        #transforms.RandomRotation(degrees=90),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "       # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]),\n",
    "    val_dir: transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]),\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    # Train uses data augmentation\n",
    "    train_dir:\n",
    "        transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256),\n",
    "        #transforms.Resize(size=224),\n",
    "        #transforms.RandomRotation(degrees=90),\n",
    "        #transforms.RandomRotation(degrees=30),\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        #transforms.ColorJitter(0.4, 0.4, 0.4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomVerticalFlip(),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    val_dir:\n",
    "        transforms.Compose([\n",
    "        #transforms.Resize(size=256),\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),data_transforms[x]) for x in [train_dir, val_dir]}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=8) for x in [train_dir, val_dir]}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [train_dir, val_dir]}\n",
    "\n",
    "class_names = image_datasets[train_dir].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <torch.utils.data.dataloader.DataLoader object at 0x7fd2e4eb9c88>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7fd2e4eb9b00>}\n",
      "{'train': 6551, 'valid': 818}\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(dataloaders)\n",
    "print(dataset_sizes)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 6551\n",
      "    Root Location: data/flower_data/train\n",
      "    Transforms (if any): Compose(\n",
      "                             RandomResizedCrop(size=(256, 256), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
      "                             RandomRotation(degrees=(-45, 45), resample=False, expand=False)\n",
      "                             RandomHorizontalFlip(p=0.5)\n",
      "                             CenterCrop(size=(224, 224))\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "print(image_datasets[train_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('lr{}, Epoch {}/{}'.format(scheduler.get_lr(),epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [train_dir, val_dir]:\n",
    "            if phase == train_dir:\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == train_dir):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == train_dir:\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == val_dir and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and reset final fully connected layer\n",
    "\n",
    "model_ft = models.densenet201(pretrained=True)\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, ClassesNumer)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(),lr=1e-4,amsgrad=True)\n",
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every ? epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer33): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer34): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer35): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer36): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer37): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer38): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer39): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer40): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer41): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer42): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer43): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer44): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer45): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer46): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer47): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer48): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1920, out_features=102, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv0.weight False\n",
      "norm0.weight False\n",
      "norm0.bias False\n",
      "denseblock1.denselayer1.norm1.weight False\n",
      "denseblock1.denselayer1.norm1.bias False\n",
      "denseblock1.denselayer1.conv1.weight False\n",
      "denseblock1.denselayer1.norm2.weight False\n",
      "denseblock1.denselayer1.norm2.bias False\n",
      "denseblock1.denselayer1.conv2.weight False\n",
      "denseblock1.denselayer2.norm1.weight False\n",
      "denseblock1.denselayer2.norm1.bias False\n",
      "denseblock1.denselayer2.conv1.weight False\n",
      "denseblock1.denselayer2.norm2.weight False\n",
      "denseblock1.denselayer2.norm2.bias False\n",
      "denseblock1.denselayer2.conv2.weight False\n",
      "denseblock1.denselayer3.norm1.weight False\n",
      "denseblock1.denselayer3.norm1.bias False\n",
      "denseblock1.denselayer3.conv1.weight False\n",
      "denseblock1.denselayer3.norm2.weight False\n",
      "denseblock1.denselayer3.norm2.bias False\n",
      "denseblock1.denselayer3.conv2.weight False\n",
      "denseblock1.denselayer4.norm1.weight False\n",
      "denseblock1.denselayer4.norm1.bias False\n",
      "denseblock1.denselayer4.conv1.weight False\n",
      "denseblock1.denselayer4.norm2.weight False\n",
      "denseblock1.denselayer4.norm2.bias False\n",
      "denseblock1.denselayer4.conv2.weight False\n",
      "denseblock1.denselayer5.norm1.weight False\n",
      "denseblock1.denselayer5.norm1.bias False\n",
      "denseblock1.denselayer5.conv1.weight False\n",
      "denseblock1.denselayer5.norm2.weight False\n",
      "denseblock1.denselayer5.norm2.bias False\n",
      "denseblock1.denselayer5.conv2.weight False\n",
      "denseblock1.denselayer6.norm1.weight False\n",
      "denseblock1.denselayer6.norm1.bias False\n",
      "denseblock1.denselayer6.conv1.weight False\n",
      "denseblock1.denselayer6.norm2.weight False\n",
      "denseblock1.denselayer6.norm2.bias False\n",
      "denseblock1.denselayer6.conv2.weight False\n",
      "transition1.norm.weight False\n",
      "transition1.norm.bias False\n",
      "transition1.conv.weight False\n",
      "denseblock2.denselayer1.norm1.weight False\n",
      "denseblock2.denselayer1.norm1.bias False\n",
      "denseblock2.denselayer1.conv1.weight False\n",
      "denseblock2.denselayer1.norm2.weight False\n",
      "denseblock2.denselayer1.norm2.bias False\n",
      "denseblock2.denselayer1.conv2.weight False\n",
      "denseblock2.denselayer2.norm1.weight False\n",
      "denseblock2.denselayer2.norm1.bias False\n",
      "denseblock2.denselayer2.conv1.weight False\n",
      "denseblock2.denselayer2.norm2.weight False\n",
      "denseblock2.denselayer2.norm2.bias False\n",
      "denseblock2.denselayer2.conv2.weight False\n",
      "denseblock2.denselayer3.norm1.weight False\n",
      "denseblock2.denselayer3.norm1.bias False\n",
      "denseblock2.denselayer3.conv1.weight False\n",
      "denseblock2.denselayer3.norm2.weight False\n",
      "denseblock2.denselayer3.norm2.bias False\n",
      "denseblock2.denselayer3.conv2.weight False\n",
      "denseblock2.denselayer4.norm1.weight False\n",
      "denseblock2.denselayer4.norm1.bias False\n",
      "denseblock2.denselayer4.conv1.weight False\n",
      "denseblock2.denselayer4.norm2.weight False\n",
      "denseblock2.denselayer4.norm2.bias False\n",
      "denseblock2.denselayer4.conv2.weight False\n",
      "denseblock2.denselayer5.norm1.weight False\n",
      "denseblock2.denselayer5.norm1.bias False\n",
      "denseblock2.denselayer5.conv1.weight False\n",
      "denseblock2.denselayer5.norm2.weight False\n",
      "denseblock2.denselayer5.norm2.bias False\n",
      "denseblock2.denselayer5.conv2.weight False\n",
      "denseblock2.denselayer6.norm1.weight False\n",
      "denseblock2.denselayer6.norm1.bias False\n",
      "denseblock2.denselayer6.conv1.weight False\n",
      "denseblock2.denselayer6.norm2.weight False\n",
      "denseblock2.denselayer6.norm2.bias False\n",
      "denseblock2.denselayer6.conv2.weight False\n",
      "denseblock2.denselayer7.norm1.weight False\n",
      "denseblock2.denselayer7.norm1.bias False\n",
      "denseblock2.denselayer7.conv1.weight False\n",
      "denseblock2.denselayer7.norm2.weight False\n",
      "denseblock2.denselayer7.norm2.bias False\n",
      "denseblock2.denselayer7.conv2.weight False\n",
      "denseblock2.denselayer8.norm1.weight False\n",
      "denseblock2.denselayer8.norm1.bias False\n",
      "denseblock2.denselayer8.conv1.weight False\n",
      "denseblock2.denselayer8.norm2.weight False\n",
      "denseblock2.denselayer8.norm2.bias False\n",
      "denseblock2.denselayer8.conv2.weight False\n",
      "denseblock2.denselayer9.norm1.weight False\n",
      "denseblock2.denselayer9.norm1.bias False\n",
      "denseblock2.denselayer9.conv1.weight False\n",
      "denseblock2.denselayer9.norm2.weight False\n",
      "denseblock2.denselayer9.norm2.bias False\n",
      "denseblock2.denselayer9.conv2.weight False\n",
      "denseblock2.denselayer10.norm1.weight False\n",
      "denseblock2.denselayer10.norm1.bias False\n",
      "denseblock2.denselayer10.conv1.weight False\n",
      "denseblock2.denselayer10.norm2.weight False\n",
      "denseblock2.denselayer10.norm2.bias False\n",
      "denseblock2.denselayer10.conv2.weight False\n",
      "denseblock2.denselayer11.norm1.weight False\n",
      "denseblock2.denselayer11.norm1.bias False\n",
      "denseblock2.denselayer11.conv1.weight False\n",
      "denseblock2.denselayer11.norm2.weight False\n",
      "denseblock2.denselayer11.norm2.bias False\n",
      "denseblock2.denselayer11.conv2.weight False\n",
      "denseblock2.denselayer12.norm1.weight False\n",
      "denseblock2.denselayer12.norm1.bias False\n",
      "denseblock2.denselayer12.conv1.weight False\n",
      "denseblock2.denselayer12.norm2.weight False\n",
      "denseblock2.denselayer12.norm2.bias False\n",
      "denseblock2.denselayer12.conv2.weight False\n",
      "transition2.norm.weight False\n",
      "transition2.norm.bias False\n",
      "transition2.conv.weight False\n",
      "denseblock3.denselayer1.norm1.weight False\n",
      "denseblock3.denselayer1.norm1.bias False\n",
      "denseblock3.denselayer1.conv1.weight False\n",
      "denseblock3.denselayer1.norm2.weight False\n",
      "denseblock3.denselayer1.norm2.bias False\n",
      "denseblock3.denselayer1.conv2.weight False\n",
      "denseblock3.denselayer2.norm1.weight False\n",
      "denseblock3.denselayer2.norm1.bias False\n",
      "denseblock3.denselayer2.conv1.weight False\n",
      "denseblock3.denselayer2.norm2.weight False\n",
      "denseblock3.denselayer2.norm2.bias False\n",
      "denseblock3.denselayer2.conv2.weight False\n",
      "denseblock3.denselayer3.norm1.weight False\n",
      "denseblock3.denselayer3.norm1.bias False\n",
      "denseblock3.denselayer3.conv1.weight False\n",
      "denseblock3.denselayer3.norm2.weight False\n",
      "denseblock3.denselayer3.norm2.bias False\n",
      "denseblock3.denselayer3.conv2.weight False\n",
      "denseblock3.denselayer4.norm1.weight False\n",
      "denseblock3.denselayer4.norm1.bias False\n",
      "denseblock3.denselayer4.conv1.weight False\n",
      "denseblock3.denselayer4.norm2.weight False\n",
      "denseblock3.denselayer4.norm2.bias False\n",
      "denseblock3.denselayer4.conv2.weight False\n",
      "denseblock3.denselayer5.norm1.weight False\n",
      "denseblock3.denselayer5.norm1.bias False\n",
      "denseblock3.denselayer5.conv1.weight False\n",
      "denseblock3.denselayer5.norm2.weight False\n",
      "denseblock3.denselayer5.norm2.bias False\n",
      "denseblock3.denselayer5.conv2.weight False\n",
      "denseblock3.denselayer6.norm1.weight False\n",
      "denseblock3.denselayer6.norm1.bias False\n",
      "denseblock3.denselayer6.conv1.weight False\n",
      "denseblock3.denselayer6.norm2.weight False\n",
      "denseblock3.denselayer6.norm2.bias False\n",
      "denseblock3.denselayer6.conv2.weight False\n",
      "denseblock3.denselayer7.norm1.weight False\n",
      "denseblock3.denselayer7.norm1.bias False\n",
      "denseblock3.denselayer7.conv1.weight False\n",
      "denseblock3.denselayer7.norm2.weight False\n",
      "denseblock3.denselayer7.norm2.bias False\n",
      "denseblock3.denselayer7.conv2.weight False\n",
      "denseblock3.denselayer8.norm1.weight False\n",
      "denseblock3.denselayer8.norm1.bias False\n",
      "denseblock3.denselayer8.conv1.weight False\n",
      "denseblock3.denselayer8.norm2.weight False\n",
      "denseblock3.denselayer8.norm2.bias False\n",
      "denseblock3.denselayer8.conv2.weight False\n",
      "denseblock3.denselayer9.norm1.weight False\n",
      "denseblock3.denselayer9.norm1.bias False\n",
      "denseblock3.denselayer9.conv1.weight False\n",
      "denseblock3.denselayer9.norm2.weight False\n",
      "denseblock3.denselayer9.norm2.bias False\n",
      "denseblock3.denselayer9.conv2.weight False\n",
      "denseblock3.denselayer10.norm1.weight False\n",
      "denseblock3.denselayer10.norm1.bias False\n",
      "denseblock3.denselayer10.conv1.weight False\n",
      "denseblock3.denselayer10.norm2.weight False\n",
      "denseblock3.denselayer10.norm2.bias False\n",
      "denseblock3.denselayer10.conv2.weight False\n",
      "denseblock3.denselayer11.norm1.weight False\n",
      "denseblock3.denselayer11.norm1.bias False\n",
      "denseblock3.denselayer11.conv1.weight False\n",
      "denseblock3.denselayer11.norm2.weight False\n",
      "denseblock3.denselayer11.norm2.bias False\n",
      "denseblock3.denselayer11.conv2.weight False\n",
      "denseblock3.denselayer12.norm1.weight False\n",
      "denseblock3.denselayer12.norm1.bias False\n",
      "denseblock3.denselayer12.conv1.weight False\n",
      "denseblock3.denselayer12.norm2.weight False\n",
      "denseblock3.denselayer12.norm2.bias False\n",
      "denseblock3.denselayer12.conv2.weight False\n",
      "denseblock3.denselayer13.norm1.weight False\n",
      "denseblock3.denselayer13.norm1.bias False\n",
      "denseblock3.denselayer13.conv1.weight False\n",
      "denseblock3.denselayer13.norm2.weight False\n",
      "denseblock3.denselayer13.norm2.bias False\n",
      "denseblock3.denselayer13.conv2.weight False\n",
      "denseblock3.denselayer14.norm1.weight False\n",
      "denseblock3.denselayer14.norm1.bias False\n",
      "denseblock3.denselayer14.conv1.weight False\n",
      "denseblock3.denselayer14.norm2.weight False\n",
      "denseblock3.denselayer14.norm2.bias False\n",
      "denseblock3.denselayer14.conv2.weight False\n",
      "denseblock3.denselayer15.norm1.weight False\n",
      "denseblock3.denselayer15.norm1.bias False\n",
      "denseblock3.denselayer15.conv1.weight False\n",
      "denseblock3.denselayer15.norm2.weight False\n",
      "denseblock3.denselayer15.norm2.bias False\n",
      "denseblock3.denselayer15.conv2.weight False\n",
      "denseblock3.denselayer16.norm1.weight False\n",
      "denseblock3.denselayer16.norm1.bias False\n",
      "denseblock3.denselayer16.conv1.weight False\n",
      "denseblock3.denselayer16.norm2.weight False\n",
      "denseblock3.denselayer16.norm2.bias False\n",
      "denseblock3.denselayer16.conv2.weight False\n",
      "denseblock3.denselayer17.norm1.weight False\n",
      "denseblock3.denselayer17.norm1.bias False\n",
      "denseblock3.denselayer17.conv1.weight False\n",
      "denseblock3.denselayer17.norm2.weight False\n",
      "denseblock3.denselayer17.norm2.bias False\n",
      "denseblock3.denselayer17.conv2.weight False\n",
      "denseblock3.denselayer18.norm1.weight False\n",
      "denseblock3.denselayer18.norm1.bias False\n",
      "denseblock3.denselayer18.conv1.weight False\n",
      "denseblock3.denselayer18.norm2.weight False\n",
      "denseblock3.denselayer18.norm2.bias False\n",
      "denseblock3.denselayer18.conv2.weight False\n",
      "denseblock3.denselayer19.norm1.weight False\n",
      "denseblock3.denselayer19.norm1.bias False\n",
      "denseblock3.denselayer19.conv1.weight False\n",
      "denseblock3.denselayer19.norm2.weight False\n",
      "denseblock3.denselayer19.norm2.bias False\n",
      "denseblock3.denselayer19.conv2.weight False\n",
      "denseblock3.denselayer20.norm1.weight False\n",
      "denseblock3.denselayer20.norm1.bias False\n",
      "denseblock3.denselayer20.conv1.weight False\n",
      "denseblock3.denselayer20.norm2.weight False\n",
      "denseblock3.denselayer20.norm2.bias False\n",
      "denseblock3.denselayer20.conv2.weight False\n",
      "denseblock3.denselayer21.norm1.weight False\n",
      "denseblock3.denselayer21.norm1.bias False\n",
      "denseblock3.denselayer21.conv1.weight False\n",
      "denseblock3.denselayer21.norm2.weight False\n",
      "denseblock3.denselayer21.norm2.bias False\n",
      "denseblock3.denselayer21.conv2.weight False\n",
      "denseblock3.denselayer22.norm1.weight False\n",
      "denseblock3.denselayer22.norm1.bias False\n",
      "denseblock3.denselayer22.conv1.weight False\n",
      "denseblock3.denselayer22.norm2.weight False\n",
      "denseblock3.denselayer22.norm2.bias False\n",
      "denseblock3.denselayer22.conv2.weight False\n",
      "denseblock3.denselayer23.norm1.weight False\n",
      "denseblock3.denselayer23.norm1.bias False\n",
      "denseblock3.denselayer23.conv1.weight False\n",
      "denseblock3.denselayer23.norm2.weight False\n",
      "denseblock3.denselayer23.norm2.bias False\n",
      "denseblock3.denselayer23.conv2.weight False\n",
      "denseblock3.denselayer24.norm1.weight False\n",
      "denseblock3.denselayer24.norm1.bias False\n",
      "denseblock3.denselayer24.conv1.weight False\n",
      "denseblock3.denselayer24.norm2.weight False\n",
      "denseblock3.denselayer24.norm2.bias False\n",
      "denseblock3.denselayer24.conv2.weight False\n",
      "denseblock3.denselayer25.norm1.weight False\n",
      "denseblock3.denselayer25.norm1.bias False\n",
      "denseblock3.denselayer25.conv1.weight False\n",
      "denseblock3.denselayer25.norm2.weight False\n",
      "denseblock3.denselayer25.norm2.bias False\n",
      "denseblock3.denselayer25.conv2.weight False\n",
      "denseblock3.denselayer26.norm1.weight False\n",
      "denseblock3.denselayer26.norm1.bias False\n",
      "denseblock3.denselayer26.conv1.weight False\n",
      "denseblock3.denselayer26.norm2.weight False\n",
      "denseblock3.denselayer26.norm2.bias False\n",
      "denseblock3.denselayer26.conv2.weight False\n",
      "denseblock3.denselayer27.norm1.weight False\n",
      "denseblock3.denselayer27.norm1.bias False\n",
      "denseblock3.denselayer27.conv1.weight False\n",
      "denseblock3.denselayer27.norm2.weight False\n",
      "denseblock3.denselayer27.norm2.bias False\n",
      "denseblock3.denselayer27.conv2.weight False\n",
      "denseblock3.denselayer28.norm1.weight False\n",
      "denseblock3.denselayer28.norm1.bias False\n",
      "denseblock3.denselayer28.conv1.weight False\n",
      "denseblock3.denselayer28.norm2.weight False\n",
      "denseblock3.denselayer28.norm2.bias False\n",
      "denseblock3.denselayer28.conv2.weight False\n",
      "denseblock3.denselayer29.norm1.weight False\n",
      "denseblock3.denselayer29.norm1.bias False\n",
      "denseblock3.denselayer29.conv1.weight False\n",
      "denseblock3.denselayer29.norm2.weight False\n",
      "denseblock3.denselayer29.norm2.bias False\n",
      "denseblock3.denselayer29.conv2.weight False\n",
      "denseblock3.denselayer30.norm1.weight False\n",
      "denseblock3.denselayer30.norm1.bias False\n",
      "denseblock3.denselayer30.conv1.weight False\n",
      "denseblock3.denselayer30.norm2.weight False\n",
      "denseblock3.denselayer30.norm2.bias False\n",
      "denseblock3.denselayer30.conv2.weight False\n",
      "denseblock3.denselayer31.norm1.weight False\n",
      "denseblock3.denselayer31.norm1.bias False\n",
      "denseblock3.denselayer31.conv1.weight False\n",
      "denseblock3.denselayer31.norm2.weight False\n",
      "denseblock3.denselayer31.norm2.bias False\n",
      "denseblock3.denselayer31.conv2.weight False\n",
      "denseblock3.denselayer32.norm1.weight False\n",
      "denseblock3.denselayer32.norm1.bias False\n",
      "denseblock3.denselayer32.conv1.weight False\n",
      "denseblock3.denselayer32.norm2.weight False\n",
      "denseblock3.denselayer32.norm2.bias False\n",
      "denseblock3.denselayer32.conv2.weight False\n",
      "denseblock3.denselayer33.norm1.weight False\n",
      "denseblock3.denselayer33.norm1.bias False\n",
      "denseblock3.denselayer33.conv1.weight False\n",
      "denseblock3.denselayer33.norm2.weight False\n",
      "denseblock3.denselayer33.norm2.bias False\n",
      "denseblock3.denselayer33.conv2.weight False\n",
      "denseblock3.denselayer34.norm1.weight False\n",
      "denseblock3.denselayer34.norm1.bias False\n",
      "denseblock3.denselayer34.conv1.weight False\n",
      "denseblock3.denselayer34.norm2.weight False\n",
      "denseblock3.denselayer34.norm2.bias False\n",
      "denseblock3.denselayer34.conv2.weight False\n",
      "denseblock3.denselayer35.norm1.weight False\n",
      "denseblock3.denselayer35.norm1.bias False\n",
      "denseblock3.denselayer35.conv1.weight False\n",
      "denseblock3.denselayer35.norm2.weight False\n",
      "denseblock3.denselayer35.norm2.bias False\n",
      "denseblock3.denselayer35.conv2.weight False\n",
      "denseblock3.denselayer36.norm1.weight False\n",
      "denseblock3.denselayer36.norm1.bias False\n",
      "denseblock3.denselayer36.conv1.weight False\n",
      "denseblock3.denselayer36.norm2.weight False\n",
      "denseblock3.denselayer36.norm2.bias False\n",
      "denseblock3.denselayer36.conv2.weight False\n",
      "denseblock3.denselayer37.norm1.weight False\n",
      "denseblock3.denselayer37.norm1.bias False\n",
      "denseblock3.denselayer37.conv1.weight False\n",
      "denseblock3.denselayer37.norm2.weight False\n",
      "denseblock3.denselayer37.norm2.bias False\n",
      "denseblock3.denselayer37.conv2.weight False\n",
      "denseblock3.denselayer38.norm1.weight False\n",
      "denseblock3.denselayer38.norm1.bias False\n",
      "denseblock3.denselayer38.conv1.weight False\n",
      "denseblock3.denselayer38.norm2.weight False\n",
      "denseblock3.denselayer38.norm2.bias False\n",
      "denseblock3.denselayer38.conv2.weight False\n",
      "denseblock3.denselayer39.norm1.weight False\n",
      "denseblock3.denselayer39.norm1.bias False\n",
      "denseblock3.denselayer39.conv1.weight False\n",
      "denseblock3.denselayer39.norm2.weight False\n",
      "denseblock3.denselayer39.norm2.bias False\n",
      "denseblock3.denselayer39.conv2.weight False\n",
      "denseblock3.denselayer40.norm1.weight False\n",
      "denseblock3.denselayer40.norm1.bias False\n",
      "denseblock3.denselayer40.conv1.weight False\n",
      "denseblock3.denselayer40.norm2.weight False\n",
      "denseblock3.denselayer40.norm2.bias False\n",
      "denseblock3.denselayer40.conv2.weight False\n",
      "denseblock3.denselayer41.norm1.weight False\n",
      "denseblock3.denselayer41.norm1.bias False\n",
      "denseblock3.denselayer41.conv1.weight False\n",
      "denseblock3.denselayer41.norm2.weight False\n",
      "denseblock3.denselayer41.norm2.bias False\n",
      "denseblock3.denselayer41.conv2.weight False\n",
      "denseblock3.denselayer42.norm1.weight False\n",
      "denseblock3.denselayer42.norm1.bias False\n",
      "denseblock3.denselayer42.conv1.weight False\n",
      "denseblock3.denselayer42.norm2.weight False\n",
      "denseblock3.denselayer42.norm2.bias False\n",
      "denseblock3.denselayer42.conv2.weight False\n",
      "denseblock3.denselayer43.norm1.weight False\n",
      "denseblock3.denselayer43.norm1.bias False\n",
      "denseblock3.denselayer43.conv1.weight False\n",
      "denseblock3.denselayer43.norm2.weight False\n",
      "denseblock3.denselayer43.norm2.bias False\n",
      "denseblock3.denselayer43.conv2.weight False\n",
      "denseblock3.denselayer44.norm1.weight False\n",
      "denseblock3.denselayer44.norm1.bias False\n",
      "denseblock3.denselayer44.conv1.weight False\n",
      "denseblock3.denselayer44.norm2.weight False\n",
      "denseblock3.denselayer44.norm2.bias False\n",
      "denseblock3.denselayer44.conv2.weight False\n",
      "denseblock3.denselayer45.norm1.weight False\n",
      "denseblock3.denselayer45.norm1.bias False\n",
      "denseblock3.denselayer45.conv1.weight False\n",
      "denseblock3.denselayer45.norm2.weight False\n",
      "denseblock3.denselayer45.norm2.bias False\n",
      "denseblock3.denselayer45.conv2.weight False\n",
      "denseblock3.denselayer46.norm1.weight False\n",
      "denseblock3.denselayer46.norm1.bias False\n",
      "denseblock3.denselayer46.conv1.weight False\n",
      "denseblock3.denselayer46.norm2.weight False\n",
      "denseblock3.denselayer46.norm2.bias False\n",
      "denseblock3.denselayer46.conv2.weight False\n",
      "denseblock3.denselayer47.norm1.weight False\n",
      "denseblock3.denselayer47.norm1.bias False\n",
      "denseblock3.denselayer47.conv1.weight False\n",
      "denseblock3.denselayer47.norm2.weight False\n",
      "denseblock3.denselayer47.norm2.bias False\n",
      "denseblock3.denselayer47.conv2.weight False\n",
      "denseblock3.denselayer48.norm1.weight False\n",
      "denseblock3.denselayer48.norm1.bias False\n",
      "denseblock3.denselayer48.conv1.weight False\n",
      "denseblock3.denselayer48.norm2.weight False\n",
      "denseblock3.denselayer48.norm2.bias False\n",
      "denseblock3.denselayer48.conv2.weight False\n",
      "transition3.norm.weight False\n",
      "transition3.norm.bias False\n",
      "transition3.conv.weight False\n",
      "denseblock4.denselayer1.norm1.weight False\n",
      "denseblock4.denselayer1.norm1.bias False\n",
      "denseblock4.denselayer1.conv1.weight False\n",
      "denseblock4.denselayer1.norm2.weight False\n",
      "denseblock4.denselayer1.norm2.bias False\n",
      "denseblock4.denselayer1.conv2.weight False\n",
      "denseblock4.denselayer2.norm1.weight False\n",
      "denseblock4.denselayer2.norm1.bias False\n",
      "denseblock4.denselayer2.conv1.weight False\n",
      "denseblock4.denselayer2.norm2.weight False\n",
      "denseblock4.denselayer2.norm2.bias False\n",
      "denseblock4.denselayer2.conv2.weight False\n",
      "denseblock4.denselayer3.norm1.weight False\n",
      "denseblock4.denselayer3.norm1.bias False\n",
      "denseblock4.denselayer3.conv1.weight False\n",
      "denseblock4.denselayer3.norm2.weight False\n",
      "denseblock4.denselayer3.norm2.bias False\n",
      "denseblock4.denselayer3.conv2.weight False\n",
      "denseblock4.denselayer4.norm1.weight False\n",
      "denseblock4.denselayer4.norm1.bias False\n",
      "denseblock4.denselayer4.conv1.weight False\n",
      "denseblock4.denselayer4.norm2.weight False\n",
      "denseblock4.denselayer4.norm2.bias False\n",
      "denseblock4.denselayer4.conv2.weight False\n",
      "denseblock4.denselayer5.norm1.weight False\n",
      "denseblock4.denselayer5.norm1.bias False\n",
      "denseblock4.denselayer5.conv1.weight False\n",
      "denseblock4.denselayer5.norm2.weight False\n",
      "denseblock4.denselayer5.norm2.bias False\n",
      "denseblock4.denselayer5.conv2.weight False\n",
      "denseblock4.denselayer6.norm1.weight False\n",
      "denseblock4.denselayer6.norm1.bias False\n",
      "denseblock4.denselayer6.conv1.weight False\n",
      "denseblock4.denselayer6.norm2.weight False\n",
      "denseblock4.denselayer6.norm2.bias False\n",
      "denseblock4.denselayer6.conv2.weight False\n",
      "denseblock4.denselayer7.norm1.weight False\n",
      "denseblock4.denselayer7.norm1.bias False\n",
      "denseblock4.denselayer7.conv1.weight False\n",
      "denseblock4.denselayer7.norm2.weight False\n",
      "denseblock4.denselayer7.norm2.bias False\n",
      "denseblock4.denselayer7.conv2.weight False\n",
      "denseblock4.denselayer8.norm1.weight False\n",
      "denseblock4.denselayer8.norm1.bias False\n",
      "denseblock4.denselayer8.conv1.weight False\n",
      "denseblock4.denselayer8.norm2.weight False\n",
      "denseblock4.denselayer8.norm2.bias False\n",
      "denseblock4.denselayer8.conv2.weight False\n",
      "denseblock4.denselayer9.norm1.weight False\n",
      "denseblock4.denselayer9.norm1.bias False\n",
      "denseblock4.denselayer9.conv1.weight False\n",
      "denseblock4.denselayer9.norm2.weight False\n",
      "denseblock4.denselayer9.norm2.bias False\n",
      "denseblock4.denselayer9.conv2.weight False\n",
      "denseblock4.denselayer10.norm1.weight False\n",
      "denseblock4.denselayer10.norm1.bias False\n",
      "denseblock4.denselayer10.conv1.weight False\n",
      "denseblock4.denselayer10.norm2.weight False\n",
      "denseblock4.denselayer10.norm2.bias False\n",
      "denseblock4.denselayer10.conv2.weight False\n",
      "denseblock4.denselayer11.norm1.weight False\n",
      "denseblock4.denselayer11.norm1.bias False\n",
      "denseblock4.denselayer11.conv1.weight False\n",
      "denseblock4.denselayer11.norm2.weight False\n",
      "denseblock4.denselayer11.norm2.bias False\n",
      "denseblock4.denselayer11.conv2.weight False\n",
      "denseblock4.denselayer12.norm1.weight False\n",
      "denseblock4.denselayer12.norm1.bias False\n",
      "denseblock4.denselayer12.conv1.weight False\n",
      "denseblock4.denselayer12.norm2.weight False\n",
      "denseblock4.denselayer12.norm2.bias False\n",
      "denseblock4.denselayer12.conv2.weight False\n",
      "denseblock4.denselayer13.norm1.weight False\n",
      "denseblock4.denselayer13.norm1.bias False\n",
      "denseblock4.denselayer13.conv1.weight False\n",
      "denseblock4.denselayer13.norm2.weight False\n",
      "denseblock4.denselayer13.norm2.bias False\n",
      "denseblock4.denselayer13.conv2.weight False\n",
      "denseblock4.denselayer14.norm1.weight False\n",
      "denseblock4.denselayer14.norm1.bias False\n",
      "denseblock4.denselayer14.conv1.weight False\n",
      "denseblock4.denselayer14.norm2.weight False\n",
      "denseblock4.denselayer14.norm2.bias False\n",
      "denseblock4.denselayer14.conv2.weight False\n",
      "denseblock4.denselayer15.norm1.weight False\n",
      "denseblock4.denselayer15.norm1.bias False\n",
      "denseblock4.denselayer15.conv1.weight False\n",
      "denseblock4.denselayer15.norm2.weight False\n",
      "denseblock4.denselayer15.norm2.bias False\n",
      "denseblock4.denselayer15.conv2.weight False\n",
      "denseblock4.denselayer16.norm1.weight False\n",
      "denseblock4.denselayer16.norm1.bias False\n",
      "denseblock4.denselayer16.conv1.weight False\n",
      "denseblock4.denselayer16.norm2.weight False\n",
      "denseblock4.denselayer16.norm2.bias False\n",
      "denseblock4.denselayer16.conv2.weight False\n",
      "denseblock4.denselayer17.norm1.weight False\n",
      "denseblock4.denselayer17.norm1.bias False\n",
      "denseblock4.denselayer17.conv1.weight False\n",
      "denseblock4.denselayer17.norm2.weight False\n",
      "denseblock4.denselayer17.norm2.bias False\n",
      "denseblock4.denselayer17.conv2.weight False\n",
      "denseblock4.denselayer18.norm1.weight False\n",
      "denseblock4.denselayer18.norm1.bias False\n",
      "denseblock4.denselayer18.conv1.weight False\n",
      "denseblock4.denselayer18.norm2.weight False\n",
      "denseblock4.denselayer18.norm2.bias False\n",
      "denseblock4.denselayer18.conv2.weight False\n",
      "denseblock4.denselayer19.norm1.weight False\n",
      "denseblock4.denselayer19.norm1.bias False\n",
      "denseblock4.denselayer19.conv1.weight False\n",
      "denseblock4.denselayer19.norm2.weight False\n",
      "denseblock4.denselayer19.norm2.bias False\n",
      "denseblock4.denselayer19.conv2.weight False\n",
      "denseblock4.denselayer20.norm1.weight False\n",
      "denseblock4.denselayer20.norm1.bias False\n",
      "denseblock4.denselayer20.conv1.weight False\n",
      "denseblock4.denselayer20.norm2.weight False\n",
      "denseblock4.denselayer20.norm2.bias False\n",
      "denseblock4.denselayer20.conv2.weight False\n",
      "denseblock4.denselayer21.norm1.weight False\n",
      "denseblock4.denselayer21.norm1.bias False\n",
      "denseblock4.denselayer21.conv1.weight False\n",
      "denseblock4.denselayer21.norm2.weight False\n",
      "denseblock4.denselayer21.norm2.bias False\n",
      "denseblock4.denselayer21.conv2.weight False\n",
      "denseblock4.denselayer22.norm1.weight False\n",
      "denseblock4.denselayer22.norm1.bias False\n",
      "denseblock4.denselayer22.conv1.weight False\n",
      "denseblock4.denselayer22.norm2.weight False\n",
      "denseblock4.denselayer22.norm2.bias False\n",
      "denseblock4.denselayer22.conv2.weight False\n",
      "denseblock4.denselayer23.norm1.weight False\n",
      "denseblock4.denselayer23.norm1.bias False\n",
      "denseblock4.denselayer23.conv1.weight False\n",
      "denseblock4.denselayer23.norm2.weight False\n",
      "denseblock4.denselayer23.norm2.bias False\n",
      "denseblock4.denselayer23.conv2.weight False\n",
      "denseblock4.denselayer24.norm1.weight False\n",
      "denseblock4.denselayer24.norm1.bias False\n",
      "denseblock4.denselayer24.conv1.weight False\n",
      "denseblock4.denselayer24.norm2.weight False\n",
      "denseblock4.denselayer24.norm2.bias False\n",
      "denseblock4.denselayer24.conv2.weight False\n",
      "denseblock4.denselayer25.norm1.weight False\n",
      "denseblock4.denselayer25.norm1.bias False\n",
      "denseblock4.denselayer25.conv1.weight False\n",
      "denseblock4.denselayer25.norm2.weight False\n",
      "denseblock4.denselayer25.norm2.bias False\n",
      "denseblock4.denselayer25.conv2.weight False\n",
      "denseblock4.denselayer26.norm1.weight False\n",
      "denseblock4.denselayer26.norm1.bias False\n",
      "denseblock4.denselayer26.conv1.weight False\n",
      "denseblock4.denselayer26.norm2.weight False\n",
      "denseblock4.denselayer26.norm2.bias False\n",
      "denseblock4.denselayer26.conv2.weight False\n",
      "denseblock4.denselayer27.norm1.weight False\n",
      "denseblock4.denselayer27.norm1.bias False\n",
      "denseblock4.denselayer27.conv1.weight False\n",
      "denseblock4.denselayer27.norm2.weight False\n",
      "denseblock4.denselayer27.norm2.bias False\n",
      "denseblock4.denselayer27.conv2.weight False\n",
      "denseblock4.denselayer28.norm1.weight False\n",
      "denseblock4.denselayer28.norm1.bias False\n",
      "denseblock4.denselayer28.conv1.weight False\n",
      "denseblock4.denselayer28.norm2.weight False\n",
      "denseblock4.denselayer28.norm2.bias False\n",
      "denseblock4.denselayer28.conv2.weight False\n",
      "denseblock4.denselayer29.norm1.weight False\n",
      "denseblock4.denselayer29.norm1.bias False\n",
      "denseblock4.denselayer29.conv1.weight False\n",
      "denseblock4.denselayer29.norm2.weight False\n",
      "denseblock4.denselayer29.norm2.bias False\n",
      "denseblock4.denselayer29.conv2.weight False\n",
      "denseblock4.denselayer30.norm1.weight False\n",
      "denseblock4.denselayer30.norm1.bias False\n",
      "denseblock4.denselayer30.conv1.weight False\n",
      "denseblock4.denselayer30.norm2.weight False\n",
      "denseblock4.denselayer30.norm2.bias False\n",
      "denseblock4.denselayer30.conv2.weight False\n",
      "denseblock4.denselayer31.norm1.weight False\n",
      "denseblock4.denselayer31.norm1.bias False\n",
      "denseblock4.denselayer31.conv1.weight False\n",
      "denseblock4.denselayer31.norm2.weight False\n",
      "denseblock4.denselayer31.norm2.bias False\n",
      "denseblock4.denselayer31.conv2.weight False\n",
      "denseblock4.denselayer32.norm1.weight False\n",
      "denseblock4.denselayer32.norm1.bias False\n",
      "denseblock4.denselayer32.conv1.weight False\n",
      "denseblock4.denselayer32.norm2.weight False\n",
      "denseblock4.denselayer32.norm2.bias False\n",
      "denseblock4.denselayer32.conv2.weight False\n",
      "norm5.weight False\n",
      "norm5.bias False\n",
      "weight True\n",
      "bias True\n"
     ]
    }
   ],
   "source": [
    "## First train just last new layer with small lr\n",
    "\n",
    "#Freeze all layers first\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Then unfreeze last classification layer only for feature extract\n",
    "for param in model_ft.classifier.parameters():\n",
    "    param.requires_grad = True    \n",
    "\n",
    "    \n",
    "# To view which layers are freeze and which layers are not freezed:\n",
    "for name, child in model_ft.named_children():\n",
    "    for name_2, params in child.named_parameters():\n",
    "        print(name_2, params.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr[0.001], Epoch 0/5\n",
      "----------\n",
      "train Loss: 4.2480 Acc: 0.0878\n",
      "valid Loss: 3.9291 Acc: 0.1724\n",
      "\n",
      "lr[0.0001], Epoch 1/5\n",
      "----------\n",
      "train Loss: 3.6547 Acc: 0.2613\n",
      "valid Loss: 3.4208 Acc: 0.3802\n",
      "\n",
      "lr[0.0001], Epoch 2/5\n",
      "----------\n",
      "train Loss: 3.1816 Acc: 0.4242\n",
      "valid Loss: 2.9671 Acc: 0.4780\n",
      "\n",
      "lr[0.0001], Epoch 3/5\n",
      "----------\n",
      "train Loss: 2.9184 Acc: 0.4921\n",
      "valid Loss: 2.9279 Acc: 0.4902\n",
      "\n",
      "lr[1e-05], Epoch 4/5\n",
      "----------\n",
      "train Loss: 2.8774 Acc: 0.5030\n",
      "valid Loss: 2.9105 Acc: 0.4927\n",
      "\n",
      "lr[1e-05], Epoch 5/5\n",
      "----------\n",
      "train Loss: 2.8379 Acc: 0.5131\n",
      "valid Loss: 2.8409 Acc: 0.5024\n",
      "\n",
      "Training complete in 2m 14s\n",
      "Best val Acc: 0.502445\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv0.weight True\n",
      "norm0.weight True\n",
      "norm0.bias True\n",
      "denseblock1.denselayer1.norm1.weight True\n",
      "denseblock1.denselayer1.norm1.bias True\n",
      "denseblock1.denselayer1.conv1.weight True\n",
      "denseblock1.denselayer1.norm2.weight True\n",
      "denseblock1.denselayer1.norm2.bias True\n",
      "denseblock1.denselayer1.conv2.weight True\n",
      "denseblock1.denselayer2.norm1.weight True\n",
      "denseblock1.denselayer2.norm1.bias True\n",
      "denseblock1.denselayer2.conv1.weight True\n",
      "denseblock1.denselayer2.norm2.weight True\n",
      "denseblock1.denselayer2.norm2.bias True\n",
      "denseblock1.denselayer2.conv2.weight True\n",
      "denseblock1.denselayer3.norm1.weight True\n",
      "denseblock1.denselayer3.norm1.bias True\n",
      "denseblock1.denselayer3.conv1.weight True\n",
      "denseblock1.denselayer3.norm2.weight True\n",
      "denseblock1.denselayer3.norm2.bias True\n",
      "denseblock1.denselayer3.conv2.weight True\n",
      "denseblock1.denselayer4.norm1.weight True\n",
      "denseblock1.denselayer4.norm1.bias True\n",
      "denseblock1.denselayer4.conv1.weight True\n",
      "denseblock1.denselayer4.norm2.weight True\n",
      "denseblock1.denselayer4.norm2.bias True\n",
      "denseblock1.denselayer4.conv2.weight True\n",
      "denseblock1.denselayer5.norm1.weight True\n",
      "denseblock1.denselayer5.norm1.bias True\n",
      "denseblock1.denselayer5.conv1.weight True\n",
      "denseblock1.denselayer5.norm2.weight True\n",
      "denseblock1.denselayer5.norm2.bias True\n",
      "denseblock1.denselayer5.conv2.weight True\n",
      "denseblock1.denselayer6.norm1.weight True\n",
      "denseblock1.denselayer6.norm1.bias True\n",
      "denseblock1.denselayer6.conv1.weight True\n",
      "denseblock1.denselayer6.norm2.weight True\n",
      "denseblock1.denselayer6.norm2.bias True\n",
      "denseblock1.denselayer6.conv2.weight True\n",
      "transition1.norm.weight True\n",
      "transition1.norm.bias True\n",
      "transition1.conv.weight True\n",
      "denseblock2.denselayer1.norm1.weight True\n",
      "denseblock2.denselayer1.norm1.bias True\n",
      "denseblock2.denselayer1.conv1.weight True\n",
      "denseblock2.denselayer1.norm2.weight True\n",
      "denseblock2.denselayer1.norm2.bias True\n",
      "denseblock2.denselayer1.conv2.weight True\n",
      "denseblock2.denselayer2.norm1.weight True\n",
      "denseblock2.denselayer2.norm1.bias True\n",
      "denseblock2.denselayer2.conv1.weight True\n",
      "denseblock2.denselayer2.norm2.weight True\n",
      "denseblock2.denselayer2.norm2.bias True\n",
      "denseblock2.denselayer2.conv2.weight True\n",
      "denseblock2.denselayer3.norm1.weight True\n",
      "denseblock2.denselayer3.norm1.bias True\n",
      "denseblock2.denselayer3.conv1.weight True\n",
      "denseblock2.denselayer3.norm2.weight True\n",
      "denseblock2.denselayer3.norm2.bias True\n",
      "denseblock2.denselayer3.conv2.weight True\n",
      "denseblock2.denselayer4.norm1.weight True\n",
      "denseblock2.denselayer4.norm1.bias True\n",
      "denseblock2.denselayer4.conv1.weight True\n",
      "denseblock2.denselayer4.norm2.weight True\n",
      "denseblock2.denselayer4.norm2.bias True\n",
      "denseblock2.denselayer4.conv2.weight True\n",
      "denseblock2.denselayer5.norm1.weight True\n",
      "denseblock2.denselayer5.norm1.bias True\n",
      "denseblock2.denselayer5.conv1.weight True\n",
      "denseblock2.denselayer5.norm2.weight True\n",
      "denseblock2.denselayer5.norm2.bias True\n",
      "denseblock2.denselayer5.conv2.weight True\n",
      "denseblock2.denselayer6.norm1.weight True\n",
      "denseblock2.denselayer6.norm1.bias True\n",
      "denseblock2.denselayer6.conv1.weight True\n",
      "denseblock2.denselayer6.norm2.weight True\n",
      "denseblock2.denselayer6.norm2.bias True\n",
      "denseblock2.denselayer6.conv2.weight True\n",
      "denseblock2.denselayer7.norm1.weight True\n",
      "denseblock2.denselayer7.norm1.bias True\n",
      "denseblock2.denselayer7.conv1.weight True\n",
      "denseblock2.denselayer7.norm2.weight True\n",
      "denseblock2.denselayer7.norm2.bias True\n",
      "denseblock2.denselayer7.conv2.weight True\n",
      "denseblock2.denselayer8.norm1.weight True\n",
      "denseblock2.denselayer8.norm1.bias True\n",
      "denseblock2.denselayer8.conv1.weight True\n",
      "denseblock2.denselayer8.norm2.weight True\n",
      "denseblock2.denselayer8.norm2.bias True\n",
      "denseblock2.denselayer8.conv2.weight True\n",
      "denseblock2.denselayer9.norm1.weight True\n",
      "denseblock2.denselayer9.norm1.bias True\n",
      "denseblock2.denselayer9.conv1.weight True\n",
      "denseblock2.denselayer9.norm2.weight True\n",
      "denseblock2.denselayer9.norm2.bias True\n",
      "denseblock2.denselayer9.conv2.weight True\n",
      "denseblock2.denselayer10.norm1.weight True\n",
      "denseblock2.denselayer10.norm1.bias True\n",
      "denseblock2.denselayer10.conv1.weight True\n",
      "denseblock2.denselayer10.norm2.weight True\n",
      "denseblock2.denselayer10.norm2.bias True\n",
      "denseblock2.denselayer10.conv2.weight True\n",
      "denseblock2.denselayer11.norm1.weight True\n",
      "denseblock2.denselayer11.norm1.bias True\n",
      "denseblock2.denselayer11.conv1.weight True\n",
      "denseblock2.denselayer11.norm2.weight True\n",
      "denseblock2.denselayer11.norm2.bias True\n",
      "denseblock2.denselayer11.conv2.weight True\n",
      "denseblock2.denselayer12.norm1.weight True\n",
      "denseblock2.denselayer12.norm1.bias True\n",
      "denseblock2.denselayer12.conv1.weight True\n",
      "denseblock2.denselayer12.norm2.weight True\n",
      "denseblock2.denselayer12.norm2.bias True\n",
      "denseblock2.denselayer12.conv2.weight True\n",
      "transition2.norm.weight True\n",
      "transition2.norm.bias True\n",
      "transition2.conv.weight True\n",
      "denseblock3.denselayer1.norm1.weight True\n",
      "denseblock3.denselayer1.norm1.bias True\n",
      "denseblock3.denselayer1.conv1.weight True\n",
      "denseblock3.denselayer1.norm2.weight True\n",
      "denseblock3.denselayer1.norm2.bias True\n",
      "denseblock3.denselayer1.conv2.weight True\n",
      "denseblock3.denselayer2.norm1.weight True\n",
      "denseblock3.denselayer2.norm1.bias True\n",
      "denseblock3.denselayer2.conv1.weight True\n",
      "denseblock3.denselayer2.norm2.weight True\n",
      "denseblock3.denselayer2.norm2.bias True\n",
      "denseblock3.denselayer2.conv2.weight True\n",
      "denseblock3.denselayer3.norm1.weight True\n",
      "denseblock3.denselayer3.norm1.bias True\n",
      "denseblock3.denselayer3.conv1.weight True\n",
      "denseblock3.denselayer3.norm2.weight True\n",
      "denseblock3.denselayer3.norm2.bias True\n",
      "denseblock3.denselayer3.conv2.weight True\n",
      "denseblock3.denselayer4.norm1.weight True\n",
      "denseblock3.denselayer4.norm1.bias True\n",
      "denseblock3.denselayer4.conv1.weight True\n",
      "denseblock3.denselayer4.norm2.weight True\n",
      "denseblock3.denselayer4.norm2.bias True\n",
      "denseblock3.denselayer4.conv2.weight True\n",
      "denseblock3.denselayer5.norm1.weight True\n",
      "denseblock3.denselayer5.norm1.bias True\n",
      "denseblock3.denselayer5.conv1.weight True\n",
      "denseblock3.denselayer5.norm2.weight True\n",
      "denseblock3.denselayer5.norm2.bias True\n",
      "denseblock3.denselayer5.conv2.weight True\n",
      "denseblock3.denselayer6.norm1.weight True\n",
      "denseblock3.denselayer6.norm1.bias True\n",
      "denseblock3.denselayer6.conv1.weight True\n",
      "denseblock3.denselayer6.norm2.weight True\n",
      "denseblock3.denselayer6.norm2.bias True\n",
      "denseblock3.denselayer6.conv2.weight True\n",
      "denseblock3.denselayer7.norm1.weight True\n",
      "denseblock3.denselayer7.norm1.bias True\n",
      "denseblock3.denselayer7.conv1.weight True\n",
      "denseblock3.denselayer7.norm2.weight True\n",
      "denseblock3.denselayer7.norm2.bias True\n",
      "denseblock3.denselayer7.conv2.weight True\n",
      "denseblock3.denselayer8.norm1.weight True\n",
      "denseblock3.denselayer8.norm1.bias True\n",
      "denseblock3.denselayer8.conv1.weight True\n",
      "denseblock3.denselayer8.norm2.weight True\n",
      "denseblock3.denselayer8.norm2.bias True\n",
      "denseblock3.denselayer8.conv2.weight True\n",
      "denseblock3.denselayer9.norm1.weight True\n",
      "denseblock3.denselayer9.norm1.bias True\n",
      "denseblock3.denselayer9.conv1.weight True\n",
      "denseblock3.denselayer9.norm2.weight True\n",
      "denseblock3.denselayer9.norm2.bias True\n",
      "denseblock3.denselayer9.conv2.weight True\n",
      "denseblock3.denselayer10.norm1.weight True\n",
      "denseblock3.denselayer10.norm1.bias True\n",
      "denseblock3.denselayer10.conv1.weight True\n",
      "denseblock3.denselayer10.norm2.weight True\n",
      "denseblock3.denselayer10.norm2.bias True\n",
      "denseblock3.denselayer10.conv2.weight True\n",
      "denseblock3.denselayer11.norm1.weight True\n",
      "denseblock3.denselayer11.norm1.bias True\n",
      "denseblock3.denselayer11.conv1.weight True\n",
      "denseblock3.denselayer11.norm2.weight True\n",
      "denseblock3.denselayer11.norm2.bias True\n",
      "denseblock3.denselayer11.conv2.weight True\n",
      "denseblock3.denselayer12.norm1.weight True\n",
      "denseblock3.denselayer12.norm1.bias True\n",
      "denseblock3.denselayer12.conv1.weight True\n",
      "denseblock3.denselayer12.norm2.weight True\n",
      "denseblock3.denselayer12.norm2.bias True\n",
      "denseblock3.denselayer12.conv2.weight True\n",
      "denseblock3.denselayer13.norm1.weight True\n",
      "denseblock3.denselayer13.norm1.bias True\n",
      "denseblock3.denselayer13.conv1.weight True\n",
      "denseblock3.denselayer13.norm2.weight True\n",
      "denseblock3.denselayer13.norm2.bias True\n",
      "denseblock3.denselayer13.conv2.weight True\n",
      "denseblock3.denselayer14.norm1.weight True\n",
      "denseblock3.denselayer14.norm1.bias True\n",
      "denseblock3.denselayer14.conv1.weight True\n",
      "denseblock3.denselayer14.norm2.weight True\n",
      "denseblock3.denselayer14.norm2.bias True\n",
      "denseblock3.denselayer14.conv2.weight True\n",
      "denseblock3.denselayer15.norm1.weight True\n",
      "denseblock3.denselayer15.norm1.bias True\n",
      "denseblock3.denselayer15.conv1.weight True\n",
      "denseblock3.denselayer15.norm2.weight True\n",
      "denseblock3.denselayer15.norm2.bias True\n",
      "denseblock3.denselayer15.conv2.weight True\n",
      "denseblock3.denselayer16.norm1.weight True\n",
      "denseblock3.denselayer16.norm1.bias True\n",
      "denseblock3.denselayer16.conv1.weight True\n",
      "denseblock3.denselayer16.norm2.weight True\n",
      "denseblock3.denselayer16.norm2.bias True\n",
      "denseblock3.denselayer16.conv2.weight True\n",
      "denseblock3.denselayer17.norm1.weight True\n",
      "denseblock3.denselayer17.norm1.bias True\n",
      "denseblock3.denselayer17.conv1.weight True\n",
      "denseblock3.denselayer17.norm2.weight True\n",
      "denseblock3.denselayer17.norm2.bias True\n",
      "denseblock3.denselayer17.conv2.weight True\n",
      "denseblock3.denselayer18.norm1.weight True\n",
      "denseblock3.denselayer18.norm1.bias True\n",
      "denseblock3.denselayer18.conv1.weight True\n",
      "denseblock3.denselayer18.norm2.weight True\n",
      "denseblock3.denselayer18.norm2.bias True\n",
      "denseblock3.denselayer18.conv2.weight True\n",
      "denseblock3.denselayer19.norm1.weight True\n",
      "denseblock3.denselayer19.norm1.bias True\n",
      "denseblock3.denselayer19.conv1.weight True\n",
      "denseblock3.denselayer19.norm2.weight True\n",
      "denseblock3.denselayer19.norm2.bias True\n",
      "denseblock3.denselayer19.conv2.weight True\n",
      "denseblock3.denselayer20.norm1.weight True\n",
      "denseblock3.denselayer20.norm1.bias True\n",
      "denseblock3.denselayer20.conv1.weight True\n",
      "denseblock3.denselayer20.norm2.weight True\n",
      "denseblock3.denselayer20.norm2.bias True\n",
      "denseblock3.denselayer20.conv2.weight True\n",
      "denseblock3.denselayer21.norm1.weight True\n",
      "denseblock3.denselayer21.norm1.bias True\n",
      "denseblock3.denselayer21.conv1.weight True\n",
      "denseblock3.denselayer21.norm2.weight True\n",
      "denseblock3.denselayer21.norm2.bias True\n",
      "denseblock3.denselayer21.conv2.weight True\n",
      "denseblock3.denselayer22.norm1.weight True\n",
      "denseblock3.denselayer22.norm1.bias True\n",
      "denseblock3.denselayer22.conv1.weight True\n",
      "denseblock3.denselayer22.norm2.weight True\n",
      "denseblock3.denselayer22.norm2.bias True\n",
      "denseblock3.denselayer22.conv2.weight True\n",
      "denseblock3.denselayer23.norm1.weight True\n",
      "denseblock3.denselayer23.norm1.bias True\n",
      "denseblock3.denselayer23.conv1.weight True\n",
      "denseblock3.denselayer23.norm2.weight True\n",
      "denseblock3.denselayer23.norm2.bias True\n",
      "denseblock3.denselayer23.conv2.weight True\n",
      "denseblock3.denselayer24.norm1.weight True\n",
      "denseblock3.denselayer24.norm1.bias True\n",
      "denseblock3.denselayer24.conv1.weight True\n",
      "denseblock3.denselayer24.norm2.weight True\n",
      "denseblock3.denselayer24.norm2.bias True\n",
      "denseblock3.denselayer24.conv2.weight True\n",
      "denseblock3.denselayer25.norm1.weight True\n",
      "denseblock3.denselayer25.norm1.bias True\n",
      "denseblock3.denselayer25.conv1.weight True\n",
      "denseblock3.denselayer25.norm2.weight True\n",
      "denseblock3.denselayer25.norm2.bias True\n",
      "denseblock3.denselayer25.conv2.weight True\n",
      "denseblock3.denselayer26.norm1.weight True\n",
      "denseblock3.denselayer26.norm1.bias True\n",
      "denseblock3.denselayer26.conv1.weight True\n",
      "denseblock3.denselayer26.norm2.weight True\n",
      "denseblock3.denselayer26.norm2.bias True\n",
      "denseblock3.denselayer26.conv2.weight True\n",
      "denseblock3.denselayer27.norm1.weight True\n",
      "denseblock3.denselayer27.norm1.bias True\n",
      "denseblock3.denselayer27.conv1.weight True\n",
      "denseblock3.denselayer27.norm2.weight True\n",
      "denseblock3.denselayer27.norm2.bias True\n",
      "denseblock3.denselayer27.conv2.weight True\n",
      "denseblock3.denselayer28.norm1.weight True\n",
      "denseblock3.denselayer28.norm1.bias True\n",
      "denseblock3.denselayer28.conv1.weight True\n",
      "denseblock3.denselayer28.norm2.weight True\n",
      "denseblock3.denselayer28.norm2.bias True\n",
      "denseblock3.denselayer28.conv2.weight True\n",
      "denseblock3.denselayer29.norm1.weight True\n",
      "denseblock3.denselayer29.norm1.bias True\n",
      "denseblock3.denselayer29.conv1.weight True\n",
      "denseblock3.denselayer29.norm2.weight True\n",
      "denseblock3.denselayer29.norm2.bias True\n",
      "denseblock3.denselayer29.conv2.weight True\n",
      "denseblock3.denselayer30.norm1.weight True\n",
      "denseblock3.denselayer30.norm1.bias True\n",
      "denseblock3.denselayer30.conv1.weight True\n",
      "denseblock3.denselayer30.norm2.weight True\n",
      "denseblock3.denselayer30.norm2.bias True\n",
      "denseblock3.denselayer30.conv2.weight True\n",
      "denseblock3.denselayer31.norm1.weight True\n",
      "denseblock3.denselayer31.norm1.bias True\n",
      "denseblock3.denselayer31.conv1.weight True\n",
      "denseblock3.denselayer31.norm2.weight True\n",
      "denseblock3.denselayer31.norm2.bias True\n",
      "denseblock3.denselayer31.conv2.weight True\n",
      "denseblock3.denselayer32.norm1.weight True\n",
      "denseblock3.denselayer32.norm1.bias True\n",
      "denseblock3.denselayer32.conv1.weight True\n",
      "denseblock3.denselayer32.norm2.weight True\n",
      "denseblock3.denselayer32.norm2.bias True\n",
      "denseblock3.denselayer32.conv2.weight True\n",
      "denseblock3.denselayer33.norm1.weight True\n",
      "denseblock3.denselayer33.norm1.bias True\n",
      "denseblock3.denselayer33.conv1.weight True\n",
      "denseblock3.denselayer33.norm2.weight True\n",
      "denseblock3.denselayer33.norm2.bias True\n",
      "denseblock3.denselayer33.conv2.weight True\n",
      "denseblock3.denselayer34.norm1.weight True\n",
      "denseblock3.denselayer34.norm1.bias True\n",
      "denseblock3.denselayer34.conv1.weight True\n",
      "denseblock3.denselayer34.norm2.weight True\n",
      "denseblock3.denselayer34.norm2.bias True\n",
      "denseblock3.denselayer34.conv2.weight True\n",
      "denseblock3.denselayer35.norm1.weight True\n",
      "denseblock3.denselayer35.norm1.bias True\n",
      "denseblock3.denselayer35.conv1.weight True\n",
      "denseblock3.denselayer35.norm2.weight True\n",
      "denseblock3.denselayer35.norm2.bias True\n",
      "denseblock3.denselayer35.conv2.weight True\n",
      "denseblock3.denselayer36.norm1.weight True\n",
      "denseblock3.denselayer36.norm1.bias True\n",
      "denseblock3.denselayer36.conv1.weight True\n",
      "denseblock3.denselayer36.norm2.weight True\n",
      "denseblock3.denselayer36.norm2.bias True\n",
      "denseblock3.denselayer36.conv2.weight True\n",
      "denseblock3.denselayer37.norm1.weight True\n",
      "denseblock3.denselayer37.norm1.bias True\n",
      "denseblock3.denselayer37.conv1.weight True\n",
      "denseblock3.denselayer37.norm2.weight True\n",
      "denseblock3.denselayer37.norm2.bias True\n",
      "denseblock3.denselayer37.conv2.weight True\n",
      "denseblock3.denselayer38.norm1.weight True\n",
      "denseblock3.denselayer38.norm1.bias True\n",
      "denseblock3.denselayer38.conv1.weight True\n",
      "denseblock3.denselayer38.norm2.weight True\n",
      "denseblock3.denselayer38.norm2.bias True\n",
      "denseblock3.denselayer38.conv2.weight True\n",
      "denseblock3.denselayer39.norm1.weight True\n",
      "denseblock3.denselayer39.norm1.bias True\n",
      "denseblock3.denselayer39.conv1.weight True\n",
      "denseblock3.denselayer39.norm2.weight True\n",
      "denseblock3.denselayer39.norm2.bias True\n",
      "denseblock3.denselayer39.conv2.weight True\n",
      "denseblock3.denselayer40.norm1.weight True\n",
      "denseblock3.denselayer40.norm1.bias True\n",
      "denseblock3.denselayer40.conv1.weight True\n",
      "denseblock3.denselayer40.norm2.weight True\n",
      "denseblock3.denselayer40.norm2.bias True\n",
      "denseblock3.denselayer40.conv2.weight True\n",
      "denseblock3.denselayer41.norm1.weight True\n",
      "denseblock3.denselayer41.norm1.bias True\n",
      "denseblock3.denselayer41.conv1.weight True\n",
      "denseblock3.denselayer41.norm2.weight True\n",
      "denseblock3.denselayer41.norm2.bias True\n",
      "denseblock3.denselayer41.conv2.weight True\n",
      "denseblock3.denselayer42.norm1.weight True\n",
      "denseblock3.denselayer42.norm1.bias True\n",
      "denseblock3.denselayer42.conv1.weight True\n",
      "denseblock3.denselayer42.norm2.weight True\n",
      "denseblock3.denselayer42.norm2.bias True\n",
      "denseblock3.denselayer42.conv2.weight True\n",
      "denseblock3.denselayer43.norm1.weight True\n",
      "denseblock3.denselayer43.norm1.bias True\n",
      "denseblock3.denselayer43.conv1.weight True\n",
      "denseblock3.denselayer43.norm2.weight True\n",
      "denseblock3.denselayer43.norm2.bias True\n",
      "denseblock3.denselayer43.conv2.weight True\n",
      "denseblock3.denselayer44.norm1.weight True\n",
      "denseblock3.denselayer44.norm1.bias True\n",
      "denseblock3.denselayer44.conv1.weight True\n",
      "denseblock3.denselayer44.norm2.weight True\n",
      "denseblock3.denselayer44.norm2.bias True\n",
      "denseblock3.denselayer44.conv2.weight True\n",
      "denseblock3.denselayer45.norm1.weight True\n",
      "denseblock3.denselayer45.norm1.bias True\n",
      "denseblock3.denselayer45.conv1.weight True\n",
      "denseblock3.denselayer45.norm2.weight True\n",
      "denseblock3.denselayer45.norm2.bias True\n",
      "denseblock3.denselayer45.conv2.weight True\n",
      "denseblock3.denselayer46.norm1.weight True\n",
      "denseblock3.denselayer46.norm1.bias True\n",
      "denseblock3.denselayer46.conv1.weight True\n",
      "denseblock3.denselayer46.norm2.weight True\n",
      "denseblock3.denselayer46.norm2.bias True\n",
      "denseblock3.denselayer46.conv2.weight True\n",
      "denseblock3.denselayer47.norm1.weight True\n",
      "denseblock3.denselayer47.norm1.bias True\n",
      "denseblock3.denselayer47.conv1.weight True\n",
      "denseblock3.denselayer47.norm2.weight True\n",
      "denseblock3.denselayer47.norm2.bias True\n",
      "denseblock3.denselayer47.conv2.weight True\n",
      "denseblock3.denselayer48.norm1.weight True\n",
      "denseblock3.denselayer48.norm1.bias True\n",
      "denseblock3.denselayer48.conv1.weight True\n",
      "denseblock3.denselayer48.norm2.weight True\n",
      "denseblock3.denselayer48.norm2.bias True\n",
      "denseblock3.denselayer48.conv2.weight True\n",
      "transition3.norm.weight True\n",
      "transition3.norm.bias True\n",
      "transition3.conv.weight True\n",
      "denseblock4.denselayer1.norm1.weight True\n",
      "denseblock4.denselayer1.norm1.bias True\n",
      "denseblock4.denselayer1.conv1.weight True\n",
      "denseblock4.denselayer1.norm2.weight True\n",
      "denseblock4.denselayer1.norm2.bias True\n",
      "denseblock4.denselayer1.conv2.weight True\n",
      "denseblock4.denselayer2.norm1.weight True\n",
      "denseblock4.denselayer2.norm1.bias True\n",
      "denseblock4.denselayer2.conv1.weight True\n",
      "denseblock4.denselayer2.norm2.weight True\n",
      "denseblock4.denselayer2.norm2.bias True\n",
      "denseblock4.denselayer2.conv2.weight True\n",
      "denseblock4.denselayer3.norm1.weight True\n",
      "denseblock4.denselayer3.norm1.bias True\n",
      "denseblock4.denselayer3.conv1.weight True\n",
      "denseblock4.denselayer3.norm2.weight True\n",
      "denseblock4.denselayer3.norm2.bias True\n",
      "denseblock4.denselayer3.conv2.weight True\n",
      "denseblock4.denselayer4.norm1.weight True\n",
      "denseblock4.denselayer4.norm1.bias True\n",
      "denseblock4.denselayer4.conv1.weight True\n",
      "denseblock4.denselayer4.norm2.weight True\n",
      "denseblock4.denselayer4.norm2.bias True\n",
      "denseblock4.denselayer4.conv2.weight True\n",
      "denseblock4.denselayer5.norm1.weight True\n",
      "denseblock4.denselayer5.norm1.bias True\n",
      "denseblock4.denselayer5.conv1.weight True\n",
      "denseblock4.denselayer5.norm2.weight True\n",
      "denseblock4.denselayer5.norm2.bias True\n",
      "denseblock4.denselayer5.conv2.weight True\n",
      "denseblock4.denselayer6.norm1.weight True\n",
      "denseblock4.denselayer6.norm1.bias True\n",
      "denseblock4.denselayer6.conv1.weight True\n",
      "denseblock4.denselayer6.norm2.weight True\n",
      "denseblock4.denselayer6.norm2.bias True\n",
      "denseblock4.denselayer6.conv2.weight True\n",
      "denseblock4.denselayer7.norm1.weight True\n",
      "denseblock4.denselayer7.norm1.bias True\n",
      "denseblock4.denselayer7.conv1.weight True\n",
      "denseblock4.denselayer7.norm2.weight True\n",
      "denseblock4.denselayer7.norm2.bias True\n",
      "denseblock4.denselayer7.conv2.weight True\n",
      "denseblock4.denselayer8.norm1.weight True\n",
      "denseblock4.denselayer8.norm1.bias True\n",
      "denseblock4.denselayer8.conv1.weight True\n",
      "denseblock4.denselayer8.norm2.weight True\n",
      "denseblock4.denselayer8.norm2.bias True\n",
      "denseblock4.denselayer8.conv2.weight True\n",
      "denseblock4.denselayer9.norm1.weight True\n",
      "denseblock4.denselayer9.norm1.bias True\n",
      "denseblock4.denselayer9.conv1.weight True\n",
      "denseblock4.denselayer9.norm2.weight True\n",
      "denseblock4.denselayer9.norm2.bias True\n",
      "denseblock4.denselayer9.conv2.weight True\n",
      "denseblock4.denselayer10.norm1.weight True\n",
      "denseblock4.denselayer10.norm1.bias True\n",
      "denseblock4.denselayer10.conv1.weight True\n",
      "denseblock4.denselayer10.norm2.weight True\n",
      "denseblock4.denselayer10.norm2.bias True\n",
      "denseblock4.denselayer10.conv2.weight True\n",
      "denseblock4.denselayer11.norm1.weight True\n",
      "denseblock4.denselayer11.norm1.bias True\n",
      "denseblock4.denselayer11.conv1.weight True\n",
      "denseblock4.denselayer11.norm2.weight True\n",
      "denseblock4.denselayer11.norm2.bias True\n",
      "denseblock4.denselayer11.conv2.weight True\n",
      "denseblock4.denselayer12.norm1.weight True\n",
      "denseblock4.denselayer12.norm1.bias True\n",
      "denseblock4.denselayer12.conv1.weight True\n",
      "denseblock4.denselayer12.norm2.weight True\n",
      "denseblock4.denselayer12.norm2.bias True\n",
      "denseblock4.denselayer12.conv2.weight True\n",
      "denseblock4.denselayer13.norm1.weight True\n",
      "denseblock4.denselayer13.norm1.bias True\n",
      "denseblock4.denselayer13.conv1.weight True\n",
      "denseblock4.denselayer13.norm2.weight True\n",
      "denseblock4.denselayer13.norm2.bias True\n",
      "denseblock4.denselayer13.conv2.weight True\n",
      "denseblock4.denselayer14.norm1.weight True\n",
      "denseblock4.denselayer14.norm1.bias True\n",
      "denseblock4.denselayer14.conv1.weight True\n",
      "denseblock4.denselayer14.norm2.weight True\n",
      "denseblock4.denselayer14.norm2.bias True\n",
      "denseblock4.denselayer14.conv2.weight True\n",
      "denseblock4.denselayer15.norm1.weight True\n",
      "denseblock4.denselayer15.norm1.bias True\n",
      "denseblock4.denselayer15.conv1.weight True\n",
      "denseblock4.denselayer15.norm2.weight True\n",
      "denseblock4.denselayer15.norm2.bias True\n",
      "denseblock4.denselayer15.conv2.weight True\n",
      "denseblock4.denselayer16.norm1.weight True\n",
      "denseblock4.denselayer16.norm1.bias True\n",
      "denseblock4.denselayer16.conv1.weight True\n",
      "denseblock4.denselayer16.norm2.weight True\n",
      "denseblock4.denselayer16.norm2.bias True\n",
      "denseblock4.denselayer16.conv2.weight True\n",
      "denseblock4.denselayer17.norm1.weight True\n",
      "denseblock4.denselayer17.norm1.bias True\n",
      "denseblock4.denselayer17.conv1.weight True\n",
      "denseblock4.denselayer17.norm2.weight True\n",
      "denseblock4.denselayer17.norm2.bias True\n",
      "denseblock4.denselayer17.conv2.weight True\n",
      "denseblock4.denselayer18.norm1.weight True\n",
      "denseblock4.denselayer18.norm1.bias True\n",
      "denseblock4.denselayer18.conv1.weight True\n",
      "denseblock4.denselayer18.norm2.weight True\n",
      "denseblock4.denselayer18.norm2.bias True\n",
      "denseblock4.denselayer18.conv2.weight True\n",
      "denseblock4.denselayer19.norm1.weight True\n",
      "denseblock4.denselayer19.norm1.bias True\n",
      "denseblock4.denselayer19.conv1.weight True\n",
      "denseblock4.denselayer19.norm2.weight True\n",
      "denseblock4.denselayer19.norm2.bias True\n",
      "denseblock4.denselayer19.conv2.weight True\n",
      "denseblock4.denselayer20.norm1.weight True\n",
      "denseblock4.denselayer20.norm1.bias True\n",
      "denseblock4.denselayer20.conv1.weight True\n",
      "denseblock4.denselayer20.norm2.weight True\n",
      "denseblock4.denselayer20.norm2.bias True\n",
      "denseblock4.denselayer20.conv2.weight True\n",
      "denseblock4.denselayer21.norm1.weight True\n",
      "denseblock4.denselayer21.norm1.bias True\n",
      "denseblock4.denselayer21.conv1.weight True\n",
      "denseblock4.denselayer21.norm2.weight True\n",
      "denseblock4.denselayer21.norm2.bias True\n",
      "denseblock4.denselayer21.conv2.weight True\n",
      "denseblock4.denselayer22.norm1.weight True\n",
      "denseblock4.denselayer22.norm1.bias True\n",
      "denseblock4.denselayer22.conv1.weight True\n",
      "denseblock4.denselayer22.norm2.weight True\n",
      "denseblock4.denselayer22.norm2.bias True\n",
      "denseblock4.denselayer22.conv2.weight True\n",
      "denseblock4.denselayer23.norm1.weight True\n",
      "denseblock4.denselayer23.norm1.bias True\n",
      "denseblock4.denselayer23.conv1.weight True\n",
      "denseblock4.denselayer23.norm2.weight True\n",
      "denseblock4.denselayer23.norm2.bias True\n",
      "denseblock4.denselayer23.conv2.weight True\n",
      "denseblock4.denselayer24.norm1.weight True\n",
      "denseblock4.denselayer24.norm1.bias True\n",
      "denseblock4.denselayer24.conv1.weight True\n",
      "denseblock4.denselayer24.norm2.weight True\n",
      "denseblock4.denselayer24.norm2.bias True\n",
      "denseblock4.denselayer24.conv2.weight True\n",
      "denseblock4.denselayer25.norm1.weight True\n",
      "denseblock4.denselayer25.norm1.bias True\n",
      "denseblock4.denselayer25.conv1.weight True\n",
      "denseblock4.denselayer25.norm2.weight True\n",
      "denseblock4.denselayer25.norm2.bias True\n",
      "denseblock4.denselayer25.conv2.weight True\n",
      "denseblock4.denselayer26.norm1.weight True\n",
      "denseblock4.denselayer26.norm1.bias True\n",
      "denseblock4.denselayer26.conv1.weight True\n",
      "denseblock4.denselayer26.norm2.weight True\n",
      "denseblock4.denselayer26.norm2.bias True\n",
      "denseblock4.denselayer26.conv2.weight True\n",
      "denseblock4.denselayer27.norm1.weight True\n",
      "denseblock4.denselayer27.norm1.bias True\n",
      "denseblock4.denselayer27.conv1.weight True\n",
      "denseblock4.denselayer27.norm2.weight True\n",
      "denseblock4.denselayer27.norm2.bias True\n",
      "denseblock4.denselayer27.conv2.weight True\n",
      "denseblock4.denselayer28.norm1.weight True\n",
      "denseblock4.denselayer28.norm1.bias True\n",
      "denseblock4.denselayer28.conv1.weight True\n",
      "denseblock4.denselayer28.norm2.weight True\n",
      "denseblock4.denselayer28.norm2.bias True\n",
      "denseblock4.denselayer28.conv2.weight True\n",
      "denseblock4.denselayer29.norm1.weight True\n",
      "denseblock4.denselayer29.norm1.bias True\n",
      "denseblock4.denselayer29.conv1.weight True\n",
      "denseblock4.denselayer29.norm2.weight True\n",
      "denseblock4.denselayer29.norm2.bias True\n",
      "denseblock4.denselayer29.conv2.weight True\n",
      "denseblock4.denselayer30.norm1.weight True\n",
      "denseblock4.denselayer30.norm1.bias True\n",
      "denseblock4.denselayer30.conv1.weight True\n",
      "denseblock4.denselayer30.norm2.weight True\n",
      "denseblock4.denselayer30.norm2.bias True\n",
      "denseblock4.denselayer30.conv2.weight True\n",
      "denseblock4.denselayer31.norm1.weight True\n",
      "denseblock4.denselayer31.norm1.bias True\n",
      "denseblock4.denselayer31.conv1.weight True\n",
      "denseblock4.denselayer31.norm2.weight True\n",
      "denseblock4.denselayer31.norm2.bias True\n",
      "denseblock4.denselayer31.conv2.weight True\n",
      "denseblock4.denselayer32.norm1.weight True\n",
      "denseblock4.denselayer32.norm1.bias True\n",
      "denseblock4.denselayer32.conv1.weight True\n",
      "denseblock4.denselayer32.norm2.weight True\n",
      "denseblock4.denselayer32.norm2.bias True\n",
      "denseblock4.denselayer32.conv2.weight True\n",
      "norm5.weight True\n",
      "norm5.bias True\n",
      "weight True\n",
      "bias True\n"
     ]
    }
   ],
   "source": [
    "# On second round, train whole network, but only weights not bias\n",
    "'''\n",
    "# Freeze Bias but not Weights\n",
    "for name, child in model_ft.named_children():\n",
    "  for name_2, params in child.named_parameters():\n",
    "    if(str(name_2).find('bias') == -1): # weight\n",
    "        params.requires_grad = True\n",
    "        #print(name_2, params.requires_grad)\n",
    "    else:\n",
    "        params.requires_grad = False\n",
    "        \n",
    "#last bias, requires_grad=True\n",
    "# Then unfreeze last classification layer only for feature extract\n",
    "for param in model_ft.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "'''    \n",
    "\n",
    "#UnFreeze all layers first\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True \n",
    "    \n",
    "# To view which layers are freeze and which layers are not freezed:\n",
    "for name, child in model_ft.named_children():\n",
    "  for name_2, params in child.named_parameters():\n",
    "    print(name_2, params.requires_grad)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,288,870 total parameters.\n",
      "18,288,870 training parameters.\n"
     ]
    }
   ],
   "source": [
    "# Find total parameters and trainable parameters\n",
    "total_params = sum(p.numel() for p in model_ft.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model_ft.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.8)\n",
    "#optimizer_ft = optim.Adam(model_ft.parameters(),lr=1e-4,amsgrad=True)\n",
    "optimizer_ft = optim.Adam(model_ft.parameters())\n",
    "\n",
    "# Decay LR by a factor of 0.1 every ? epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr[0.01], Epoch 0/14\n",
      "----------\n",
      "train Loss: 1.7092 Acc: 0.5688\n",
      "valid Loss: 0.8446 Acc: 0.7812\n",
      "\n",
      "lr[0.001], Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.9428 Acc: 0.7471\n",
      "valid Loss: 0.6185 Acc: 0.8386\n",
      "\n",
      "lr[0.001], Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.7467 Acc: 0.7941\n",
      "valid Loss: 0.4864 Acc: 0.8619\n",
      "\n",
      "lr[0.001], Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.6374 Acc: 0.8235\n",
      "valid Loss: 0.4094 Acc: 0.9034\n",
      "\n",
      "lr[0.001], Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.5626 Acc: 0.8446\n",
      "valid Loss: 0.3166 Acc: 0.9193\n",
      "\n",
      "lr[0.001], Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.3193 Acc: 0.9150\n",
      "valid Loss: 0.1614 Acc: 0.9645\n",
      "\n",
      "lr[0.0001], Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.2505 Acc: 0.9331\n",
      "valid Loss: 0.1536 Acc: 0.9743\n",
      "\n",
      "lr[0.0001], Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.2205 Acc: 0.9447\n",
      "valid Loss: 0.1449 Acc: 0.9694\n",
      "\n",
      "lr[0.0001], Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.2166 Acc: 0.9415\n",
      "valid Loss: 0.1333 Acc: 0.9743\n",
      "\n",
      "lr[0.0001], Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.1834 Acc: 0.9527\n",
      "valid Loss: 0.1308 Acc: 0.9645\n",
      "\n",
      "lr[0.0001], Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.1807 Acc: 0.9554\n",
      "valid Loss: 0.1253 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000003e-05], Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.1748 Acc: 0.9522\n",
      "valid Loss: 0.1276 Acc: 0.9658\n",
      "\n",
      "lr[1.0000000000000003e-05], Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.1733 Acc: 0.9557\n",
      "valid Loss: 0.1295 Acc: 0.9645\n",
      "\n",
      "lr[1.0000000000000003e-05], Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.1528 Acc: 0.9624\n",
      "valid Loss: 0.1262 Acc: 0.9694\n",
      "\n",
      "lr[1.0000000000000003e-05], Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.1778 Acc: 0.9537\n",
      "valid Loss: 0.1226 Acc: 0.9743\n",
      "\n",
      "Training complete in 16m 8s\n",
      "Best val Acc: 0.974328\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv0.weight False\n",
      "norm0.weight False\n",
      "norm0.bias False\n",
      "denseblock1.denselayer1.norm1.weight False\n",
      "denseblock1.denselayer1.norm1.bias False\n",
      "denseblock1.denselayer1.conv1.weight False\n",
      "denseblock1.denselayer1.norm2.weight False\n",
      "denseblock1.denselayer1.norm2.bias False\n",
      "denseblock1.denselayer1.conv2.weight False\n",
      "denseblock1.denselayer2.norm1.weight False\n",
      "denseblock1.denselayer2.norm1.bias False\n",
      "denseblock1.denselayer2.conv1.weight False\n",
      "denseblock1.denselayer2.norm2.weight False\n",
      "denseblock1.denselayer2.norm2.bias False\n",
      "denseblock1.denselayer2.conv2.weight False\n",
      "denseblock1.denselayer3.norm1.weight False\n",
      "denseblock1.denselayer3.norm1.bias False\n",
      "denseblock1.denselayer3.conv1.weight False\n",
      "denseblock1.denselayer3.norm2.weight False\n",
      "denseblock1.denselayer3.norm2.bias False\n",
      "denseblock1.denselayer3.conv2.weight False\n",
      "denseblock1.denselayer4.norm1.weight False\n",
      "denseblock1.denselayer4.norm1.bias False\n",
      "denseblock1.denselayer4.conv1.weight False\n",
      "denseblock1.denselayer4.norm2.weight False\n",
      "denseblock1.denselayer4.norm2.bias False\n",
      "denseblock1.denselayer4.conv2.weight False\n",
      "denseblock1.denselayer5.norm1.weight False\n",
      "denseblock1.denselayer5.norm1.bias False\n",
      "denseblock1.denselayer5.conv1.weight False\n",
      "denseblock1.denselayer5.norm2.weight False\n",
      "denseblock1.denselayer5.norm2.bias False\n",
      "denseblock1.denselayer5.conv2.weight False\n",
      "denseblock1.denselayer6.norm1.weight False\n",
      "denseblock1.denselayer6.norm1.bias False\n",
      "denseblock1.denselayer6.conv1.weight False\n",
      "denseblock1.denselayer6.norm2.weight False\n",
      "denseblock1.denselayer6.norm2.bias False\n",
      "denseblock1.denselayer6.conv2.weight False\n",
      "transition1.norm.weight False\n",
      "transition1.norm.bias False\n",
      "transition1.conv.weight False\n",
      "denseblock2.denselayer1.norm1.weight False\n",
      "denseblock2.denselayer1.norm1.bias False\n",
      "denseblock2.denselayer1.conv1.weight False\n",
      "denseblock2.denselayer1.norm2.weight False\n",
      "denseblock2.denselayer1.norm2.bias False\n",
      "denseblock2.denselayer1.conv2.weight False\n",
      "denseblock2.denselayer2.norm1.weight False\n",
      "denseblock2.denselayer2.norm1.bias False\n",
      "denseblock2.denselayer2.conv1.weight False\n",
      "denseblock2.denselayer2.norm2.weight False\n",
      "denseblock2.denselayer2.norm2.bias False\n",
      "denseblock2.denselayer2.conv2.weight False\n",
      "denseblock2.denselayer3.norm1.weight False\n",
      "denseblock2.denselayer3.norm1.bias False\n",
      "denseblock2.denselayer3.conv1.weight False\n",
      "denseblock2.denselayer3.norm2.weight False\n",
      "denseblock2.denselayer3.norm2.bias False\n",
      "denseblock2.denselayer3.conv2.weight False\n",
      "denseblock2.denselayer4.norm1.weight False\n",
      "denseblock2.denselayer4.norm1.bias False\n",
      "denseblock2.denselayer4.conv1.weight False\n",
      "denseblock2.denselayer4.norm2.weight False\n",
      "denseblock2.denselayer4.norm2.bias False\n",
      "denseblock2.denselayer4.conv2.weight False\n",
      "denseblock2.denselayer5.norm1.weight False\n",
      "denseblock2.denselayer5.norm1.bias False\n",
      "denseblock2.denselayer5.conv1.weight False\n",
      "denseblock2.denselayer5.norm2.weight False\n",
      "denseblock2.denselayer5.norm2.bias False\n",
      "denseblock2.denselayer5.conv2.weight False\n",
      "denseblock2.denselayer6.norm1.weight False\n",
      "denseblock2.denselayer6.norm1.bias False\n",
      "denseblock2.denselayer6.conv1.weight False\n",
      "denseblock2.denselayer6.norm2.weight False\n",
      "denseblock2.denselayer6.norm2.bias False\n",
      "denseblock2.denselayer6.conv2.weight False\n",
      "denseblock2.denselayer7.norm1.weight False\n",
      "denseblock2.denselayer7.norm1.bias False\n",
      "denseblock2.denselayer7.conv1.weight False\n",
      "denseblock2.denselayer7.norm2.weight False\n",
      "denseblock2.denselayer7.norm2.bias False\n",
      "denseblock2.denselayer7.conv2.weight False\n",
      "denseblock2.denselayer8.norm1.weight False\n",
      "denseblock2.denselayer8.norm1.bias False\n",
      "denseblock2.denselayer8.conv1.weight False\n",
      "denseblock2.denselayer8.norm2.weight False\n",
      "denseblock2.denselayer8.norm2.bias False\n",
      "denseblock2.denselayer8.conv2.weight False\n",
      "denseblock2.denselayer9.norm1.weight False\n",
      "denseblock2.denselayer9.norm1.bias False\n",
      "denseblock2.denselayer9.conv1.weight False\n",
      "denseblock2.denselayer9.norm2.weight False\n",
      "denseblock2.denselayer9.norm2.bias False\n",
      "denseblock2.denselayer9.conv2.weight False\n",
      "denseblock2.denselayer10.norm1.weight False\n",
      "denseblock2.denselayer10.norm1.bias False\n",
      "denseblock2.denselayer10.conv1.weight False\n",
      "denseblock2.denselayer10.norm2.weight False\n",
      "denseblock2.denselayer10.norm2.bias False\n",
      "denseblock2.denselayer10.conv2.weight False\n",
      "denseblock2.denselayer11.norm1.weight False\n",
      "denseblock2.denselayer11.norm1.bias False\n",
      "denseblock2.denselayer11.conv1.weight False\n",
      "denseblock2.denselayer11.norm2.weight False\n",
      "denseblock2.denselayer11.norm2.bias False\n",
      "denseblock2.denselayer11.conv2.weight False\n",
      "denseblock2.denselayer12.norm1.weight False\n",
      "denseblock2.denselayer12.norm1.bias False\n",
      "denseblock2.denselayer12.conv1.weight False\n",
      "denseblock2.denselayer12.norm2.weight False\n",
      "denseblock2.denselayer12.norm2.bias False\n",
      "denseblock2.denselayer12.conv2.weight False\n",
      "transition2.norm.weight False\n",
      "transition2.norm.bias False\n",
      "transition2.conv.weight False\n",
      "denseblock3.denselayer1.norm1.weight False\n",
      "denseblock3.denselayer1.norm1.bias False\n",
      "denseblock3.denselayer1.conv1.weight False\n",
      "denseblock3.denselayer1.norm2.weight False\n",
      "denseblock3.denselayer1.norm2.bias False\n",
      "denseblock3.denselayer1.conv2.weight False\n",
      "denseblock3.denselayer2.norm1.weight False\n",
      "denseblock3.denselayer2.norm1.bias False\n",
      "denseblock3.denselayer2.conv1.weight False\n",
      "denseblock3.denselayer2.norm2.weight False\n",
      "denseblock3.denselayer2.norm2.bias False\n",
      "denseblock3.denselayer2.conv2.weight False\n",
      "denseblock3.denselayer3.norm1.weight False\n",
      "denseblock3.denselayer3.norm1.bias False\n",
      "denseblock3.denselayer3.conv1.weight False\n",
      "denseblock3.denselayer3.norm2.weight False\n",
      "denseblock3.denselayer3.norm2.bias False\n",
      "denseblock3.denselayer3.conv2.weight False\n",
      "denseblock3.denselayer4.norm1.weight False\n",
      "denseblock3.denselayer4.norm1.bias False\n",
      "denseblock3.denselayer4.conv1.weight False\n",
      "denseblock3.denselayer4.norm2.weight False\n",
      "denseblock3.denselayer4.norm2.bias False\n",
      "denseblock3.denselayer4.conv2.weight False\n",
      "denseblock3.denselayer5.norm1.weight False\n",
      "denseblock3.denselayer5.norm1.bias False\n",
      "denseblock3.denselayer5.conv1.weight False\n",
      "denseblock3.denselayer5.norm2.weight False\n",
      "denseblock3.denselayer5.norm2.bias False\n",
      "denseblock3.denselayer5.conv2.weight False\n",
      "denseblock3.denselayer6.norm1.weight False\n",
      "denseblock3.denselayer6.norm1.bias False\n",
      "denseblock3.denselayer6.conv1.weight False\n",
      "denseblock3.denselayer6.norm2.weight False\n",
      "denseblock3.denselayer6.norm2.bias False\n",
      "denseblock3.denselayer6.conv2.weight False\n",
      "denseblock3.denselayer7.norm1.weight False\n",
      "denseblock3.denselayer7.norm1.bias False\n",
      "denseblock3.denselayer7.conv1.weight False\n",
      "denseblock3.denselayer7.norm2.weight False\n",
      "denseblock3.denselayer7.norm2.bias False\n",
      "denseblock3.denselayer7.conv2.weight False\n",
      "denseblock3.denselayer8.norm1.weight False\n",
      "denseblock3.denselayer8.norm1.bias False\n",
      "denseblock3.denselayer8.conv1.weight False\n",
      "denseblock3.denselayer8.norm2.weight False\n",
      "denseblock3.denselayer8.norm2.bias False\n",
      "denseblock3.denselayer8.conv2.weight False\n",
      "denseblock3.denselayer9.norm1.weight False\n",
      "denseblock3.denselayer9.norm1.bias False\n",
      "denseblock3.denselayer9.conv1.weight False\n",
      "denseblock3.denselayer9.norm2.weight False\n",
      "denseblock3.denselayer9.norm2.bias False\n",
      "denseblock3.denselayer9.conv2.weight False\n",
      "denseblock3.denselayer10.norm1.weight False\n",
      "denseblock3.denselayer10.norm1.bias False\n",
      "denseblock3.denselayer10.conv1.weight False\n",
      "denseblock3.denselayer10.norm2.weight False\n",
      "denseblock3.denselayer10.norm2.bias False\n",
      "denseblock3.denselayer10.conv2.weight False\n",
      "denseblock3.denselayer11.norm1.weight False\n",
      "denseblock3.denselayer11.norm1.bias False\n",
      "denseblock3.denselayer11.conv1.weight False\n",
      "denseblock3.denselayer11.norm2.weight False\n",
      "denseblock3.denselayer11.norm2.bias False\n",
      "denseblock3.denselayer11.conv2.weight False\n",
      "denseblock3.denselayer12.norm1.weight False\n",
      "denseblock3.denselayer12.norm1.bias False\n",
      "denseblock3.denselayer12.conv1.weight False\n",
      "denseblock3.denselayer12.norm2.weight False\n",
      "denseblock3.denselayer12.norm2.bias False\n",
      "denseblock3.denselayer12.conv2.weight False\n",
      "denseblock3.denselayer13.norm1.weight False\n",
      "denseblock3.denselayer13.norm1.bias False\n",
      "denseblock3.denselayer13.conv1.weight False\n",
      "denseblock3.denselayer13.norm2.weight False\n",
      "denseblock3.denselayer13.norm2.bias False\n",
      "denseblock3.denselayer13.conv2.weight False\n",
      "denseblock3.denselayer14.norm1.weight False\n",
      "denseblock3.denselayer14.norm1.bias False\n",
      "denseblock3.denselayer14.conv1.weight False\n",
      "denseblock3.denselayer14.norm2.weight False\n",
      "denseblock3.denselayer14.norm2.bias False\n",
      "denseblock3.denselayer14.conv2.weight False\n",
      "denseblock3.denselayer15.norm1.weight False\n",
      "denseblock3.denselayer15.norm1.bias False\n",
      "denseblock3.denselayer15.conv1.weight False\n",
      "denseblock3.denselayer15.norm2.weight False\n",
      "denseblock3.denselayer15.norm2.bias False\n",
      "denseblock3.denselayer15.conv2.weight False\n",
      "denseblock3.denselayer16.norm1.weight False\n",
      "denseblock3.denselayer16.norm1.bias False\n",
      "denseblock3.denselayer16.conv1.weight False\n",
      "denseblock3.denselayer16.norm2.weight False\n",
      "denseblock3.denselayer16.norm2.bias False\n",
      "denseblock3.denselayer16.conv2.weight False\n",
      "denseblock3.denselayer17.norm1.weight False\n",
      "denseblock3.denselayer17.norm1.bias False\n",
      "denseblock3.denselayer17.conv1.weight False\n",
      "denseblock3.denselayer17.norm2.weight False\n",
      "denseblock3.denselayer17.norm2.bias False\n",
      "denseblock3.denselayer17.conv2.weight False\n",
      "denseblock3.denselayer18.norm1.weight False\n",
      "denseblock3.denselayer18.norm1.bias False\n",
      "denseblock3.denselayer18.conv1.weight False\n",
      "denseblock3.denselayer18.norm2.weight False\n",
      "denseblock3.denselayer18.norm2.bias False\n",
      "denseblock3.denselayer18.conv2.weight False\n",
      "denseblock3.denselayer19.norm1.weight False\n",
      "denseblock3.denselayer19.norm1.bias False\n",
      "denseblock3.denselayer19.conv1.weight False\n",
      "denseblock3.denselayer19.norm2.weight False\n",
      "denseblock3.denselayer19.norm2.bias False\n",
      "denseblock3.denselayer19.conv2.weight False\n",
      "denseblock3.denselayer20.norm1.weight False\n",
      "denseblock3.denselayer20.norm1.bias False\n",
      "denseblock3.denselayer20.conv1.weight False\n",
      "denseblock3.denselayer20.norm2.weight False\n",
      "denseblock3.denselayer20.norm2.bias False\n",
      "denseblock3.denselayer20.conv2.weight False\n",
      "denseblock3.denselayer21.norm1.weight False\n",
      "denseblock3.denselayer21.norm1.bias False\n",
      "denseblock3.denselayer21.conv1.weight False\n",
      "denseblock3.denselayer21.norm2.weight False\n",
      "denseblock3.denselayer21.norm2.bias False\n",
      "denseblock3.denselayer21.conv2.weight False\n",
      "denseblock3.denselayer22.norm1.weight False\n",
      "denseblock3.denselayer22.norm1.bias False\n",
      "denseblock3.denselayer22.conv1.weight False\n",
      "denseblock3.denselayer22.norm2.weight False\n",
      "denseblock3.denselayer22.norm2.bias False\n",
      "denseblock3.denselayer22.conv2.weight False\n",
      "denseblock3.denselayer23.norm1.weight False\n",
      "denseblock3.denselayer23.norm1.bias False\n",
      "denseblock3.denselayer23.conv1.weight False\n",
      "denseblock3.denselayer23.norm2.weight False\n",
      "denseblock3.denselayer23.norm2.bias False\n",
      "denseblock3.denselayer23.conv2.weight False\n",
      "denseblock3.denselayer24.norm1.weight False\n",
      "denseblock3.denselayer24.norm1.bias False\n",
      "denseblock3.denselayer24.conv1.weight False\n",
      "denseblock3.denselayer24.norm2.weight False\n",
      "denseblock3.denselayer24.norm2.bias False\n",
      "denseblock3.denselayer24.conv2.weight False\n",
      "denseblock3.denselayer25.norm1.weight False\n",
      "denseblock3.denselayer25.norm1.bias False\n",
      "denseblock3.denselayer25.conv1.weight False\n",
      "denseblock3.denselayer25.norm2.weight False\n",
      "denseblock3.denselayer25.norm2.bias False\n",
      "denseblock3.denselayer25.conv2.weight False\n",
      "denseblock3.denselayer26.norm1.weight False\n",
      "denseblock3.denselayer26.norm1.bias False\n",
      "denseblock3.denselayer26.conv1.weight False\n",
      "denseblock3.denselayer26.norm2.weight False\n",
      "denseblock3.denselayer26.norm2.bias False\n",
      "denseblock3.denselayer26.conv2.weight False\n",
      "denseblock3.denselayer27.norm1.weight False\n",
      "denseblock3.denselayer27.norm1.bias False\n",
      "denseblock3.denselayer27.conv1.weight False\n",
      "denseblock3.denselayer27.norm2.weight False\n",
      "denseblock3.denselayer27.norm2.bias False\n",
      "denseblock3.denselayer27.conv2.weight False\n",
      "denseblock3.denselayer28.norm1.weight False\n",
      "denseblock3.denselayer28.norm1.bias False\n",
      "denseblock3.denselayer28.conv1.weight False\n",
      "denseblock3.denselayer28.norm2.weight False\n",
      "denseblock3.denselayer28.norm2.bias False\n",
      "denseblock3.denselayer28.conv2.weight False\n",
      "denseblock3.denselayer29.norm1.weight False\n",
      "denseblock3.denselayer29.norm1.bias False\n",
      "denseblock3.denselayer29.conv1.weight False\n",
      "denseblock3.denselayer29.norm2.weight False\n",
      "denseblock3.denselayer29.norm2.bias False\n",
      "denseblock3.denselayer29.conv2.weight False\n",
      "denseblock3.denselayer30.norm1.weight False\n",
      "denseblock3.denselayer30.norm1.bias False\n",
      "denseblock3.denselayer30.conv1.weight False\n",
      "denseblock3.denselayer30.norm2.weight False\n",
      "denseblock3.denselayer30.norm2.bias False\n",
      "denseblock3.denselayer30.conv2.weight False\n",
      "denseblock3.denselayer31.norm1.weight False\n",
      "denseblock3.denselayer31.norm1.bias False\n",
      "denseblock3.denselayer31.conv1.weight False\n",
      "denseblock3.denselayer31.norm2.weight False\n",
      "denseblock3.denselayer31.norm2.bias False\n",
      "denseblock3.denselayer31.conv2.weight False\n",
      "denseblock3.denselayer32.norm1.weight False\n",
      "denseblock3.denselayer32.norm1.bias False\n",
      "denseblock3.denselayer32.conv1.weight False\n",
      "denseblock3.denselayer32.norm2.weight False\n",
      "denseblock3.denselayer32.norm2.bias False\n",
      "denseblock3.denselayer32.conv2.weight False\n",
      "denseblock3.denselayer33.norm1.weight False\n",
      "denseblock3.denselayer33.norm1.bias False\n",
      "denseblock3.denselayer33.conv1.weight False\n",
      "denseblock3.denselayer33.norm2.weight False\n",
      "denseblock3.denselayer33.norm2.bias False\n",
      "denseblock3.denselayer33.conv2.weight False\n",
      "denseblock3.denselayer34.norm1.weight False\n",
      "denseblock3.denselayer34.norm1.bias False\n",
      "denseblock3.denselayer34.conv1.weight False\n",
      "denseblock3.denselayer34.norm2.weight False\n",
      "denseblock3.denselayer34.norm2.bias False\n",
      "denseblock3.denselayer34.conv2.weight False\n",
      "denseblock3.denselayer35.norm1.weight False\n",
      "denseblock3.denselayer35.norm1.bias False\n",
      "denseblock3.denselayer35.conv1.weight False\n",
      "denseblock3.denselayer35.norm2.weight False\n",
      "denseblock3.denselayer35.norm2.bias False\n",
      "denseblock3.denselayer35.conv2.weight False\n",
      "denseblock3.denselayer36.norm1.weight False\n",
      "denseblock3.denselayer36.norm1.bias False\n",
      "denseblock3.denselayer36.conv1.weight False\n",
      "denseblock3.denselayer36.norm2.weight False\n",
      "denseblock3.denselayer36.norm2.bias False\n",
      "denseblock3.denselayer36.conv2.weight False\n",
      "denseblock3.denselayer37.norm1.weight False\n",
      "denseblock3.denselayer37.norm1.bias False\n",
      "denseblock3.denselayer37.conv1.weight False\n",
      "denseblock3.denselayer37.norm2.weight False\n",
      "denseblock3.denselayer37.norm2.bias False\n",
      "denseblock3.denselayer37.conv2.weight False\n",
      "denseblock3.denselayer38.norm1.weight False\n",
      "denseblock3.denselayer38.norm1.bias False\n",
      "denseblock3.denselayer38.conv1.weight False\n",
      "denseblock3.denselayer38.norm2.weight False\n",
      "denseblock3.denselayer38.norm2.bias False\n",
      "denseblock3.denselayer38.conv2.weight False\n",
      "denseblock3.denselayer39.norm1.weight False\n",
      "denseblock3.denselayer39.norm1.bias False\n",
      "denseblock3.denselayer39.conv1.weight False\n",
      "denseblock3.denselayer39.norm2.weight False\n",
      "denseblock3.denselayer39.norm2.bias False\n",
      "denseblock3.denselayer39.conv2.weight False\n",
      "denseblock3.denselayer40.norm1.weight False\n",
      "denseblock3.denselayer40.norm1.bias False\n",
      "denseblock3.denselayer40.conv1.weight False\n",
      "denseblock3.denselayer40.norm2.weight False\n",
      "denseblock3.denselayer40.norm2.bias False\n",
      "denseblock3.denselayer40.conv2.weight False\n",
      "denseblock3.denselayer41.norm1.weight False\n",
      "denseblock3.denselayer41.norm1.bias False\n",
      "denseblock3.denselayer41.conv1.weight False\n",
      "denseblock3.denselayer41.norm2.weight False\n",
      "denseblock3.denselayer41.norm2.bias False\n",
      "denseblock3.denselayer41.conv2.weight False\n",
      "denseblock3.denselayer42.norm1.weight False\n",
      "denseblock3.denselayer42.norm1.bias False\n",
      "denseblock3.denselayer42.conv1.weight False\n",
      "denseblock3.denselayer42.norm2.weight False\n",
      "denseblock3.denselayer42.norm2.bias False\n",
      "denseblock3.denselayer42.conv2.weight False\n",
      "denseblock3.denselayer43.norm1.weight False\n",
      "denseblock3.denselayer43.norm1.bias False\n",
      "denseblock3.denselayer43.conv1.weight False\n",
      "denseblock3.denselayer43.norm2.weight False\n",
      "denseblock3.denselayer43.norm2.bias False\n",
      "denseblock3.denselayer43.conv2.weight False\n",
      "denseblock3.denselayer44.norm1.weight False\n",
      "denseblock3.denselayer44.norm1.bias False\n",
      "denseblock3.denselayer44.conv1.weight False\n",
      "denseblock3.denselayer44.norm2.weight False\n",
      "denseblock3.denselayer44.norm2.bias False\n",
      "denseblock3.denselayer44.conv2.weight False\n",
      "denseblock3.denselayer45.norm1.weight False\n",
      "denseblock3.denselayer45.norm1.bias False\n",
      "denseblock3.denselayer45.conv1.weight False\n",
      "denseblock3.denselayer45.norm2.weight False\n",
      "denseblock3.denselayer45.norm2.bias False\n",
      "denseblock3.denselayer45.conv2.weight False\n",
      "denseblock3.denselayer46.norm1.weight False\n",
      "denseblock3.denselayer46.norm1.bias False\n",
      "denseblock3.denselayer46.conv1.weight False\n",
      "denseblock3.denselayer46.norm2.weight False\n",
      "denseblock3.denselayer46.norm2.bias False\n",
      "denseblock3.denselayer46.conv2.weight False\n",
      "denseblock3.denselayer47.norm1.weight False\n",
      "denseblock3.denselayer47.norm1.bias False\n",
      "denseblock3.denselayer47.conv1.weight False\n",
      "denseblock3.denselayer47.norm2.weight False\n",
      "denseblock3.denselayer47.norm2.bias False\n",
      "denseblock3.denselayer47.conv2.weight False\n",
      "denseblock3.denselayer48.norm1.weight False\n",
      "denseblock3.denselayer48.norm1.bias False\n",
      "denseblock3.denselayer48.conv1.weight False\n",
      "denseblock3.denselayer48.norm2.weight False\n",
      "denseblock3.denselayer48.norm2.bias False\n",
      "denseblock3.denselayer48.conv2.weight False\n",
      "transition3.norm.weight False\n",
      "transition3.norm.bias False\n",
      "transition3.conv.weight False\n",
      "denseblock4.denselayer1.norm1.weight False\n",
      "denseblock4.denselayer1.norm1.bias False\n",
      "denseblock4.denselayer1.conv1.weight False\n",
      "denseblock4.denselayer1.norm2.weight False\n",
      "denseblock4.denselayer1.norm2.bias False\n",
      "denseblock4.denselayer1.conv2.weight False\n",
      "denseblock4.denselayer2.norm1.weight False\n",
      "denseblock4.denselayer2.norm1.bias False\n",
      "denseblock4.denselayer2.conv1.weight False\n",
      "denseblock4.denselayer2.norm2.weight False\n",
      "denseblock4.denselayer2.norm2.bias False\n",
      "denseblock4.denselayer2.conv2.weight False\n",
      "denseblock4.denselayer3.norm1.weight False\n",
      "denseblock4.denselayer3.norm1.bias False\n",
      "denseblock4.denselayer3.conv1.weight False\n",
      "denseblock4.denselayer3.norm2.weight False\n",
      "denseblock4.denselayer3.norm2.bias False\n",
      "denseblock4.denselayer3.conv2.weight False\n",
      "denseblock4.denselayer4.norm1.weight False\n",
      "denseblock4.denselayer4.norm1.bias False\n",
      "denseblock4.denselayer4.conv1.weight False\n",
      "denseblock4.denselayer4.norm2.weight False\n",
      "denseblock4.denselayer4.norm2.bias False\n",
      "denseblock4.denselayer4.conv2.weight False\n",
      "denseblock4.denselayer5.norm1.weight False\n",
      "denseblock4.denselayer5.norm1.bias False\n",
      "denseblock4.denselayer5.conv1.weight False\n",
      "denseblock4.denselayer5.norm2.weight False\n",
      "denseblock4.denselayer5.norm2.bias False\n",
      "denseblock4.denselayer5.conv2.weight False\n",
      "denseblock4.denselayer6.norm1.weight False\n",
      "denseblock4.denselayer6.norm1.bias False\n",
      "denseblock4.denselayer6.conv1.weight False\n",
      "denseblock4.denselayer6.norm2.weight False\n",
      "denseblock4.denselayer6.norm2.bias False\n",
      "denseblock4.denselayer6.conv2.weight False\n",
      "denseblock4.denselayer7.norm1.weight False\n",
      "denseblock4.denselayer7.norm1.bias False\n",
      "denseblock4.denselayer7.conv1.weight False\n",
      "denseblock4.denselayer7.norm2.weight False\n",
      "denseblock4.denselayer7.norm2.bias False\n",
      "denseblock4.denselayer7.conv2.weight False\n",
      "denseblock4.denselayer8.norm1.weight False\n",
      "denseblock4.denselayer8.norm1.bias False\n",
      "denseblock4.denselayer8.conv1.weight False\n",
      "denseblock4.denselayer8.norm2.weight False\n",
      "denseblock4.denselayer8.norm2.bias False\n",
      "denseblock4.denselayer8.conv2.weight False\n",
      "denseblock4.denselayer9.norm1.weight False\n",
      "denseblock4.denselayer9.norm1.bias False\n",
      "denseblock4.denselayer9.conv1.weight False\n",
      "denseblock4.denselayer9.norm2.weight False\n",
      "denseblock4.denselayer9.norm2.bias False\n",
      "denseblock4.denselayer9.conv2.weight False\n",
      "denseblock4.denselayer10.norm1.weight False\n",
      "denseblock4.denselayer10.norm1.bias False\n",
      "denseblock4.denselayer10.conv1.weight False\n",
      "denseblock4.denselayer10.norm2.weight False\n",
      "denseblock4.denselayer10.norm2.bias False\n",
      "denseblock4.denselayer10.conv2.weight False\n",
      "denseblock4.denselayer11.norm1.weight False\n",
      "denseblock4.denselayer11.norm1.bias False\n",
      "denseblock4.denselayer11.conv1.weight False\n",
      "denseblock4.denselayer11.norm2.weight False\n",
      "denseblock4.denselayer11.norm2.bias False\n",
      "denseblock4.denselayer11.conv2.weight False\n",
      "denseblock4.denselayer12.norm1.weight False\n",
      "denseblock4.denselayer12.norm1.bias False\n",
      "denseblock4.denselayer12.conv1.weight False\n",
      "denseblock4.denselayer12.norm2.weight False\n",
      "denseblock4.denselayer12.norm2.bias False\n",
      "denseblock4.denselayer12.conv2.weight False\n",
      "denseblock4.denselayer13.norm1.weight False\n",
      "denseblock4.denselayer13.norm1.bias False\n",
      "denseblock4.denselayer13.conv1.weight False\n",
      "denseblock4.denselayer13.norm2.weight False\n",
      "denseblock4.denselayer13.norm2.bias False\n",
      "denseblock4.denselayer13.conv2.weight False\n",
      "denseblock4.denselayer14.norm1.weight False\n",
      "denseblock4.denselayer14.norm1.bias False\n",
      "denseblock4.denselayer14.conv1.weight False\n",
      "denseblock4.denselayer14.norm2.weight False\n",
      "denseblock4.denselayer14.norm2.bias False\n",
      "denseblock4.denselayer14.conv2.weight False\n",
      "denseblock4.denselayer15.norm1.weight False\n",
      "denseblock4.denselayer15.norm1.bias False\n",
      "denseblock4.denselayer15.conv1.weight False\n",
      "denseblock4.denselayer15.norm2.weight False\n",
      "denseblock4.denselayer15.norm2.bias False\n",
      "denseblock4.denselayer15.conv2.weight False\n",
      "denseblock4.denselayer16.norm1.weight False\n",
      "denseblock4.denselayer16.norm1.bias False\n",
      "denseblock4.denselayer16.conv1.weight False\n",
      "denseblock4.denselayer16.norm2.weight False\n",
      "denseblock4.denselayer16.norm2.bias False\n",
      "denseblock4.denselayer16.conv2.weight False\n",
      "denseblock4.denselayer17.norm1.weight False\n",
      "denseblock4.denselayer17.norm1.bias False\n",
      "denseblock4.denselayer17.conv1.weight False\n",
      "denseblock4.denselayer17.norm2.weight False\n",
      "denseblock4.denselayer17.norm2.bias False\n",
      "denseblock4.denselayer17.conv2.weight False\n",
      "denseblock4.denselayer18.norm1.weight False\n",
      "denseblock4.denselayer18.norm1.bias False\n",
      "denseblock4.denselayer18.conv1.weight False\n",
      "denseblock4.denselayer18.norm2.weight False\n",
      "denseblock4.denselayer18.norm2.bias False\n",
      "denseblock4.denselayer18.conv2.weight False\n",
      "denseblock4.denselayer19.norm1.weight False\n",
      "denseblock4.denselayer19.norm1.bias False\n",
      "denseblock4.denselayer19.conv1.weight False\n",
      "denseblock4.denselayer19.norm2.weight False\n",
      "denseblock4.denselayer19.norm2.bias False\n",
      "denseblock4.denselayer19.conv2.weight False\n",
      "denseblock4.denselayer20.norm1.weight False\n",
      "denseblock4.denselayer20.norm1.bias False\n",
      "denseblock4.denselayer20.conv1.weight False\n",
      "denseblock4.denselayer20.norm2.weight False\n",
      "denseblock4.denselayer20.norm2.bias False\n",
      "denseblock4.denselayer20.conv2.weight False\n",
      "denseblock4.denselayer21.norm1.weight False\n",
      "denseblock4.denselayer21.norm1.bias False\n",
      "denseblock4.denselayer21.conv1.weight False\n",
      "denseblock4.denselayer21.norm2.weight False\n",
      "denseblock4.denselayer21.norm2.bias False\n",
      "denseblock4.denselayer21.conv2.weight False\n",
      "denseblock4.denselayer22.norm1.weight False\n",
      "denseblock4.denselayer22.norm1.bias False\n",
      "denseblock4.denselayer22.conv1.weight False\n",
      "denseblock4.denselayer22.norm2.weight False\n",
      "denseblock4.denselayer22.norm2.bias False\n",
      "denseblock4.denselayer22.conv2.weight False\n",
      "denseblock4.denselayer23.norm1.weight False\n",
      "denseblock4.denselayer23.norm1.bias False\n",
      "denseblock4.denselayer23.conv1.weight False\n",
      "denseblock4.denselayer23.norm2.weight False\n",
      "denseblock4.denselayer23.norm2.bias False\n",
      "denseblock4.denselayer23.conv2.weight False\n",
      "denseblock4.denselayer24.norm1.weight False\n",
      "denseblock4.denselayer24.norm1.bias False\n",
      "denseblock4.denselayer24.conv1.weight False\n",
      "denseblock4.denselayer24.norm2.weight False\n",
      "denseblock4.denselayer24.norm2.bias False\n",
      "denseblock4.denselayer24.conv2.weight False\n",
      "denseblock4.denselayer25.norm1.weight False\n",
      "denseblock4.denselayer25.norm1.bias False\n",
      "denseblock4.denselayer25.conv1.weight False\n",
      "denseblock4.denselayer25.norm2.weight False\n",
      "denseblock4.denselayer25.norm2.bias False\n",
      "denseblock4.denselayer25.conv2.weight False\n",
      "denseblock4.denselayer26.norm1.weight False\n",
      "denseblock4.denselayer26.norm1.bias False\n",
      "denseblock4.denselayer26.conv1.weight False\n",
      "denseblock4.denselayer26.norm2.weight False\n",
      "denseblock4.denselayer26.norm2.bias False\n",
      "denseblock4.denselayer26.conv2.weight False\n",
      "denseblock4.denselayer27.norm1.weight False\n",
      "denseblock4.denselayer27.norm1.bias False\n",
      "denseblock4.denselayer27.conv1.weight False\n",
      "denseblock4.denselayer27.norm2.weight False\n",
      "denseblock4.denselayer27.norm2.bias False\n",
      "denseblock4.denselayer27.conv2.weight False\n",
      "denseblock4.denselayer28.norm1.weight False\n",
      "denseblock4.denselayer28.norm1.bias False\n",
      "denseblock4.denselayer28.conv1.weight False\n",
      "denseblock4.denselayer28.norm2.weight False\n",
      "denseblock4.denselayer28.norm2.bias False\n",
      "denseblock4.denselayer28.conv2.weight False\n",
      "denseblock4.denselayer29.norm1.weight False\n",
      "denseblock4.denselayer29.norm1.bias False\n",
      "denseblock4.denselayer29.conv1.weight False\n",
      "denseblock4.denselayer29.norm2.weight False\n",
      "denseblock4.denselayer29.norm2.bias False\n",
      "denseblock4.denselayer29.conv2.weight False\n",
      "denseblock4.denselayer30.norm1.weight False\n",
      "denseblock4.denselayer30.norm1.bias False\n",
      "denseblock4.denselayer30.conv1.weight False\n",
      "denseblock4.denselayer30.norm2.weight False\n",
      "denseblock4.denselayer30.norm2.bias False\n",
      "denseblock4.denselayer30.conv2.weight False\n",
      "denseblock4.denselayer31.norm1.weight False\n",
      "denseblock4.denselayer31.norm1.bias False\n",
      "denseblock4.denselayer31.conv1.weight False\n",
      "denseblock4.denselayer31.norm2.weight False\n",
      "denseblock4.denselayer31.norm2.bias False\n",
      "denseblock4.denselayer31.conv2.weight False\n",
      "denseblock4.denselayer32.norm1.weight False\n",
      "denseblock4.denselayer32.norm1.bias False\n",
      "denseblock4.denselayer32.conv1.weight False\n",
      "denseblock4.denselayer32.norm2.weight False\n",
      "denseblock4.denselayer32.norm2.bias False\n",
      "denseblock4.denselayer32.conv2.weight False\n",
      "norm5.weight False\n",
      "norm5.bias False\n",
      "weight True\n",
      "bias True\n"
     ]
    }
   ],
   "source": [
    "#Freeze all layers first\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Then unfreeze last classification layer only for feature extract\n",
    "for param in model_ft.classifier.parameters():\n",
    "    param.requires_grad = True    \n",
    "\n",
    "    \n",
    "# To view which layers are freeze and which layers are not freezed:\n",
    "for name, child in model_ft.named_children():\n",
    "  for name_2, params in child.named_parameters():\n",
    "    print(name_2, params.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr[0.0001], Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.2195 Acc: 0.9437\n",
      "valid Loss: 0.1502 Acc: 0.9743\n",
      "\n",
      "lr[1e-05], Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.2207 Acc: 0.9435\n",
      "valid Loss: 0.1460 Acc: 0.9743\n",
      "\n",
      "lr[1e-05], Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.2390 Acc: 0.9391\n",
      "valid Loss: 0.1470 Acc: 0.9743\n",
      "\n",
      "lr[1e-05], Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.2065 Acc: 0.9457\n",
      "valid Loss: 0.1514 Acc: 0.9694\n",
      "\n",
      "lr[1e-05], Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.2270 Acc: 0.9402\n",
      "valid Loss: 0.1482 Acc: 0.9707\n",
      "\n",
      "lr[1e-05], Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.2234 Acc: 0.9415\n",
      "valid Loss: 0.1530 Acc: 0.9731\n",
      "\n",
      "lr[1e-05], Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.2296 Acc: 0.9379\n",
      "valid Loss: 0.1499 Acc: 0.9694\n",
      "\n",
      "lr[1e-05], Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.2195 Acc: 0.9420\n",
      "valid Loss: 0.1497 Acc: 0.9707\n",
      "\n",
      "lr[1e-05], Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.2147 Acc: 0.9444\n",
      "valid Loss: 0.1503 Acc: 0.9719\n",
      "\n",
      "lr[1e-05], Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.2201 Acc: 0.9417\n",
      "valid Loss: 0.1491 Acc: 0.9743\n",
      "\n",
      "lr[1e-05], Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.2218 Acc: 0.9417\n",
      "valid Loss: 0.1493 Acc: 0.9743\n",
      "\n",
      "lr[1e-05], Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.2327 Acc: 0.9408\n",
      "valid Loss: 0.1487 Acc: 0.9756\n",
      "\n",
      "lr[1e-05], Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.2232 Acc: 0.9428\n",
      "valid Loss: 0.1495 Acc: 0.9719\n",
      "\n",
      "lr[1e-05], Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.2360 Acc: 0.9396\n",
      "valid Loss: 0.1498 Acc: 0.9743\n",
      "\n",
      "lr[1e-05], Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.2240 Acc: 0.9437\n",
      "valid Loss: 0.1459 Acc: 0.9743\n",
      "\n",
      "lr[1e-05], Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.2124 Acc: 0.9438\n",
      "valid Loss: 0.1506 Acc: 0.9756\n",
      "\n",
      "lr[1e-05], Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.2258 Acc: 0.9408\n",
      "valid Loss: 0.1503 Acc: 0.9707\n",
      "\n",
      "lr[1e-05], Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.2233 Acc: 0.9409\n",
      "valid Loss: 0.1501 Acc: 0.9707\n",
      "\n",
      "lr[1e-05], Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.2340 Acc: 0.9421\n",
      "valid Loss: 0.1545 Acc: 0.9658\n",
      "\n",
      "lr[1e-05], Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.2094 Acc: 0.9464\n",
      "valid Loss: 0.1467 Acc: 0.9731\n",
      "\n",
      "lr[1e-05], Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.2228 Acc: 0.9412\n",
      "valid Loss: 0.1468 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.2137 Acc: 0.9463\n",
      "valid Loss: 0.1464 Acc: 0.9719\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.2225 Acc: 0.9408\n",
      "valid Loss: 0.1452 Acc: 0.9768\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.2060 Acc: 0.9452\n",
      "valid Loss: 0.1527 Acc: 0.9694\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.2102 Acc: 0.9466\n",
      "valid Loss: 0.1453 Acc: 0.9719\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.2114 Acc: 0.9454\n",
      "valid Loss: 0.1470 Acc: 0.9719\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.2311 Acc: 0.9399\n",
      "valid Loss: 0.1469 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.2297 Acc: 0.9370\n",
      "valid Loss: 0.1467 Acc: 0.9719\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.2204 Acc: 0.9415\n",
      "valid Loss: 0.1512 Acc: 0.9719\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.2232 Acc: 0.9400\n",
      "valid Loss: 0.1481 Acc: 0.9694\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.2098 Acc: 0.9489\n",
      "valid Loss: 0.1453 Acc: 0.9743\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.2321 Acc: 0.9385\n",
      "valid Loss: 0.1550 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.2183 Acc: 0.9426\n",
      "valid Loss: 0.1453 Acc: 0.9768\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.2249 Acc: 0.9412\n",
      "valid Loss: 0.1493 Acc: 0.9743\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.2289 Acc: 0.9400\n",
      "valid Loss: 0.1491 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.2312 Acc: 0.9420\n",
      "valid Loss: 0.1480 Acc: 0.9719\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.2331 Acc: 0.9420\n",
      "valid Loss: 0.1465 Acc: 0.9743\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.2207 Acc: 0.9382\n",
      "valid Loss: 0.1521 Acc: 0.9658\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.2215 Acc: 0.9428\n",
      "valid Loss: 0.1513 Acc: 0.9670\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.2157 Acc: 0.9429\n",
      "valid Loss: 0.1441 Acc: 0.9719\n",
      "\n",
      "lr[1.0000000000000002e-06], Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.2117 Acc: 0.9440\n",
      "valid Loss: 0.1506 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.2300 Acc: 0.9397\n",
      "valid Loss: 0.1475 Acc: 0.9768\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.2232 Acc: 0.9406\n",
      "valid Loss: 0.1478 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.2141 Acc: 0.9418\n",
      "valid Loss: 0.1553 Acc: 0.9645\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.2276 Acc: 0.9415\n",
      "valid Loss: 0.1487 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.2211 Acc: 0.9412\n",
      "valid Loss: 0.1489 Acc: 0.9682\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.2126 Acc: 0.9428\n",
      "valid Loss: 0.1480 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.2161 Acc: 0.9450\n",
      "valid Loss: 0.1475 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.2314 Acc: 0.9382\n",
      "valid Loss: 0.1474 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.2121 Acc: 0.9428\n",
      "valid Loss: 0.1490 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.2235 Acc: 0.9443\n",
      "valid Loss: 0.1472 Acc: 0.9719\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.2190 Acc: 0.9391\n",
      "valid Loss: 0.1490 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.2217 Acc: 0.9420\n",
      "valid Loss: 0.1478 Acc: 0.9694\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.2190 Acc: 0.9426\n",
      "valid Loss: 0.1483 Acc: 0.9719\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.2322 Acc: 0.9388\n",
      "valid Loss: 0.1480 Acc: 0.9743\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.2067 Acc: 0.9473\n",
      "valid Loss: 0.1486 Acc: 0.9694\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.2139 Acc: 0.9460\n",
      "valid Loss: 0.1461 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.2160 Acc: 0.9435\n",
      "valid Loss: 0.1465 Acc: 0.9719\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.2202 Acc: 0.9418\n",
      "valid Loss: 0.1519 Acc: 0.9694\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.2238 Acc: 0.9437\n",
      "valid Loss: 0.1510 Acc: 0.9743\n",
      "\n",
      "lr[1.0000000000000002e-07], Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.2377 Acc: 0.9379\n",
      "valid Loss: 0.1489 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.2092 Acc: 0.9458\n",
      "valid Loss: 0.1463 Acc: 0.9743\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.2180 Acc: 0.9423\n",
      "valid Loss: 0.1530 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.2184 Acc: 0.9418\n",
      "valid Loss: 0.1457 Acc: 0.9743\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.2268 Acc: 0.9402\n",
      "valid Loss: 0.1469 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.2268 Acc: 0.9421\n",
      "valid Loss: 0.1498 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.2074 Acc: 0.9475\n",
      "valid Loss: 0.1508 Acc: 0.9756\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.2335 Acc: 0.9414\n",
      "valid Loss: 0.1519 Acc: 0.9694\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.2318 Acc: 0.9400\n",
      "valid Loss: 0.1546 Acc: 0.9682\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.2127 Acc: 0.9437\n",
      "valid Loss: 0.1465 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.2268 Acc: 0.9394\n",
      "valid Loss: 0.1474 Acc: 0.9719\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.2219 Acc: 0.9428\n",
      "valid Loss: 0.1467 Acc: 0.9743\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.2234 Acc: 0.9415\n",
      "valid Loss: 0.1453 Acc: 0.9756\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.2173 Acc: 0.9440\n",
      "valid Loss: 0.1505 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.2207 Acc: 0.9396\n",
      "valid Loss: 0.1486 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 75/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2363 Acc: 0.9399\n",
      "valid Loss: 0.1480 Acc: 0.9756\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.2257 Acc: 0.9425\n",
      "valid Loss: 0.1471 Acc: 0.9719\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.2161 Acc: 0.9423\n",
      "valid Loss: 0.1535 Acc: 0.9682\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.2121 Acc: 0.9461\n",
      "valid Loss: 0.1479 Acc: 0.9694\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.2027 Acc: 0.9470\n",
      "valid Loss: 0.1527 Acc: 0.9743\n",
      "\n",
      "lr[1.0000000000000004e-08], Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.2084 Acc: 0.9481\n",
      "valid Loss: 0.1443 Acc: 0.9768\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.2183 Acc: 0.9426\n",
      "valid Loss: 0.1483 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.2240 Acc: 0.9399\n",
      "valid Loss: 0.1484 Acc: 0.9694\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.2171 Acc: 0.9428\n",
      "valid Loss: 0.1536 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.2309 Acc: 0.9408\n",
      "valid Loss: 0.1463 Acc: 0.9768\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.2364 Acc: 0.9363\n",
      "valid Loss: 0.1479 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.2313 Acc: 0.9386\n",
      "valid Loss: 0.1501 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.2196 Acc: 0.9421\n",
      "valid Loss: 0.1506 Acc: 0.9694\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.2253 Acc: 0.9403\n",
      "valid Loss: 0.1504 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.2094 Acc: 0.9461\n",
      "valid Loss: 0.1505 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.2228 Acc: 0.9452\n",
      "valid Loss: 0.1497 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.2193 Acc: 0.9415\n",
      "valid Loss: 0.1482 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.2227 Acc: 0.9440\n",
      "valid Loss: 0.1483 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.2238 Acc: 0.9463\n",
      "valid Loss: 0.1528 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.2241 Acc: 0.9389\n",
      "valid Loss: 0.1473 Acc: 0.9719\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.2263 Acc: 0.9418\n",
      "valid Loss: 0.1495 Acc: 0.9731\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.2359 Acc: 0.9396\n",
      "valid Loss: 0.1481 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.2190 Acc: 0.9414\n",
      "valid Loss: 0.1447 Acc: 0.9756\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 98/99\n",
      "----------\n",
      "train Loss: 0.2113 Acc: 0.9454\n",
      "valid Loss: 0.1534 Acc: 0.9707\n",
      "\n",
      "lr[1.0000000000000003e-09], Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.2175 Acc: 0.9426\n",
      "valid Loss: 0.1511 Acc: 0.9707\n",
      "\n",
      "Training complete in 39m 57s\n",
      "Best val Acc: 0.976773\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=1e-5, momentum=0.4)\n",
    "# Decay LR by a factor of 0.1 every ? epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UnFreeze all layers first\n",
    "#for param in model_ft.parameters():\n",
    "#    param.requires_grad = True "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
