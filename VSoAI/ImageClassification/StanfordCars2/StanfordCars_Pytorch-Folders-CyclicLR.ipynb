{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-283c0d40bede>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai'"
     ]
    }
   ],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import fastai\n",
    "print(\"fastai: \",fastai.__version__)\n",
    "import torch\n",
    "print(\"Torch: \",torch.__version__)\n",
    "import torchvision\n",
    "print(\"Torchvision: \",torchvision.__version__)\n",
    "import sklearn\n",
    "print(\"sklearn: \",sklearn.__version__)\n",
    "import sys\n",
    "print(\"Python: \",sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    devID=torch.cuda.current_device()\n",
    "    print(\"GPU: \",torch.cuda.get_device_name(devID))\n",
    "else:\n",
    "    print(\"Torch Cuda not avaialbe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../../../../../data/StanfordCars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PATH.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = PATH/'cars_train'\n",
    "path_test = PATH/'cars_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = get_image_files(path_train)\n",
    "fnames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of images: {len(fnames)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = Path(f'{path_train}/00001.jpg')\n",
    "img = plt.imread(pic)\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(f'{PATH}/devkit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cars class labels matlab file\n",
    "class_annos = scipy.io.loadmat(PATH/'devkit/cars_meta.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_annos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_annos[\"class_names\"][0][14][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train annotiation file\n",
    "train_annos = scipy.io.loadmat(PATH/'devkit/cars_train_annos.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matlab file decoding mask inside 'annotations' array\n",
    "# dtype=[('bbox_x1', 'O'), ('bbox_y1', 'O'), ('bbox_x2', 'O'), ('bbox_y2', 'O'), ('class', 'O'), ('fname', 'O')])}\n",
    "train_annos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract item 0 class\n",
    "train_annos[\"annotations\"][0][0][4][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract itme 0 file name\n",
    "train_annos[\"annotations\"][0][0][5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_set = len(train_annos[\"annotations\"][0])\n",
    "print(f'Total number of data items in dataset: {total_set}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_total = len(class_annos[\"class_names\"][0])\n",
    "print(f'Total number of classes: {classes_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop to extract file name and class number into list\n",
    "#                                                     fname                                    class\n",
    "classes = [[f'cars_train/{train_annos[\"annotations\"][0][i][5][0]}',train_annos[\"annotations\"][0][i][4][0][0]] for i in range(total_set)]\n",
    "classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame from list\n",
    "df = pd.DataFrame(classes, columns = ['name', 'label']) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform class number from [1..196] to [0..195]\n",
    "df['label'] = df['label']-1\n",
    "df['label'].min(), df['label'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify number of unique classes\n",
    "len(df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify length of car class annotations in cars_meta.mat\n",
    "total_labels = len(class_annos[\"class_names\"][0])\n",
    "total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_annos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract class label strings into list\n",
    "labels = [class_annos[\"class_names\"][0][i][0] for i in range(total_labels)]\n",
    "labels[:5], len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating datafreame form list\n",
    "df_label = pd.DataFrame(labels)\n",
    "print(f' dataframe shape: {df_label.shape}')\n",
    "df_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frame new_labels of class labels sorted according to class numbers\n",
    "new_labels = pd.DataFrame(df_label[0][df['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "new_labels.reset_index(inplace=True)\n",
    "new_labels=new_labels.drop(columns='index', axis=1)\n",
    "new_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reaplace integer class numbers with string  class labels\n",
    "df['label'] = new_labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8144,), (8144,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create python data dictionary {}, path/file and image size(x,y)\n",
    "# ps very long processing time\n",
    "e_d = {k: PIL.Image.open(k).size for k in fnames}\n",
    "#transform to list\n",
    "row_sz, col_sz = list(zip(*e_d.values()))\n",
    "# and to numpy\n",
    "row_sz = np.array(row_sz); col_sz = np.array(col_sz)\n",
    "row_sz.shape, col_sz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(row_sz);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(col_sz);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of all classes\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for NoN values\n",
    "df['label'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe into train and test\n",
    "import random\n",
    "np.random.seed(42)\n",
    "\n",
    "def splitDF(df, train_ratio):\n",
    "    df['random_number'] = np.random.rand(len(df))\n",
    "\n",
    "    train = df[df['random_number'] <= train_ratio]\n",
    "    test = df[df['random_number'] > train_ratio]\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = splitDF(df,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6526, 1618)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>random_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cars_train/00001.jpg</td>\n",
       "      <td>Audi TTS Coupe 2012</td>\n",
       "      <td>0.374540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cars_train/00003.jpg</td>\n",
       "      <td>Dodge Dakota Club Cab 2007</td>\n",
       "      <td>0.731994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cars_train/00004.jpg</td>\n",
       "      <td>Hyundai Sonata Hybrid Sedan 2012</td>\n",
       "      <td>0.598658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cars_train/00005.jpg</td>\n",
       "      <td>Ford F-450 Super Duty Crew Cab 2012</td>\n",
       "      <td>0.156019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cars_train/00006.jpg</td>\n",
       "      <td>Geo Metro Convertible 1993</td>\n",
       "      <td>0.155995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cars_train/00007.jpg</td>\n",
       "      <td>Dodge Journey SUV 2012</td>\n",
       "      <td>0.058084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cars_train/00009.jpg</td>\n",
       "      <td>Mitsubishi Lancer Sedan 2012</td>\n",
       "      <td>0.601115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cars_train/00010.jpg</td>\n",
       "      <td>Chevrolet Traverse SUV 2012</td>\n",
       "      <td>0.708073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cars_train/00011.jpg</td>\n",
       "      <td>Buick Verano Sedan 2012</td>\n",
       "      <td>0.020584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cars_train/00014.jpg</td>\n",
       "      <td>Dodge Caravan Minivan 1997</td>\n",
       "      <td>0.212339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                label  random_number\n",
       "0   cars_train/00001.jpg                  Audi TTS Coupe 2012       0.374540\n",
       "2   cars_train/00003.jpg           Dodge Dakota Club Cab 2007       0.731994\n",
       "3   cars_train/00004.jpg     Hyundai Sonata Hybrid Sedan 2012       0.598658\n",
       "4   cars_train/00005.jpg  Ford F-450 Super Duty Crew Cab 2012       0.156019\n",
       "5   cars_train/00006.jpg           Geo Metro Convertible 1993       0.155995\n",
       "6   cars_train/00007.jpg               Dodge Journey SUV 2012       0.058084\n",
       "8   cars_train/00009.jpg         Mitsubishi Lancer Sedan 2012       0.601115\n",
       "9   cars_train/00010.jpg          Chevrolet Traverse SUV 2012       0.708073\n",
       "10  cars_train/00011.jpg              Buick Verano Sedan 2012       0.020584\n",
       "13  cars_train/00014.jpg           Dodge Caravan Minivan 1997       0.212339"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>random_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cars_train/00002.jpg</td>\n",
       "      <td>Acura TL Sedan 2012</td>\n",
       "      <td>0.950714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cars_train/00008.jpg</td>\n",
       "      <td>Dodge Charger Sedan 2012</td>\n",
       "      <td>0.866176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cars_train/00012.jpg</td>\n",
       "      <td>Toyota Sequoia SUV 2012</td>\n",
       "      <td>0.969910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cars_train/00013.jpg</td>\n",
       "      <td>Hyundai Elantra Sedan 2007</td>\n",
       "      <td>0.832443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cars_train/00034.jpg</td>\n",
       "      <td>Hyundai Veracruz SUV 2012</td>\n",
       "      <td>0.948886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                       label  random_number\n",
       "1   cars_train/00002.jpg         Acura TL Sedan 2012       0.950714\n",
       "7   cars_train/00008.jpg    Dodge Charger Sedan 2012       0.866176\n",
       "11  cars_train/00012.jpg     Toyota Sequoia SUV 2012       0.969910\n",
       "12  cars_train/00013.jpg  Hyundai Elantra Sedan 2007       0.832443\n",
       "33  cars_train/00034.jpg   Hyundai Veracruz SUV 2012       0.948886"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_DIR = '/home/norvilr/ml/data/StanfordCars'\n",
    "Model_DIR = '/home/norvilr/ml/github/AI/VSoAI/ImageClassification/StanfordCars2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#create folders based on class labels and copy files\n",
    "#run just once, to create folders and copy files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def createClassFolders():\n",
    "    for folder in df['label']:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if os.getcwd()  != Data_DIR:\n",
    "    os.chdir(Data_DIR)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if not os.path.exists('train'):\n",
    "    os.makedirs('train')    \n",
    "if not os.path.exists('test'):\n",
    "    os.makedirs('test')\n",
    "print(os.listdir())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if os.path.exists('train'):\n",
    "    os.chdir('train')\n",
    "    createClassFolders()\n",
    "if os.path.exists('../test'):\n",
    "    os.chdir('../test')\n",
    "    createClassFolders()    \n",
    "os.chdir('../')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print( 'created class subdirectories in train: ')\n",
    "!find train -mindepth 1 -type d | wc -l\n",
    "print( 'created class subdirectories in train: ')\n",
    "!find test -mindepth 1 -type d | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#copy files into train subdirs\n",
    "for index, row in train.iterrows():\n",
    "    cmd = f'cp -f {row[\"name\"]} train/\"{row[\"label\"]}\"/'\n",
    "    os.popen(cmd) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#copy files into test subdirs\n",
    "for index, row in test.iterrows():\n",
    "    cmd = f'cp -f {row[\"name\"]} test/\"{row[\"label\"]}\"/'\n",
    "    os.popen(cmd) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#return to jupyter notebook directory\n",
    "if os.getcwd()  != Model_DIR:\n",
    "    os.chdir(Model_DIR)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train'\n",
    "val_dir = 'test'\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    train_dir: transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        #transforms.Resize(224),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    val_dir: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Total Count:  196\n"
     ]
    }
   ],
   "source": [
    "classes = os.listdir(f'{Data_DIR}/train')\n",
    "classes.sort()\n",
    "ClassesNumer = len(classes)\n",
    "print(\"Class Total Count: \", ClassesNumer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(Data_DIR, x), transform=data_transforms[x]) for x in [train_dir, val_dir]}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in [train_dir, val_dir]}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [train_dir, val_dir]}\n",
    "\n",
    "class_names = image_datasets[train_dir].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 6571\n",
       "    Root location: /home/norvilr/ml/data/StanfordCars/train"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets[train_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 224, 224]), torch.Size([32]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through the dataloader once\n",
    "trainiter = iter(dataloaders[train_dir])\n",
    "features, labels = next(trainiter)\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [train_dir, val_dir]:\n",
    "            if phase == train_dir:\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == train_dir):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == train_dir:\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == val_dir and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and reset final fully connected layer\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "#model_ft = models.resnet34(pretrained=True)\n",
    "\n",
    "#adding one fully connected layer with output=Classes\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, ClassesNumer)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer_ft = optim.Adam(model.parameters())\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "exp_lr_scheduler = lr_scheduler.CyclicLR(optimizer_ft, base_lr=0.01, max_lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight False\n",
      "weight False\n",
      "bias False\n",
      "0.conv1.weight False\n",
      "0.bn1.weight False\n",
      "0.bn1.bias False\n",
      "0.conv2.weight False\n",
      "0.bn2.weight False\n",
      "0.bn2.bias False\n",
      "0.conv3.weight False\n",
      "0.bn3.weight False\n",
      "0.bn3.bias False\n",
      "0.downsample.0.weight False\n",
      "0.downsample.1.weight False\n",
      "0.downsample.1.bias False\n",
      "1.conv1.weight False\n",
      "1.bn1.weight False\n",
      "1.bn1.bias False\n",
      "1.conv2.weight False\n",
      "1.bn2.weight False\n",
      "1.bn2.bias False\n",
      "1.conv3.weight False\n",
      "1.bn3.weight False\n",
      "1.bn3.bias False\n",
      "2.conv1.weight False\n",
      "2.bn1.weight False\n",
      "2.bn1.bias False\n",
      "2.conv2.weight False\n",
      "2.bn2.weight False\n",
      "2.bn2.bias False\n",
      "2.conv3.weight False\n",
      "2.bn3.weight False\n",
      "2.bn3.bias False\n",
      "0.conv1.weight False\n",
      "0.bn1.weight False\n",
      "0.bn1.bias False\n",
      "0.conv2.weight False\n",
      "0.bn2.weight False\n",
      "0.bn2.bias False\n",
      "0.conv3.weight False\n",
      "0.bn3.weight False\n",
      "0.bn3.bias False\n",
      "0.downsample.0.weight False\n",
      "0.downsample.1.weight False\n",
      "0.downsample.1.bias False\n",
      "1.conv1.weight False\n",
      "1.bn1.weight False\n",
      "1.bn1.bias False\n",
      "1.conv2.weight False\n",
      "1.bn2.weight False\n",
      "1.bn2.bias False\n",
      "1.conv3.weight False\n",
      "1.bn3.weight False\n",
      "1.bn3.bias False\n",
      "2.conv1.weight False\n",
      "2.bn1.weight False\n",
      "2.bn1.bias False\n",
      "2.conv2.weight False\n",
      "2.bn2.weight False\n",
      "2.bn2.bias False\n",
      "2.conv3.weight False\n",
      "2.bn3.weight False\n",
      "2.bn3.bias False\n",
      "3.conv1.weight False\n",
      "3.bn1.weight False\n",
      "3.bn1.bias False\n",
      "3.conv2.weight False\n",
      "3.bn2.weight False\n",
      "3.bn2.bias False\n",
      "3.conv3.weight False\n",
      "3.bn3.weight False\n",
      "3.bn3.bias False\n",
      "4.conv1.weight False\n",
      "4.bn1.weight False\n",
      "4.bn1.bias False\n",
      "4.conv2.weight False\n",
      "4.bn2.weight False\n",
      "4.bn2.bias False\n",
      "4.conv3.weight False\n",
      "4.bn3.weight False\n",
      "4.bn3.bias False\n",
      "5.conv1.weight False\n",
      "5.bn1.weight False\n",
      "5.bn1.bias False\n",
      "5.conv2.weight False\n",
      "5.bn2.weight False\n",
      "5.bn2.bias False\n",
      "5.conv3.weight False\n",
      "5.bn3.weight False\n",
      "5.bn3.bias False\n",
      "6.conv1.weight False\n",
      "6.bn1.weight False\n",
      "6.bn1.bias False\n",
      "6.conv2.weight False\n",
      "6.bn2.weight False\n",
      "6.bn2.bias False\n",
      "6.conv3.weight False\n",
      "6.bn3.weight False\n",
      "6.bn3.bias False\n",
      "7.conv1.weight False\n",
      "7.bn1.weight False\n",
      "7.bn1.bias False\n",
      "7.conv2.weight False\n",
      "7.bn2.weight False\n",
      "7.bn2.bias False\n",
      "7.conv3.weight False\n",
      "7.bn3.weight False\n",
      "7.bn3.bias False\n",
      "0.conv1.weight False\n",
      "0.bn1.weight False\n",
      "0.bn1.bias False\n",
      "0.conv2.weight False\n",
      "0.bn2.weight False\n",
      "0.bn2.bias False\n",
      "0.conv3.weight False\n",
      "0.bn3.weight False\n",
      "0.bn3.bias False\n",
      "0.downsample.0.weight False\n",
      "0.downsample.1.weight False\n",
      "0.downsample.1.bias False\n",
      "1.conv1.weight False\n",
      "1.bn1.weight False\n",
      "1.bn1.bias False\n",
      "1.conv2.weight False\n",
      "1.bn2.weight False\n",
      "1.bn2.bias False\n",
      "1.conv3.weight False\n",
      "1.bn3.weight False\n",
      "1.bn3.bias False\n",
      "2.conv1.weight False\n",
      "2.bn1.weight False\n",
      "2.bn1.bias False\n",
      "2.conv2.weight False\n",
      "2.bn2.weight False\n",
      "2.bn2.bias False\n",
      "2.conv3.weight False\n",
      "2.bn3.weight False\n",
      "2.bn3.bias False\n",
      "3.conv1.weight False\n",
      "3.bn1.weight False\n",
      "3.bn1.bias False\n",
      "3.conv2.weight False\n",
      "3.bn2.weight False\n",
      "3.bn2.bias False\n",
      "3.conv3.weight False\n",
      "3.bn3.weight False\n",
      "3.bn3.bias False\n",
      "4.conv1.weight False\n",
      "4.bn1.weight False\n",
      "4.bn1.bias False\n",
      "4.conv2.weight False\n",
      "4.bn2.weight False\n",
      "4.bn2.bias False\n",
      "4.conv3.weight False\n",
      "4.bn3.weight False\n",
      "4.bn3.bias False\n",
      "5.conv1.weight False\n",
      "5.bn1.weight False\n",
      "5.bn1.bias False\n",
      "5.conv2.weight False\n",
      "5.bn2.weight False\n",
      "5.bn2.bias False\n",
      "5.conv3.weight False\n",
      "5.bn3.weight False\n",
      "5.bn3.bias False\n",
      "6.conv1.weight False\n",
      "6.bn1.weight False\n",
      "6.bn1.bias False\n",
      "6.conv2.weight False\n",
      "6.bn2.weight False\n",
      "6.bn2.bias False\n",
      "6.conv3.weight False\n",
      "6.bn3.weight False\n",
      "6.bn3.bias False\n",
      "7.conv1.weight False\n",
      "7.bn1.weight False\n",
      "7.bn1.bias False\n",
      "7.conv2.weight False\n",
      "7.bn2.weight False\n",
      "7.bn2.bias False\n",
      "7.conv3.weight False\n",
      "7.bn3.weight False\n",
      "7.bn3.bias False\n",
      "8.conv1.weight False\n",
      "8.bn1.weight False\n",
      "8.bn1.bias False\n",
      "8.conv2.weight False\n",
      "8.bn2.weight False\n",
      "8.bn2.bias False\n",
      "8.conv3.weight False\n",
      "8.bn3.weight False\n",
      "8.bn3.bias False\n",
      "9.conv1.weight False\n",
      "9.bn1.weight False\n",
      "9.bn1.bias False\n",
      "9.conv2.weight False\n",
      "9.bn2.weight False\n",
      "9.bn2.bias False\n",
      "9.conv3.weight False\n",
      "9.bn3.weight False\n",
      "9.bn3.bias False\n",
      "10.conv1.weight False\n",
      "10.bn1.weight False\n",
      "10.bn1.bias False\n",
      "10.conv2.weight False\n",
      "10.bn2.weight False\n",
      "10.bn2.bias False\n",
      "10.conv3.weight False\n",
      "10.bn3.weight False\n",
      "10.bn3.bias False\n",
      "11.conv1.weight False\n",
      "11.bn1.weight False\n",
      "11.bn1.bias False\n",
      "11.conv2.weight False\n",
      "11.bn2.weight False\n",
      "11.bn2.bias False\n",
      "11.conv3.weight False\n",
      "11.bn3.weight False\n",
      "11.bn3.bias False\n",
      "12.conv1.weight False\n",
      "12.bn1.weight False\n",
      "12.bn1.bias False\n",
      "12.conv2.weight False\n",
      "12.bn2.weight False\n",
      "12.bn2.bias False\n",
      "12.conv3.weight False\n",
      "12.bn3.weight False\n",
      "12.bn3.bias False\n",
      "13.conv1.weight False\n",
      "13.bn1.weight False\n",
      "13.bn1.bias False\n",
      "13.conv2.weight False\n",
      "13.bn2.weight False\n",
      "13.bn2.bias False\n",
      "13.conv3.weight False\n",
      "13.bn3.weight False\n",
      "13.bn3.bias False\n",
      "14.conv1.weight False\n",
      "14.bn1.weight False\n",
      "14.bn1.bias False\n",
      "14.conv2.weight False\n",
      "14.bn2.weight False\n",
      "14.bn2.bias False\n",
      "14.conv3.weight False\n",
      "14.bn3.weight False\n",
      "14.bn3.bias False\n",
      "15.conv1.weight False\n",
      "15.bn1.weight False\n",
      "15.bn1.bias False\n",
      "15.conv2.weight False\n",
      "15.bn2.weight False\n",
      "15.bn2.bias False\n",
      "15.conv3.weight False\n",
      "15.bn3.weight False\n",
      "15.bn3.bias False\n",
      "16.conv1.weight False\n",
      "16.bn1.weight False\n",
      "16.bn1.bias False\n",
      "16.conv2.weight False\n",
      "16.bn2.weight False\n",
      "16.bn2.bias False\n",
      "16.conv3.weight False\n",
      "16.bn3.weight False\n",
      "16.bn3.bias False\n",
      "17.conv1.weight False\n",
      "17.bn1.weight False\n",
      "17.bn1.bias False\n",
      "17.conv2.weight False\n",
      "17.bn2.weight False\n",
      "17.bn2.bias False\n",
      "17.conv3.weight False\n",
      "17.bn3.weight False\n",
      "17.bn3.bias False\n",
      "18.conv1.weight False\n",
      "18.bn1.weight False\n",
      "18.bn1.bias False\n",
      "18.conv2.weight False\n",
      "18.bn2.weight False\n",
      "18.bn2.bias False\n",
      "18.conv3.weight False\n",
      "18.bn3.weight False\n",
      "18.bn3.bias False\n",
      "19.conv1.weight False\n",
      "19.bn1.weight False\n",
      "19.bn1.bias False\n",
      "19.conv2.weight False\n",
      "19.bn2.weight False\n",
      "19.bn2.bias False\n",
      "19.conv3.weight False\n",
      "19.bn3.weight False\n",
      "19.bn3.bias False\n",
      "20.conv1.weight False\n",
      "20.bn1.weight False\n",
      "20.bn1.bias False\n",
      "20.conv2.weight False\n",
      "20.bn2.weight False\n",
      "20.bn2.bias False\n",
      "20.conv3.weight False\n",
      "20.bn3.weight False\n",
      "20.bn3.bias False\n",
      "21.conv1.weight False\n",
      "21.bn1.weight False\n",
      "21.bn1.bias False\n",
      "21.conv2.weight False\n",
      "21.bn2.weight False\n",
      "21.bn2.bias False\n",
      "21.conv3.weight False\n",
      "21.bn3.weight False\n",
      "21.bn3.bias False\n",
      "22.conv1.weight False\n",
      "22.bn1.weight False\n",
      "22.bn1.bias False\n",
      "22.conv2.weight False\n",
      "22.bn2.weight False\n",
      "22.bn2.bias False\n",
      "22.conv3.weight False\n",
      "22.bn3.weight False\n",
      "22.bn3.bias False\n",
      "23.conv1.weight False\n",
      "23.bn1.weight False\n",
      "23.bn1.bias False\n",
      "23.conv2.weight False\n",
      "23.bn2.weight False\n",
      "23.bn2.bias False\n",
      "23.conv3.weight False\n",
      "23.bn3.weight False\n",
      "23.bn3.bias False\n",
      "24.conv1.weight False\n",
      "24.bn1.weight False\n",
      "24.bn1.bias False\n",
      "24.conv2.weight False\n",
      "24.bn2.weight False\n",
      "24.bn2.bias False\n",
      "24.conv3.weight False\n",
      "24.bn3.weight False\n",
      "24.bn3.bias False\n",
      "25.conv1.weight False\n",
      "25.bn1.weight False\n",
      "25.bn1.bias False\n",
      "25.conv2.weight False\n",
      "25.bn2.weight False\n",
      "25.bn2.bias False\n",
      "25.conv3.weight False\n",
      "25.bn3.weight False\n",
      "25.bn3.bias False\n",
      "26.conv1.weight False\n",
      "26.bn1.weight False\n",
      "26.bn1.bias False\n",
      "26.conv2.weight False\n",
      "26.bn2.weight False\n",
      "26.bn2.bias False\n",
      "26.conv3.weight False\n",
      "26.bn3.weight False\n",
      "26.bn3.bias False\n",
      "27.conv1.weight False\n",
      "27.bn1.weight False\n",
      "27.bn1.bias False\n",
      "27.conv2.weight False\n",
      "27.bn2.weight False\n",
      "27.bn2.bias False\n",
      "27.conv3.weight False\n",
      "27.bn3.weight False\n",
      "27.bn3.bias False\n",
      "28.conv1.weight False\n",
      "28.bn1.weight False\n",
      "28.bn1.bias False\n",
      "28.conv2.weight False\n",
      "28.bn2.weight False\n",
      "28.bn2.bias False\n",
      "28.conv3.weight False\n",
      "28.bn3.weight False\n",
      "28.bn3.bias False\n",
      "29.conv1.weight False\n",
      "29.bn1.weight False\n",
      "29.bn1.bias False\n",
      "29.conv2.weight False\n",
      "29.bn2.weight False\n",
      "29.bn2.bias False\n",
      "29.conv3.weight False\n",
      "29.bn3.weight False\n",
      "29.bn3.bias False\n",
      "30.conv1.weight False\n",
      "30.bn1.weight False\n",
      "30.bn1.bias False\n",
      "30.conv2.weight False\n",
      "30.bn2.weight False\n",
      "30.bn2.bias False\n",
      "30.conv3.weight False\n",
      "30.bn3.weight False\n",
      "30.bn3.bias False\n",
      "31.conv1.weight False\n",
      "31.bn1.weight False\n",
      "31.bn1.bias False\n",
      "31.conv2.weight False\n",
      "31.bn2.weight False\n",
      "31.bn2.bias False\n",
      "31.conv3.weight False\n",
      "31.bn3.weight False\n",
      "31.bn3.bias False\n",
      "32.conv1.weight False\n",
      "32.bn1.weight False\n",
      "32.bn1.bias False\n",
      "32.conv2.weight False\n",
      "32.bn2.weight False\n",
      "32.bn2.bias False\n",
      "32.conv3.weight False\n",
      "32.bn3.weight False\n",
      "32.bn3.bias False\n",
      "33.conv1.weight False\n",
      "33.bn1.weight False\n",
      "33.bn1.bias False\n",
      "33.conv2.weight False\n",
      "33.bn2.weight False\n",
      "33.bn2.bias False\n",
      "33.conv3.weight False\n",
      "33.bn3.weight False\n",
      "33.bn3.bias False\n",
      "34.conv1.weight False\n",
      "34.bn1.weight False\n",
      "34.bn1.bias False\n",
      "34.conv2.weight False\n",
      "34.bn2.weight False\n",
      "34.bn2.bias False\n",
      "34.conv3.weight False\n",
      "34.bn3.weight False\n",
      "34.bn3.bias False\n",
      "35.conv1.weight False\n",
      "35.bn1.weight False\n",
      "35.bn1.bias False\n",
      "35.conv2.weight False\n",
      "35.bn2.weight False\n",
      "35.bn2.bias False\n",
      "35.conv3.weight False\n",
      "35.bn3.weight False\n",
      "35.bn3.bias False\n",
      "0.conv1.weight False\n",
      "0.bn1.weight False\n",
      "0.bn1.bias False\n",
      "0.conv2.weight False\n",
      "0.bn2.weight False\n",
      "0.bn2.bias False\n",
      "0.conv3.weight False\n",
      "0.bn3.weight False\n",
      "0.bn3.bias False\n",
      "0.downsample.0.weight False\n",
      "0.downsample.1.weight False\n",
      "0.downsample.1.bias False\n",
      "1.conv1.weight False\n",
      "1.bn1.weight False\n",
      "1.bn1.bias False\n",
      "1.conv2.weight False\n",
      "1.bn2.weight False\n",
      "1.bn2.bias False\n",
      "1.conv3.weight False\n",
      "1.bn3.weight False\n",
      "1.bn3.bias False\n",
      "2.conv1.weight False\n",
      "2.bn1.weight False\n",
      "2.bn1.bias False\n",
      "2.conv2.weight False\n",
      "2.bn2.weight False\n",
      "2.bn2.bias False\n",
      "2.conv3.weight False\n",
      "2.bn3.weight False\n",
      "2.bn3.bias False\n",
      "weight True\n",
      "bias True\n"
     ]
    }
   ],
   "source": [
    "# freeze all layers except last ones added next\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False    \n",
    "# Then unfreeze last classification layer only for feature extract\n",
    "for param in model_ft.fc.parameters():\n",
    "    param.requires_grad = True  \n",
    "#To view which layers are freeze and which layers are not freezed:\n",
    "for name, child in model_ft.named_children():\n",
    "    for name_2, params in child.named_parameters():\n",
    "        print(name_2, params.requires_grad)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 5.2269 Acc: 0.0286\n",
      "test Loss: 4.5949 Acc: 0.1024\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 4.4887 Acc: 0.0966\n",
      "test Loss: 4.0378 Acc: 0.1418\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 4.0332 Acc: 0.1572\n",
      "test Loss: 3.7704 Acc: 0.1742\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 3.8179 Acc: 0.1878\n",
      "test Loss: 3.4828 Acc: 0.2136\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 3.5829 Acc: 0.2261\n",
      "test Loss: 3.4425 Acc: 0.2098\n",
      "\n",
      "Training complete in 2m 52s\n",
      "Best val Acc: 0.213605\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight True\n",
      "weight True\n",
      "bias True\n",
      "0.conv1.weight True\n",
      "0.bn1.weight True\n",
      "0.bn1.bias True\n",
      "0.conv2.weight True\n",
      "0.bn2.weight True\n",
      "0.bn2.bias True\n",
      "0.conv3.weight True\n",
      "0.bn3.weight True\n",
      "0.bn3.bias True\n",
      "0.downsample.0.weight True\n",
      "0.downsample.1.weight True\n",
      "0.downsample.1.bias True\n",
      "1.conv1.weight True\n",
      "1.bn1.weight True\n",
      "1.bn1.bias True\n",
      "1.conv2.weight True\n",
      "1.bn2.weight True\n",
      "1.bn2.bias True\n",
      "1.conv3.weight True\n",
      "1.bn3.weight True\n",
      "1.bn3.bias True\n",
      "2.conv1.weight True\n",
      "2.bn1.weight True\n",
      "2.bn1.bias True\n",
      "2.conv2.weight True\n",
      "2.bn2.weight True\n",
      "2.bn2.bias True\n",
      "2.conv3.weight True\n",
      "2.bn3.weight True\n",
      "2.bn3.bias True\n",
      "0.conv1.weight True\n",
      "0.bn1.weight True\n",
      "0.bn1.bias True\n",
      "0.conv2.weight True\n",
      "0.bn2.weight True\n",
      "0.bn2.bias True\n",
      "0.conv3.weight True\n",
      "0.bn3.weight True\n",
      "0.bn3.bias True\n",
      "0.downsample.0.weight True\n",
      "0.downsample.1.weight True\n",
      "0.downsample.1.bias True\n",
      "1.conv1.weight True\n",
      "1.bn1.weight True\n",
      "1.bn1.bias True\n",
      "1.conv2.weight True\n",
      "1.bn2.weight True\n",
      "1.bn2.bias True\n",
      "1.conv3.weight True\n",
      "1.bn3.weight True\n",
      "1.bn3.bias True\n",
      "2.conv1.weight True\n",
      "2.bn1.weight True\n",
      "2.bn1.bias True\n",
      "2.conv2.weight True\n",
      "2.bn2.weight True\n",
      "2.bn2.bias True\n",
      "2.conv3.weight True\n",
      "2.bn3.weight True\n",
      "2.bn3.bias True\n",
      "3.conv1.weight True\n",
      "3.bn1.weight True\n",
      "3.bn1.bias True\n",
      "3.conv2.weight True\n",
      "3.bn2.weight True\n",
      "3.bn2.bias True\n",
      "3.conv3.weight True\n",
      "3.bn3.weight True\n",
      "3.bn3.bias True\n",
      "4.conv1.weight True\n",
      "4.bn1.weight True\n",
      "4.bn1.bias True\n",
      "4.conv2.weight True\n",
      "4.bn2.weight True\n",
      "4.bn2.bias True\n",
      "4.conv3.weight True\n",
      "4.bn3.weight True\n",
      "4.bn3.bias True\n",
      "5.conv1.weight True\n",
      "5.bn1.weight True\n",
      "5.bn1.bias True\n",
      "5.conv2.weight True\n",
      "5.bn2.weight True\n",
      "5.bn2.bias True\n",
      "5.conv3.weight True\n",
      "5.bn3.weight True\n",
      "5.bn3.bias True\n",
      "6.conv1.weight True\n",
      "6.bn1.weight True\n",
      "6.bn1.bias True\n",
      "6.conv2.weight True\n",
      "6.bn2.weight True\n",
      "6.bn2.bias True\n",
      "6.conv3.weight True\n",
      "6.bn3.weight True\n",
      "6.bn3.bias True\n",
      "7.conv1.weight True\n",
      "7.bn1.weight True\n",
      "7.bn1.bias True\n",
      "7.conv2.weight True\n",
      "7.bn2.weight True\n",
      "7.bn2.bias True\n",
      "7.conv3.weight True\n",
      "7.bn3.weight True\n",
      "7.bn3.bias True\n",
      "0.conv1.weight True\n",
      "0.bn1.weight True\n",
      "0.bn1.bias True\n",
      "0.conv2.weight True\n",
      "0.bn2.weight True\n",
      "0.bn2.bias True\n",
      "0.conv3.weight True\n",
      "0.bn3.weight True\n",
      "0.bn3.bias True\n",
      "0.downsample.0.weight True\n",
      "0.downsample.1.weight True\n",
      "0.downsample.1.bias True\n",
      "1.conv1.weight True\n",
      "1.bn1.weight True\n",
      "1.bn1.bias True\n",
      "1.conv2.weight True\n",
      "1.bn2.weight True\n",
      "1.bn2.bias True\n",
      "1.conv3.weight True\n",
      "1.bn3.weight True\n",
      "1.bn3.bias True\n",
      "2.conv1.weight True\n",
      "2.bn1.weight True\n",
      "2.bn1.bias True\n",
      "2.conv2.weight True\n",
      "2.bn2.weight True\n",
      "2.bn2.bias True\n",
      "2.conv3.weight True\n",
      "2.bn3.weight True\n",
      "2.bn3.bias True\n",
      "3.conv1.weight True\n",
      "3.bn1.weight True\n",
      "3.bn1.bias True\n",
      "3.conv2.weight True\n",
      "3.bn2.weight True\n",
      "3.bn2.bias True\n",
      "3.conv3.weight True\n",
      "3.bn3.weight True\n",
      "3.bn3.bias True\n",
      "4.conv1.weight True\n",
      "4.bn1.weight True\n",
      "4.bn1.bias True\n",
      "4.conv2.weight True\n",
      "4.bn2.weight True\n",
      "4.bn2.bias True\n",
      "4.conv3.weight True\n",
      "4.bn3.weight True\n",
      "4.bn3.bias True\n",
      "5.conv1.weight True\n",
      "5.bn1.weight True\n",
      "5.bn1.bias True\n",
      "5.conv2.weight True\n",
      "5.bn2.weight True\n",
      "5.bn2.bias True\n",
      "5.conv3.weight True\n",
      "5.bn3.weight True\n",
      "5.bn3.bias True\n",
      "6.conv1.weight True\n",
      "6.bn1.weight True\n",
      "6.bn1.bias True\n",
      "6.conv2.weight True\n",
      "6.bn2.weight True\n",
      "6.bn2.bias True\n",
      "6.conv3.weight True\n",
      "6.bn3.weight True\n",
      "6.bn3.bias True\n",
      "7.conv1.weight True\n",
      "7.bn1.weight True\n",
      "7.bn1.bias True\n",
      "7.conv2.weight True\n",
      "7.bn2.weight True\n",
      "7.bn2.bias True\n",
      "7.conv3.weight True\n",
      "7.bn3.weight True\n",
      "7.bn3.bias True\n",
      "8.conv1.weight True\n",
      "8.bn1.weight True\n",
      "8.bn1.bias True\n",
      "8.conv2.weight True\n",
      "8.bn2.weight True\n",
      "8.bn2.bias True\n",
      "8.conv3.weight True\n",
      "8.bn3.weight True\n",
      "8.bn3.bias True\n",
      "9.conv1.weight True\n",
      "9.bn1.weight True\n",
      "9.bn1.bias True\n",
      "9.conv2.weight True\n",
      "9.bn2.weight True\n",
      "9.bn2.bias True\n",
      "9.conv3.weight True\n",
      "9.bn3.weight True\n",
      "9.bn3.bias True\n",
      "10.conv1.weight True\n",
      "10.bn1.weight True\n",
      "10.bn1.bias True\n",
      "10.conv2.weight True\n",
      "10.bn2.weight True\n",
      "10.bn2.bias True\n",
      "10.conv3.weight True\n",
      "10.bn3.weight True\n",
      "10.bn3.bias True\n",
      "11.conv1.weight True\n",
      "11.bn1.weight True\n",
      "11.bn1.bias True\n",
      "11.conv2.weight True\n",
      "11.bn2.weight True\n",
      "11.bn2.bias True\n",
      "11.conv3.weight True\n",
      "11.bn3.weight True\n",
      "11.bn3.bias True\n",
      "12.conv1.weight True\n",
      "12.bn1.weight True\n",
      "12.bn1.bias True\n",
      "12.conv2.weight True\n",
      "12.bn2.weight True\n",
      "12.bn2.bias True\n",
      "12.conv3.weight True\n",
      "12.bn3.weight True\n",
      "12.bn3.bias True\n",
      "13.conv1.weight True\n",
      "13.bn1.weight True\n",
      "13.bn1.bias True\n",
      "13.conv2.weight True\n",
      "13.bn2.weight True\n",
      "13.bn2.bias True\n",
      "13.conv3.weight True\n",
      "13.bn3.weight True\n",
      "13.bn3.bias True\n",
      "14.conv1.weight True\n",
      "14.bn1.weight True\n",
      "14.bn1.bias True\n",
      "14.conv2.weight True\n",
      "14.bn2.weight True\n",
      "14.bn2.bias True\n",
      "14.conv3.weight True\n",
      "14.bn3.weight True\n",
      "14.bn3.bias True\n",
      "15.conv1.weight True\n",
      "15.bn1.weight True\n",
      "15.bn1.bias True\n",
      "15.conv2.weight True\n",
      "15.bn2.weight True\n",
      "15.bn2.bias True\n",
      "15.conv3.weight True\n",
      "15.bn3.weight True\n",
      "15.bn3.bias True\n",
      "16.conv1.weight True\n",
      "16.bn1.weight True\n",
      "16.bn1.bias True\n",
      "16.conv2.weight True\n",
      "16.bn2.weight True\n",
      "16.bn2.bias True\n",
      "16.conv3.weight True\n",
      "16.bn3.weight True\n",
      "16.bn3.bias True\n",
      "17.conv1.weight True\n",
      "17.bn1.weight True\n",
      "17.bn1.bias True\n",
      "17.conv2.weight True\n",
      "17.bn2.weight True\n",
      "17.bn2.bias True\n",
      "17.conv3.weight True\n",
      "17.bn3.weight True\n",
      "17.bn3.bias True\n",
      "18.conv1.weight True\n",
      "18.bn1.weight True\n",
      "18.bn1.bias True\n",
      "18.conv2.weight True\n",
      "18.bn2.weight True\n",
      "18.bn2.bias True\n",
      "18.conv3.weight True\n",
      "18.bn3.weight True\n",
      "18.bn3.bias True\n",
      "19.conv1.weight True\n",
      "19.bn1.weight True\n",
      "19.bn1.bias True\n",
      "19.conv2.weight True\n",
      "19.bn2.weight True\n",
      "19.bn2.bias True\n",
      "19.conv3.weight True\n",
      "19.bn3.weight True\n",
      "19.bn3.bias True\n",
      "20.conv1.weight True\n",
      "20.bn1.weight True\n",
      "20.bn1.bias True\n",
      "20.conv2.weight True\n",
      "20.bn2.weight True\n",
      "20.bn2.bias True\n",
      "20.conv3.weight True\n",
      "20.bn3.weight True\n",
      "20.bn3.bias True\n",
      "21.conv1.weight True\n",
      "21.bn1.weight True\n",
      "21.bn1.bias True\n",
      "21.conv2.weight True\n",
      "21.bn2.weight True\n",
      "21.bn2.bias True\n",
      "21.conv3.weight True\n",
      "21.bn3.weight True\n",
      "21.bn3.bias True\n",
      "22.conv1.weight True\n",
      "22.bn1.weight True\n",
      "22.bn1.bias True\n",
      "22.conv2.weight True\n",
      "22.bn2.weight True\n",
      "22.bn2.bias True\n",
      "22.conv3.weight True\n",
      "22.bn3.weight True\n",
      "22.bn3.bias True\n",
      "23.conv1.weight True\n",
      "23.bn1.weight True\n",
      "23.bn1.bias True\n",
      "23.conv2.weight True\n",
      "23.bn2.weight True\n",
      "23.bn2.bias True\n",
      "23.conv3.weight True\n",
      "23.bn3.weight True\n",
      "23.bn3.bias True\n",
      "24.conv1.weight True\n",
      "24.bn1.weight True\n",
      "24.bn1.bias True\n",
      "24.conv2.weight True\n",
      "24.bn2.weight True\n",
      "24.bn2.bias True\n",
      "24.conv3.weight True\n",
      "24.bn3.weight True\n",
      "24.bn3.bias True\n",
      "25.conv1.weight True\n",
      "25.bn1.weight True\n",
      "25.bn1.bias True\n",
      "25.conv2.weight True\n",
      "25.bn2.weight True\n",
      "25.bn2.bias True\n",
      "25.conv3.weight True\n",
      "25.bn3.weight True\n",
      "25.bn3.bias True\n",
      "26.conv1.weight True\n",
      "26.bn1.weight True\n",
      "26.bn1.bias True\n",
      "26.conv2.weight True\n",
      "26.bn2.weight True\n",
      "26.bn2.bias True\n",
      "26.conv3.weight True\n",
      "26.bn3.weight True\n",
      "26.bn3.bias True\n",
      "27.conv1.weight True\n",
      "27.bn1.weight True\n",
      "27.bn1.bias True\n",
      "27.conv2.weight True\n",
      "27.bn2.weight True\n",
      "27.bn2.bias True\n",
      "27.conv3.weight True\n",
      "27.bn3.weight True\n",
      "27.bn3.bias True\n",
      "28.conv1.weight True\n",
      "28.bn1.weight True\n",
      "28.bn1.bias True\n",
      "28.conv2.weight True\n",
      "28.bn2.weight True\n",
      "28.bn2.bias True\n",
      "28.conv3.weight True\n",
      "28.bn3.weight True\n",
      "28.bn3.bias True\n",
      "29.conv1.weight True\n",
      "29.bn1.weight True\n",
      "29.bn1.bias True\n",
      "29.conv2.weight True\n",
      "29.bn2.weight True\n",
      "29.bn2.bias True\n",
      "29.conv3.weight True\n",
      "29.bn3.weight True\n",
      "29.bn3.bias True\n",
      "30.conv1.weight True\n",
      "30.bn1.weight True\n",
      "30.bn1.bias True\n",
      "30.conv2.weight True\n",
      "30.bn2.weight True\n",
      "30.bn2.bias True\n",
      "30.conv3.weight True\n",
      "30.bn3.weight True\n",
      "30.bn3.bias True\n",
      "31.conv1.weight True\n",
      "31.bn1.weight True\n",
      "31.bn1.bias True\n",
      "31.conv2.weight True\n",
      "31.bn2.weight True\n",
      "31.bn2.bias True\n",
      "31.conv3.weight True\n",
      "31.bn3.weight True\n",
      "31.bn3.bias True\n",
      "32.conv1.weight True\n",
      "32.bn1.weight True\n",
      "32.bn1.bias True\n",
      "32.conv2.weight True\n",
      "32.bn2.weight True\n",
      "32.bn2.bias True\n",
      "32.conv3.weight True\n",
      "32.bn3.weight True\n",
      "32.bn3.bias True\n",
      "33.conv1.weight True\n",
      "33.bn1.weight True\n",
      "33.bn1.bias True\n",
      "33.conv2.weight True\n",
      "33.bn2.weight True\n",
      "33.bn2.bias True\n",
      "33.conv3.weight True\n",
      "33.bn3.weight True\n",
      "33.bn3.bias True\n",
      "34.conv1.weight True\n",
      "34.bn1.weight True\n",
      "34.bn1.bias True\n",
      "34.conv2.weight True\n",
      "34.bn2.weight True\n",
      "34.bn2.bias True\n",
      "34.conv3.weight True\n",
      "34.bn3.weight True\n",
      "34.bn3.bias True\n",
      "35.conv1.weight True\n",
      "35.bn1.weight True\n",
      "35.bn1.bias True\n",
      "35.conv2.weight True\n",
      "35.bn2.weight True\n",
      "35.bn2.bias True\n",
      "35.conv3.weight True\n",
      "35.bn3.weight True\n",
      "35.bn3.bias True\n",
      "0.conv1.weight True\n",
      "0.bn1.weight True\n",
      "0.bn1.bias True\n",
      "0.conv2.weight True\n",
      "0.bn2.weight True\n",
      "0.bn2.bias True\n",
      "0.conv3.weight True\n",
      "0.bn3.weight True\n",
      "0.bn3.bias True\n",
      "0.downsample.0.weight True\n",
      "0.downsample.1.weight True\n",
      "0.downsample.1.bias True\n",
      "1.conv1.weight True\n",
      "1.bn1.weight True\n",
      "1.bn1.bias True\n",
      "1.conv2.weight True\n",
      "1.bn2.weight True\n",
      "1.bn2.bias True\n",
      "1.conv3.weight True\n",
      "1.bn3.weight True\n",
      "1.bn3.bias True\n",
      "2.conv1.weight True\n",
      "2.bn1.weight True\n",
      "2.bn1.bias True\n",
      "2.conv2.weight True\n",
      "2.bn2.weight True\n",
      "2.bn2.bias True\n",
      "2.conv3.weight True\n",
      "2.bn3.weight True\n",
      "2.bn3.bias True\n",
      "weight True\n",
      "bias True\n"
     ]
    }
   ],
   "source": [
    "#UnFreeze all layers first\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True \n",
    "\n",
    "# To view which layers are freeze and which layers are not freezed:\n",
    "for name, child in model_ft.named_children():\n",
    "    for name_2, params in child.named_parameters():\n",
    "        print(name_2, params.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "exp_lr_scheduler = lr_scheduler.CyclicLR(optimizer_ft, base_lr=0.01, max_lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20\n",
      "----------\n",
      "train Loss: 3.2714 Acc: 0.2468\n",
      "test Loss: 2.9160 Acc: 0.3020\n",
      "\n",
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 2.4691 Acc: 0.3818\n",
      "test Loss: 1.8331 Acc: 0.5079\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 2.0584 Acc: 0.4722\n",
      "test Loss: 2.2528 Acc: 0.4234\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 1.8497 Acc: 0.5188\n",
      "test Loss: 1.6768 Acc: 0.5334\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 1.6525 Acc: 0.5635\n",
      "test Loss: 1.5862 Acc: 0.5779\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 1.5611 Acc: 0.5921\n",
      "test Loss: 1.8952 Acc: 0.5391\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 1.4590 Acc: 0.6198\n",
      "test Loss: 1.3742 Acc: 0.6427\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 1.3814 Acc: 0.6284\n",
      "test Loss: 1.4366 Acc: 0.6065\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 1.3246 Acc: 0.6517\n",
      "test Loss: 1.6666 Acc: 0.5931\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 1.2930 Acc: 0.6593\n",
      "test Loss: 1.3981 Acc: 0.6281\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 1.1892 Acc: 0.6883\n",
      "test Loss: 1.4161 Acc: 0.6351\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 1.1978 Acc: 0.6786\n",
      "test Loss: 1.2095 Acc: 0.6777\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 1.1721 Acc: 0.6824\n",
      "test Loss: 1.1217 Acc: 0.7018\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 1.0843 Acc: 0.7067\n",
      "test Loss: 1.1458 Acc: 0.6968\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 1.0351 Acc: 0.7226\n",
      "test Loss: 1.2962 Acc: 0.6548\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 1.0650 Acc: 0.7116\n",
      "test Loss: 1.2405 Acc: 0.6834\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 1.0249 Acc: 0.7279\n",
      "test Loss: 1.1061 Acc: 0.7063\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.9682 Acc: 0.7413\n",
      "test Loss: 1.2362 Acc: 0.6898\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.8942 Acc: 0.7579\n",
      "test Loss: 0.8692 Acc: 0.7591\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.8830 Acc: 0.7626\n",
      "test Loss: 1.0876 Acc: 0.7133\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 0.8970 Acc: 0.7612\n",
      "test Loss: 1.1004 Acc: 0.7203\n",
      "\n",
      "Training complete in 32m 16s\n",
      "Best val Acc: 0.759059\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20\n",
      "----------\n",
      "train Loss: 0.6335 Acc: 0.8364\n",
      "test Loss: 0.5364 Acc: 0.8525\n",
      "\n",
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 0.4986 Acc: 0.8688\n",
      "test Loss: 0.4868 Acc: 0.8557\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.4592 Acc: 0.8851\n",
      "test Loss: 0.4629 Acc: 0.8665\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.4480 Acc: 0.8853\n",
      "test Loss: 0.4461 Acc: 0.8678\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.4098 Acc: 0.8936\n",
      "test Loss: 0.4340 Acc: 0.8767\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.3995 Acc: 0.8974\n",
      "test Loss: 0.4326 Acc: 0.8767\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.4041 Acc: 0.8974\n",
      "test Loss: 0.4158 Acc: 0.8792\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.3881 Acc: 0.9031\n",
      "test Loss: 0.4207 Acc: 0.8773\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.3766 Acc: 0.9018\n",
      "test Loss: 0.4115 Acc: 0.8837\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.3631 Acc: 0.9081\n",
      "test Loss: 0.4240 Acc: 0.8792\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.3415 Acc: 0.9095\n",
      "test Loss: 0.4193 Acc: 0.8760\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.3392 Acc: 0.9126\n",
      "test Loss: 0.4114 Acc: 0.8760\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.3388 Acc: 0.9087\n",
      "test Loss: 0.4164 Acc: 0.8779\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.3470 Acc: 0.9136\n",
      "test Loss: 0.4159 Acc: 0.8786\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 0.3427 Acc: 0.9122\n",
      "test Loss: 0.4079 Acc: 0.8754\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 0.3036 Acc: 0.9207\n",
      "test Loss: 0.4200 Acc: 0.8754\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 0.3140 Acc: 0.9169\n",
      "test Loss: 0.4068 Acc: 0.8818\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.3456 Acc: 0.9099\n",
      "test Loss: 0.4077 Acc: 0.8856\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.3113 Acc: 0.9209\n",
      "test Loss: 0.4147 Acc: 0.8767\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.3348 Acc: 0.9161\n",
      "test Loss: 0.4196 Acc: 0.8792\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 0.3187 Acc: 0.9195\n",
      "test Loss: 0.4334 Acc: 0.8818\n",
      "\n",
      "Training complete in 32m 16s\n",
      "Best val Acc: 0.885569\n"
     ]
    }
   ],
   "source": [
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "exp_lr_scheduler = lr_scheduler.CyclicLR(optimizer_ft, base_lr=0.001, max_lr=0.1)\n",
    "# Train and evaluate\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential(\n",
    "#   (0): AdaptiveAvgPool2d(output_size=1)\n",
    "#   (1): AdaptiveMaxPool2d(output_size=1)\n",
    "#   (2): Flatten()\n",
    "#   (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#   (4): Dropout(p=0.25)\n",
    "#   (5): Linear(in_features=1024, out_features=512, bias=True)\n",
    "#   (6): ReLU(inplace)\n",
    "#   (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#   (8): Dropout(p=0.5)\n",
    "#   (9): Linear(in_features=512, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images from 224 to 299\n",
    "data_transforms = {\n",
    "    train_dir: transforms.Compose([\n",
    "        transforms.RandomResizedCrop(299),\n",
    "        #transforms.RandomRotation(degrees=15),\n",
    "        #transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    val_dir: transforms.Compose([\n",
    "        transforms.Resize(312),\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {x: datasets.ImageFolder(os.path.join(Data_DIR, x), transform=data_transforms[x]) for x in [train_dir, val_dir]}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8, shuffle=True, num_workers=4) for x in [train_dir, val_dir]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20\n",
      "----------\n",
      "train Loss: 0.5270 Acc: 0.8752\n",
      "test Loss: 0.3474 Acc: 0.8951\n",
      "\n",
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 0.4855 Acc: 0.8872\n",
      "test Loss: 0.3372 Acc: 0.8938\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.4532 Acc: 0.8853\n",
      "test Loss: 0.3542 Acc: 0.8900\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.4331 Acc: 0.8956\n",
      "test Loss: 0.3523 Acc: 0.8926\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.4273 Acc: 0.8948\n",
      "test Loss: 0.3848 Acc: 0.8907\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.4288 Acc: 0.8945\n",
      "test Loss: 0.3959 Acc: 0.8887\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.4032 Acc: 0.9023\n",
      "test Loss: 0.3840 Acc: 0.8818\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.3953 Acc: 0.9025\n",
      "test Loss: 0.3877 Acc: 0.8957\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.3930 Acc: 0.8989\n",
      "test Loss: 0.3721 Acc: 0.8824\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.3777 Acc: 0.9046\n",
      "test Loss: 0.4183 Acc: 0.8805\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.3822 Acc: 0.9012\n",
      "test Loss: 0.4009 Acc: 0.8856\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.3907 Acc: 0.9018\n",
      "test Loss: 0.3712 Acc: 0.8887\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.3792 Acc: 0.9064\n",
      "test Loss: 0.3829 Acc: 0.8837\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.3995 Acc: 0.9011\n",
      "test Loss: 0.4029 Acc: 0.8900\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-827eed017a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCyclicLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-86ad53e9c08a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "exp_lr_scheduler = lr_scheduler.CyclicLR(optimizer_ft, base_lr=0.001, max_lr=0.1)\n",
    "# Train and evaluate\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/15\n",
      "----------\n",
      "train Loss: 0.3317 Acc: 0.9175\n",
      "test Loss: 0.3779 Acc: 0.8913\n",
      "\n",
      "Epoch 1/15\n",
      "----------\n",
      "train Loss: 0.3245 Acc: 0.9224\n",
      "test Loss: 0.3610 Acc: 0.8938\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "train Loss: 0.3230 Acc: 0.9206\n",
      "test Loss: 0.3548 Acc: 0.9027\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "train Loss: 0.3009 Acc: 0.9280\n",
      "test Loss: 0.3552 Acc: 0.8983\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "train Loss: 0.2756 Acc: 0.9323\n",
      "test Loss: 0.3519 Acc: 0.9027\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "train Loss: 0.3028 Acc: 0.9256\n",
      "test Loss: 0.3465 Acc: 0.9021\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "train Loss: 0.2907 Acc: 0.9291\n",
      "test Loss: 0.3642 Acc: 0.8983\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "train Loss: 0.2743 Acc: 0.9333\n",
      "test Loss: 0.3475 Acc: 0.9034\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "train Loss: 0.2772 Acc: 0.9356\n",
      "test Loss: 0.3645 Acc: 0.8926\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "train Loss: 0.2646 Acc: 0.9361\n",
      "test Loss: 0.3701 Acc: 0.8957\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "train Loss: 0.2792 Acc: 0.9327\n",
      "test Loss: 0.3595 Acc: 0.8983\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "train Loss: 0.2514 Acc: 0.9402\n",
      "test Loss: 0.3668 Acc: 0.8996\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "train Loss: 0.2829 Acc: 0.9301\n",
      "test Loss: 0.3716 Acc: 0.8964\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "train Loss: 0.2692 Acc: 0.9340\n",
      "test Loss: 0.3692 Acc: 0.8964\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "train Loss: 0.2564 Acc: 0.9353\n",
      "test Loss: 0.3675 Acc: 0.8970\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "train Loss: 0.2659 Acc: 0.9333\n",
      "test Loss: 0.3616 Acc: 0.8964\n",
      "\n",
      "Training complete in 48m 34s\n",
      "Best val Acc: 0.903369\n"
     ]
    }
   ],
   "source": [
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "exp_lr_scheduler = lr_scheduler.CyclicLR(optimizer_ft, base_lr=0.0001, max_lr=0.01)\n",
    "# Train and evaluate\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.3010 Acc: 0.9298\n",
      "test Loss: 0.3678 Acc: 0.8989\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.2677 Acc: 0.9350\n",
      "test Loss: 0.3638 Acc: 0.8957\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.2885 Acc: 0.9329\n",
      "test Loss: 0.3601 Acc: 0.8951\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.2803 Acc: 0.9336\n",
      "test Loss: 0.3646 Acc: 0.8970\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.2617 Acc: 0.9379\n",
      "test Loss: 0.3643 Acc: 0.8970\n",
      "\n",
      "Training complete in 15m 11s\n",
      "Best val Acc: 0.898919\n"
     ]
    }
   ],
   "source": [
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0001, momentum=0.9)\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "exp_lr_scheduler = lr_scheduler.CyclicLR(optimizer_ft, base_lr=0.00001, max_lr=0.001)\n",
    "# Train and evaluate\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
