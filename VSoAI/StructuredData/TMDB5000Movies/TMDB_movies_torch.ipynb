{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    devID=torch.cuda.current_device()\n",
    "    devID, torch.cuda.get_device_name(devID)\n",
    "else:\n",
    "    print(\"Torch Cuda not avaialbe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH ='data/'\n",
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import json\n",
    "\n",
    "#movies = pd.read_csv(PATH+'tmdb_5000_movies.csv')\n",
    "#credits = pd.read_csv(PATH+'tmdb_5000_credits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tmdb_movies(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.date())\n",
    "    json_columns = ['genres', 'keywords', 'production_countries', 'production_companies', 'spoken_languages']\n",
    "    for column in json_columns:\n",
    "        df[column] = df[column].apply(json.loads)  #needed to make json objects lists rahter than strings\n",
    "    return df\n",
    "\n",
    "def load_tmdb_credits(path):\n",
    "    df = pd.read_csv(path)\n",
    "    json_columns = ['cast', 'crew']\n",
    "    for column in json_columns:\n",
    "        df[column] = df[column].apply(json.loads)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = load_tmdb_movies(PATH+'tmdb_5000_movies.csv')\n",
    "credits = load_tmdb_credits(PATH+'tmdb_5000_credits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits.columns = ['id','title2','cast','crew']\n",
    "credits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = movies.merge(credits,how='inner',on='id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitJsonToList(obj, column):\n",
    "    fullDict = []\n",
    "    for i in obj[column]:\n",
    "    #    dictLine = json.loads(i)\n",
    "        localDict = []\n",
    "        for items in i:\n",
    "            localDict.append(items['name'])\n",
    "    #    print(localDict)\n",
    "        fullDict.append(localDict)\n",
    "    return fullDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this would run if we didn't load csv files with json.load \n",
    "# fullDict = []\n",
    "# for i in movies['genres']:\n",
    "#     dictLine = json.loads(i)\n",
    "#     localDict = []\n",
    "#     for items in dictLine:\n",
    "#         localDict.append(items['name'])\n",
    "#     print(localDict)\n",
    "#     fullDict.append(localDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keywords'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['production_companies'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['production_countries'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['spoken_languages'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cast'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['crew'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['genres', 'cast', 'crew', 'keywords','production_companies', 'production_countries', 'spoken_languages']\n",
    "for column in features:\n",
    "    df2[column] = splitJsonToList(df2, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies2['genres'] = splitJsonToList(movies2, 'genres')\n",
    "#['id', 'budget', 'original_title', 'popularity', 'vote_average', 'vote_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_movies=int(df2.id.nunique())\n",
    "n_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#train, test = train_test_split(df2, test_size=0.2)\n",
    "# print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-75f06992582a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# select only few relative columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_small\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'budget'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'popularity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vote_average'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vote_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# select only few relative columns\n",
    "df_small = df[['id', 'budget', 'popularity', 'vote_average', 'vote_count']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cardinality of some variables\n",
    "df_small['vote_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't have to dead with nan filling, since all values valid\n",
    "df_small.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_small.T\n",
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cardinality of some variables\n",
    "df_small['budget'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to instantiate an object of the TabularData class we created earlier. But before that, we need to label encode the categorical features. For this, we will be using sklearn.preprocessing.LabelEncoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"id\", \"vote_average\", \"vote_count\", \"budget\"]\n",
    "output_feature = \"popularity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for cat_col in categorical_features:\n",
    "        label_encoders[cat_col] = LabelEncoder()\n",
    "        df_small[cat_col] = label_encoders[cat_col].fit_transform(df_small[cat_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_small.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset into train and test\n",
    "from sklearn.model_selection import train_test_split as cv\n",
    "df_small, df_small_test = cv.train_test_split(df_small, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "  def __init__(self, data, cat_cols=None, output_col=None):\n",
    "    \"\"\"\n",
    "    Characterizes a Dataset for PyTorch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data: pandas data frame\n",
    "      The data frame object for the input data. It must\n",
    "      contain all the continuous, categorical and the\n",
    "      output columns to be used.\n",
    "\n",
    "    cat_cols: List of strings\n",
    "      The names of the categorical columns in the data.\n",
    "      These columns will be passed through the embedding\n",
    "      layers in the model. These columns must be\n",
    "      label encoded beforehand. \n",
    "\n",
    "    output_col: string\n",
    "      The name of the output variable column in the data\n",
    "      provided.\n",
    "    \"\"\"\n",
    "\n",
    "    self.n = data.shape[0]\n",
    "\n",
    "    if output_col:\n",
    "      self.y = data[output_col].astype(np.float32).values.reshape(-1, 1)\n",
    "    else:\n",
    "      self.y =  np.zeros((self.n, 1))\n",
    "\n",
    "    self.cat_cols = cat_cols if cat_cols else []\n",
    "    self.cont_cols = [col for col in data.columns\n",
    "                      if col not in self.cat_cols + [output_col]]\n",
    "\n",
    "    if self.cont_cols:\n",
    "      self.cont_X = data[self.cont_cols].astype(np.float32).values\n",
    "    else:\n",
    "      self.cont_X = np.zeros((self.n, 1))\n",
    "\n",
    "    if self.cat_cols:\n",
    "      self.cat_X = data[cat_cols].astype(np.int64).values\n",
    "    else:\n",
    "      self.cat_X =  np.zeros((self.n, 1))\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"\n",
    "    Denotes the total number of samples.\n",
    "    \"\"\"\n",
    "    return self.n\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    \"\"\"\n",
    "    Generates one sample of data.\n",
    "    \"\"\"\n",
    "    return [self.y[idx], self.cont_X[idx], self.cat_X[idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s instantiate an object of the TabularDataset class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch abstract class representing a Dataset.\n",
    "#All other datasets should subclass it. All subclasses should override\n",
    "#``__len__``, that provides the size of the dataset, and ``__getitem__``,\n",
    "\n",
    "dataset = TabularDataset(data=df_small, cat_cols=categorical_features,\n",
    "                             output_col=output_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['id', 'vote_average', 'vote_count', 'budget'],\n",
       " array([[2702,   54, 1606,  426],\n",
       "        [ 131,   51, 1496,  434],\n",
       "        [4313,   45, 1492,  427],\n",
       "        ...,\n",
       "        [4383,   52,    6,    0],\n",
       "        [4082,   39,    7,    0],\n",
       "        [2916,   45,   16,    0]]),\n",
       " [],\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " array([[150.43758 ],\n",
       "        [139.08261 ],\n",
       "        [107.376785],\n",
       "        ...,\n",
       "        [  1.444476],\n",
       "        [  0.857008],\n",
       "        [  1.929883]], dtype=float32),\n",
       " 4803)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.cat_cols,dataset.cat_X, dataset.cont_cols, dataset.cont_X, dataset.y, dataset.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.cont_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the training loop, we need to create a torch.util.data.Dataloader object. It serves the following purpose –\n",
    " -   creates batches from the dataset\n",
    " -   shuffles the data\n",
    " -   loads the data in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#??DataLoader\n",
    "#    Data loader. Combines a dataset and a sampler, and provides\n",
    "#    single- or multi-process iterators over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "dataloader = DataLoader(dataset, batchsize, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(dataloader).next()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq0AAACfCAYAAADTceAkAAAABHNCSVQICAgIfAhkiAAAIABJREFUeF7snQV0U0kXx/9JLXU3KkiNAsV1cVjc3R0WFlsWWGSBxWFxdyks7ou7O4UWWijUqLfUvWmTJvlmUsoHbYFKrMvcc3IgLyN3fu81uTNz516OhAiYMAKMACPACDACjAAjwAgwAipMgKvCujHVGAFGgBFgBBgBRoARYAQYASkBZrSyB4ERYAQYAUaAEWAEGAFGQOUJMKNV5W8RU5ARYAQYAUaAEWAEGAFGgBmt7BlgBBgBRoARYAQYAUaAEVB5AsxoVflbxBRkBBgBRoARYAQYAUaAEWBGK3sGGAFGgBFgBBgBRoARYARUnkDpjVYSMYufnob4+HgkJmdArOAhiwR8xCenQlTEyF3nt/2JtRc8FKwl644RYAQYAUaAEWAEGAFGoDQESmm0SuB78wy6tGgKOzs7uNZqi3NvEwrqI0jDke1rcfJBQMHPSnkl/PpKmLcfAZ+07CK15HnrDK54BRepLCvECDACjAAjwAgwAowAI6AaBNRLowY/2gd/zPwDaD8Xic9HIPvlI/hqqSHg8U2cvv0UEm0D9BoyBHh1CmvXb4Ka02tkZU7G4LY1EfbiXxy64g1tk+oYOqQTTPS4ePXoCs7eeCFVSWRdFX+N6omgJ+dJWy+hZeyC3kO6wArpOHXiMEwt7fA6XR8ja7XCwhHOcNDSgDD9A06ePoSQWC10HTQcNsJIHDl5EXHp6WjWZyiau1YozXBZXUaAEWAEGAFGgBFgBBgBJREoldH64d0TBMQAq4b0hTYZgHbNn/ATYrB0yX5E6xkh1Os0jj9PwfYBBhDk5ICbmY60zCzEP3RH+7Gb0Lx5Y8TcWIJ772KwcqgZxg1dDNdWjeB56zS47f/EwHPr0WLaLrT4uQniLh3BgUdvcX5xL+xZPRuhhg3Qvt8vSNINxfzdTzCqf1tsGtsX2yP00N7FAPvPlUOz9Od4HpQMzcRItOz2BIGeZ5SEmXXLCDACjAAjwAgwAowAI1AaAqUyWgVkBTODw4GG+ufN6MDOQgvnT11ESFIijMXRsGsxErUrHYBW11/wa/eGOD57DSKCA3EhNR7CrFQYCZ8gsktLCMW6qFylCkI8LqNT3764dnQYyjcYhC1bZiPswlqMXkDaTO4J6Jhj9MJtmNHWFSEXlkvHz018j+svUjBx8xZM/9kFWUIh/M5GIfrQv3j9IRH4YIPoHFFpWLG6jAAjwAgwAowAI8AIMAJKIlAqn1ZTx6oox8nCxcs3ISADyIwOQPCTu1j6z330WLID8wY3/mxYEggEtBSgxlGDZf2eOHj+Cq5duYDVc8fCXCMHAnU1+D54gOoDFmBsI2toqKkhJS0RGUIBYsOCkK2hB01N2gIHPC3el8jIB3pqOYhKTINAmIqYYH/s3H8Amk0m4Nz6X2kVJowAI8AIMAKMACPACDACZZRAqVZaTZ2aYMaELpi/fSoaH14MdZEmBs6cjurW6jiw9E/oa6ZAS6sCJDoGaFK1EhZv+gNTuVzM6tEfRtf/xG+/jIC2mg7cuozDb41ywM+IgF+kEJI7x3HcrTba9OwP94nL0aXpXeJekI6fR62Ck2Hh1qdYryIG9WuEvxb8gscbjdGo31hUr2SD6+e3Y7K3NiwkZfQOMbUZAUaAEWAEGAFGgBFgBMCRECkNB3FOJvzfvkJETAa09O1Rr54TMoK88So0CSbWphBlaKBa/coQJ0bAw9MPJvbVUc3ZHFHBXngXnACupgVq1KmCJ1tG4Y+jMRjUozFe3z0DT5MO8Dm8FPFvveAbnQB1C2vUcXUFT5yJly89YeFSD3ZG2siKC8aD9yloVqc61IUZ8HnhhQTiZlC1VjWYCuPwmPSpaV0O3OgUOLWoj0Tfx0jWcyLuChalGTarywgwAowAI8AIMAKMACOgQAKlNlplpWvQw6P4a9ZavErKhpF9HUz7ax66N6zIdvVlBZi1wwgwAowAI8AIMAKMQBkmoDJGaxlmyFRnBBgBRoARYAQYAUaAEZAzgVIdxJKzbqx5RoARYAQYAUaAEWAEGAFGQEqAGa3sQWAEGAFGgBFgBBgBRoARUHkCpYoekH90gqjX2HLkCnLE9GwXDy16D0S9iqb5i7H3jAAjwAgwAowAI8AIMAKMQLEIyHSlNdrrAuau3ASP1+8QGPgeSZnZRVbm9ckVqN5wDMKKXOO/VFCAu6f246H/h2INKsLnHg5dfCSNkZsngrhA7D1yFrGZn18tVrOsMCPACDACjAAjwAgwAipHQKZGq1gsRrZ+JcxZuxE7dqxD26rlkBjwEOP7NYeLiyva9PkDQQnZCHlwGh0b/0SuuaDX1CV4530fM5dvxNtXZ9Chfne8iH2Lni6VcdovG5l+N9GkbS/cDY7HqaWD0XngMLRu2hinX8bg1ZUdaFmvMmmnNv5YexoZgkxc3bwUdatXR/WOA3E7OFkJwCV4dfgv6djyXtvvh39Hj0wcXDUPxx4Hf6fclx/73jyMPzedROZnl7NCn2H6gnUISUmD+8wuaL/s6BefF6sDGRfO/OCPUyeO4ujRozh56l/4hcbJuAfWHCPACDACjAAjwAj8VwnI1D2AQuLF+WDQz02hYeyEjTv/hsfyBfCINcfQwc1x9+RhLNnXGgsba6B9j05IjYrC1mOn8KRnN4wb2BVe20KxZs/fcNIVINo/gBihEkiIyRUVFUPSsoqQlhiDF++E2L5xA+oaR2NEn3mwbfMLmuvF4vCapWjaohyOuZ9ChXZ90aV6BfDjU4CKRgq+dyLER0XCX9sFL/YuBJfLgbWDKfyeP0KOiSkSQsKgaWyPytYSeHoFo3zthnCwzE2YkJkajVs3rsKgnANqVXGEmiQHEf7P4R2UCH0zZzSu60jay8H7Vy8QkMBHQjqfjE2HvCRIiwzE/VcBsBQlQSwdMRfVmnaDRLsyuBkJeOblD5NyxgjwC4aztE9jpCdG4slzH5K4QQyJli7q1G8IK30tufFKeH0FEyYug6NbDeiSCUZ4+hqMW7YRk9vXklufnxqOf4tBoxai45xlGFS/kvz7Yz0wAowAI8AIMAKMgEwJyNxoFRqWx7RFS1HR1AzVjMTY7x+L+MQ4XL0eCxjawkhThPdeD7HP/RJ09TSQmcqHkKsNeysLqJMMWpXdKkMny/urg9Sv3QndmtRFRsBFBL3PQtzLuwhV58DSoRzEXAuMGNERS09exV5fc0xb0uqr7cj9A3EOMjIywNE1hpG2EJsWTsTJKA2Y8UTECE+Gg4sN+BEhCHfoAd9Tf0nVub13Nd5ppSNKYIB17kfgFnsFg+dshTpPH2kJ6Ri5+hB6mvli0IiZyDK0gmZyFGDXHYLUSMwf2hWX4vThbCBEikCPtMbFw3934YiRBF3tEjB16GCI7KtAFB+I6Erd8e74HCwaPQQ3wrMhSApBkJ4rLp84JlejlY5RbFAJy92PooGBBJv/HICty3egW4NF2PXHMKhbVsPTNGOcWDQGZ/euwaErz6Cm74hhf/6BDrZCzJm6FBa1nXH9wh00GzENfw7qhBifu1i3YT1ehvBRrVV3zPh9EF5vW4ozkurYOWMQ9s0fjnflh6FK8BZcu3MHnhExSFy0FpM6KcBQlvtDxjpgBBgBRoARYAR+HAIydQ+g2ESaBqj9U1O0+KkujI2NYGNiCOOG3bFmyybMnTIcDao4wMvzKXiVumDRtH4w089dZeRq8YCsKPh4BSBLYgzTirq4+fAOzp6/jKT0gv6ZXEMLWJjqovH4Bdi8ZQ0G9uqMqjppCOZWwZ/zZ8A6IQhHrjxS3p0M9cTkyZMwdvFmxGcIKRlUaD4cJ/dvhZ0eHw1HL8OlHTMRdtcD70W5a6MN+07DlbP7URsxOH/jPk7tP4zQeCGMjIwgyYrGKWKM37lyAclmzXDk/CWM71RXOr50P8LJQ4I1525i2x9DoKNW8LZKNDQxaOZG3Nw5CxH3niM4NYpkKEvG8N+XYHib6qjddgBaOCnu0JymoQnatGoFUbQXQmKy8ObFQ1zwS8S4Xm3x6tR6zNjzEK2HjUYVs3DMm7YU75NS4fngPO75g+hrj9UzZuF+oD8WjZ+Ix+o1MHpUOzw7sQEbTz1GTOBbvAyIkLIJ8fPGm7A41G/RAeYmZmhGUgO3dLNX3nPBemYEGAFGgBFgBBiBEhEoaN2UqJncSuo6BqhkaQYNtVxDFGqmGL1gFhziL2JAj76Yu+0RrEg0gV79BoEbeBJ/7LgLB+vy0NVSR4WfOqKtfQbmjP6LrDRaY/K0X/BozURcCheiRkV7aGmoQc/IHDbG+tLOeKY1sWzdBDxaOw49e4zG7Qgx9E2Mkeh3Cb+P+R0fdF3wS7dmpRhNKatWaYsXnp54c2YbbAxzt9wNraygq6kJNS0tWFnaQFffHEgVfjpIpUuMUx7ZpudpaEAsFiIjUwRLtybo1bcvpsxZiPF9m0KUlQkezwCG2jxizOpKlRTzM5HG1YGNPg8GxoZQIy4J+UWNtGllS/s0k/aZpaMPY90s7J07Dgd9NDFrUNv8VeT+np+Rihw1Ml5Noq+aNjqPmoVuzevC29sLFap3wMj+AzGqT1foEh/nD6kSqOkYYtC4SRg2djzKJwXg/cs3eBDBxahRwzBo0HB0tDNBYHDhR/mcqtSCgY4eqjRqimr2ijPO5Q6RdcAIMAKMACPACPwgBGTqHmDXeiL8yetzsavdESfOdfwSZ6XRePB2dAHEu+94fLrmPGE1/MnrC5l3GL0/XuCoaaDloLnwJK/PZeaGg5i5oUDTCrzAAYfajBGemDB+gvT/PSb9UYT+Obi2eR6G3THAvQQ1LGnSCDac51i75wnuPuIiJzEcpk0qYQTxO+Uf2Yxpo2IRRFYnORV7QdehPhpaz8O8YcOhl/oaadkG3+2Pm5GIaLEGqjZvQgxdPSR9iIOouh3y5hvfbaCkBSQipKemIPqlP7bsP4dy9QbCwehLI9vEwBAhz17CNzwCYQ9uIVOvPEzIkMSCbHg88UCT5DdI5NrDpoIJzDTTcPPZa7Q31sHzqDhUKGcDQ6Eugl5GIJqEYPN8Qw57VSbKcrlQJ9ODxNhEZAlyiKEs00e/pDRYPUaAEWAEGAFGgBEoIgH2y11EUEUvpga3dgOwXOj0qYo+Tw9th0xAXfuq0DIyxMjxv8OVGFxcrWpYtmwcbNV10HPcXAx2ccbrR8/RfUxLdGvkDPV6q3C+2kE8fhkP3bq9MGxYSxioNcM2riW8QlMxZcoovH4vgYlNdew6cRJHLzxEk/a/ocvTQNgZ8NCk51gY8WpD18wYoyf/DjdLHjjI7VM3OhTZEg7siJEniPLColkT4FDlNhrbETcNuQkHagkv0Lm6A1nxrYS2vftiz9JJ0AeJ8iC19HOl4+g/cOP+aLR1KA+NajWweOVuOOoISBExPI6Tg1z3HqD55I1oUbspdGcNwaQ5I1F+rgANeo/C+l6tYUwih1U4NBI1m9xCw4rmxFglzhmWThjYtCLxg+0D0c7TWDKqkdxGyRpmBBgBRoARYAQYAdkT4EiIyL5Z1qKqE0gJvIVhPUfhik8I1M2d0HPkVKxdNI6sXKqm5ilhT9C9XR+MPPwKQ2qZqKaSTCtGgBFgBBgBRoARkBsBttIqN7Sq3bChY0scf/Ia2TkiSLjq0NbWJr7Iqquzlp4luvYdCBczea4Eq+74mWaMACPACDACjMCPToCttP7oTwAbPyPACDACjAAjwAgwAmWAgEyjB5SB8TIVGQFGgBFgBBgBRoARYATKIAFmtJbBm8ZUZgQYAUaAEWAEGAFG4EcjwIzWH+2Os/EyAowAI8AIMAKMACNQBgkwo7UM3jSmMiPACDACjAAjwAgwAj8aAZWLHkAjcPH5/AL3gcfjkfjwP7CNnZBUgAkM9ACS6YoJI8AIMAKMACPACDAC/3UCSjdaqZEqFovhSVKeJiQkQCgU4vnz5wW416hRAzo6OtDT00OjRo2kBizns4D0BSqU5Qs0dG5ODiTnLkLy5h1A3gr+OVFgRBptmoBTzhocXR1wJv9Ksj6RmFVqP7BhX4AQu8AIMAKMACPACDAC/xUCSg159fjxY0RGRsLHx6fYPJ2dnWFjY4MWLVoUu64qV5AcPAqx92sIT10utprq9WuAW782uL+OAXhaxa6vqhV2vs+Ef1rOF+q1MNdE53IsZquq3jOmFyPACDACjAAjIGsCSjFaqbF6584dZGVllXo86urqaNmyJRo0aEB2ysvuVjk1VoVbdkMcR9wASpmjjKOpAc3RA8EZPgQwNS41Y0U3sOpdOm7FC3Al9OPzISZA8jOhWV+5ualfx1bWxU+mGhhaQUfRqrL+GAFGgBFgBBgBRkBBBBRqtIpEIpw+fRqvX7+W+fAcHR3RuHFjVKpUSeZty7tB0Yy5EJ65AlDjTIaiVqMyNCaQVdfWLWTYqnyauhsrwDxirN7/kA1kiYvfCfWK0OQSw1UbM4gRW9Wg7E5gij94VoMRYAQYAUaAEfjvE1CY0RoUFIQLFy4gMTFRblQ1NTXRtWtXuLm5ya0PmTbs8wbCyTMhCo8uuJIoo444WhrQmjkJGDZIRi3KtpkUoQRdHiXhfjRZVRXIyGjncTGsojb21TOSrbKsNUaAEWAEGAFGgBFQGgGFGK2BgYE4deoUMjMz5T5QLS0tdO7cGdWrV5d7X6Xq4KU3BL9MgTghpVTNFKUyh0cM1xmTieE6sCjFFVbmCXEB+ONNOh6EFowWIRMliMuAZ2Nj1DJiq64y4ckaYQQYAUaAEWAElEhA7karIg3WPI7UcO3SpYvqrrh6vYTg12nEfzVZYbdeuuI6+zdgyACF9fmtjo6G8THgERm/oASuAN9qOP9nOmp43toUdYyZ4ZofDXvPCDACjAAjwAiUJQJyjY8UHR2tsBXWz6FnZ2fj3LlzcvGdLfXNDQ2HYPx0hRqsVGdJthBZy9ZBcrhg6KxSj6mYDRyXGqzkwJm8DVaqV6YIdW8l4HmSsJhasuKMACPACDACjAAjoEoE5Ga05pA4o0+ePFGIS0BhQAUCAS5fviyN+6oyIhBCvP8wxLGFJApQhJICEbIXrQIyMhTRW6F9nIrgo99DarDKyH+10F7yXcwQoR4xXF8ww7UotFgZRoARYAQYAUZAJQnIzWh9+/YtXr58qdRBp6enw8PDQ6k6fNH5k6cQ7D+uXH2EIkg2bVeKDkLiCdCbugSQw1cKF2K40hXXt6lfxntVuB6sQ0aAEWAEGAFGgBEoEQG5Ga23b98ukUKyrqQqetBxCddvk/XwStRe9q7DAHGhULTUvJ1QsnBWslKUGK4bA5W3yiyrYbB2GAFGgBFgBBiBH5GAXIxWLy8vaUpWVRDqJnD//n3lq3LjFkTeJCWrioh4xTqFanKHxGH1pWGtlCzbg/l4ly+7lpJVYt0zAowAI8AIMAKMQBEIyMVovXv3bhG6VlwRqo9EooQt6c+GKNy0U26xWEtCUnjkXyBBfjFzP9eJ5kyY8jqNJE8oiaYyrkNWWzcHsNVWGVNlzTECjAAjwAgwAnInIHOjNT4+Hny+nOJulhAHPYz14cOHEtaWQbXwSEjiFGMgFlVbCTkUhje+RS1eqnJPEwR4FaH8Vda8QWx5n4mgdObbWqqbyiozAowAI8AIMAIKJiBzozUgIABZWapjoOTxlEfq2CLfq+cvII5RDXeJz3UWnb9c5CGUpuCeEPknlSiWfpli3IgRFKsKK8wIMAKMACPACDACyiUgc6NVucP5eu+pqakQi1Vhf/rrOir6E+nqr5wPZNE0rXtCVGvlnXIeF5CuaNzF6k8sEmDpmNZYezPgYz0RTq8ajSEbz0L1aBZraKwwI8AIMAKMACNQIgIyN1pfvXpVIkXkXcnbm6RNJYeySiqxsbHo27cvaDvFdTXIOXWupN3KtV7O/WdAVHSx+pg7dy4OHz4MX9+iuRYIqEMrWdlUOUkXqZxKXyhEJlj+3h4IjMvzv5WgfNWGaF7FHlxBBt77ByI2Llr6PMamfiwjzkZ4kC+59gaRMcSHmIggMxX+5F7RcjEpuYZ6TOg7hEdFwT8gEBmfJXiQiHOw669R2HI3SLXZMO0YAUaAEWAEfkgC6rIeNfVpLYuSmJiItLTcH/rC9I+MjMSJEyekrxo1aqBq1aqYNWsWLC0tYWFhUViVT9fEweHf/FxVPqS+v1HEmPmW0EgMS5cuhb6+vjRV7s8//4xWrVrBzs4OXG7BOVCiIrJefUvhr31GkhtciMpC53K8r5VQsevqeHR2L/bp5KBnxRSM6DgE4vIOiPDzhV6LMXjivhBP9i/E7I0nkZghgbnDT9iyZw1iT6zBrD3nkJaeCp1GA3Bv/zLs+KMnjgXpQk3PHFv2HkZTB6PcsZLDim+fPwTfNVXFxs7U+S8TSImLRLamESwMdaXD5KfGI47Pha2lCQp+o/yXSbCxMQKMwPcIyNxo/V6Hqvr54sWLsX79+iKpR1eT6YuuODo7O0uNtpEjR8LFxQUGBgZFakMVC/n5+cHNza1IqlEDn46fvqiMGDEC9erVw4ABA6Cnpwd19dxHazaNGqCKkiOBL0k00LmcKir3fZ3EHDE6j12FX22ewLDrMbxPCcTGtfuhbl0fLeto49H1+zh25w0mNm6KoXF8+PoHYM/xm3i9PTc+r16tjri25S8YaqmRzkTwueCOrRc88Mw/EaJ9f2Pcvcr4deF01LDQ/74yrAQjUAoCGya0wQO3Bbg2ry9pJQeP9k/H4Ie28D26BMalaPdbVbP56RBytKDH0/hWMfYZI8AIqBgBNpEt5Q3x9/fH9u3b0bBhQzRp0qSUrZXd6u7u7pg4cSLMzMyk6XuZyJcAV1MLFSs7wsDYFkjKIocfU5GUpglrF2c4uFTHkIkT0MbFADtWLMc/nvFwrmgOcP6vk6F91Y8GK73GgbaxOcqXLw99njr0zKxQobwNdDTZ14N87yJrvSABddhVb4Mx7RrAUJQK92XLcOf5PcybMxsn7npAmpRbmIqbR9dh5sw/sfPIY9Bghvz4cOxYtZJcm4mjt55Ky728tBt7Tp/HtpWL4RX5pSf47j+6o8fK0wW7Z1cYAUZApQmwldZS3h7qJtC1a1fpSqujo2MpWyu71adMmYIGDRqgf//+ZXcQKqj5q3N7sDSIGJENu5D10K/HGhYZl0dtB11cCIlCdRttBL72RrmajZAuyIGOWBOxMYEkTvDX6nPh2LgbZjbsiNj7/4DfeThmDailgjSYSj8CgZBnl7H4niXmD66D03sX4u3hhmhbUxMjxt6F5aUziN0/FctupaJdIyccXjYUEeqn0CX7KrwiImFAJm+Tx/wG3XNnkH7/DCbveYFeg0ejWhY1WrV/BHxsjIzAf5qAzI3WFi1a4Pr16yoHzdra+tOWdWHK/f3331i0aFFhH0mvhYWFoVq1atL/U+OMboVTn1YTExNoa3/7y1Bj8i/I/nPZV9tW1gdqFckq3WfuDFWqVAGNsvAt6dGjB27evAkjIyMMHjz4k08rdQngcD5byvtWI+yz7xLgcNXRuucIGESIpQf/9MlhK7dm3dGXVxU8Ayt06zsQjqbEH5dbERMm9IKVhimWHDsJu/17ERKejrqdx6FnmwboZrsUK3b8C92ao7DCKArltNRRt20fmNg4FNSBw0XjTn0hdCKrskwYARUhMGK1O+a4RuBW86kIj/bHrZuv8NYrDGFvH4OfxofOcy+Mam+DyLW7cSYkFgkp5ohL50tNVLO24+C+Zj7UPn43eR9dgM5TtiIpJRkCrgfMNy/A3IMn8Fvb3O92FRkyU4MRYAS+QkDmRquaGvWRUz1xcHD4ptGqpaUF+vqa0ANXv/zyC+bNmyf1Wy2O7ypHUzX9pri1yBe1qcmnIdODVPSA1bekTZs2mD59OqpXr45y5b7vENrYRBNnoGJxWr81QBX5jKOmjqEzN2DoF/o0QuuP76fOX/LxfzWxeVPN3P9bVsa0GSu/HEG1Vli2qdUX1xxGLyx0lByuGnpN+PrErdBK7CIjIGcC6vT7k6Mm9W6RqHGhxeGh+aRV2DaxA9KigpCsXhEntwxHksNg3Fhtg17DPktRzdX4ZLBSNV27/o7HTUZj/9yBuGI2EIendIMhcWliwggwAmWDgMyNVrrySA/h5OSoVsYhc/PSrR5RX80dO3aU7K5aWYKjy4MkQ7WSLnAdKxV7PNRnrDgytII2pj9NLk4VxZTlcTGqko5i+mK9MAKMwDcJPN8xCzVOLoVNsxEYbf/1ohJNK/Qd3gm/blyDLpe3QUunHMYuX4eaZBdsyyp3jIgwhTDza24wgIaOIWzIy1BPE1oGxrC1tf56Z+wTRoARUDkCHAkRWWu1atUqpKerVvD2BQsWKHX7WtC2B8RBYbJGXar2eE+uAeampWrje5XjssWwOFa8WLDfa1Mmn+twIenNfrBkwlJhjeTA99lDaJWvDQfLb+8IKEwl1lGpCUT4eSE8MXdCzzOxgb1+NoJSNFGvsjX8PF/AwKk2yvEE8PIJhl1lF5hoSfD+vS/iEoTQNrRB1Sq20MhKJhFd3kGkT9y1+NkwdXECNzEYYdkGqO1kU0DHD+/fIIkYwK628v3+K9Axu8AIMAKlIiAXo/XGjRug8TxVRWrWrAnqi6lMkex0R/aKzcpU4Yu+NVr/BLUta8nSg3xdF4Qkr0CLe4l4FKZaeZwmu+lhQy1Dlbkf/2VF0gPuYuzs1SR+bA5xwdFD1yGTMbBHU5DF7gKSFB2C6HQNOBFDo+CTmYShNV1h+edlrOpb8KBYzNOjGL5gP+oPnoW/BjZHToQnxq85gt/++IscTlM9IzeHHBryJ6HI+OSoO4f4E5tbV4CdtbyCPBVAzS4wAowAI1DmCBTys1H6MdStW/e7vpGl76VoLVBXBVUIRcXp2glqFb7vA1q0UZW+lNr4MXI3WKmWGuQJa24qcy+U0gHgctDIVLN0bSiwNjVugoMCEBBAXkHBiE/9uo+wKDsDoeTQYKZAdTJ+pUT54d6LANQbucYoAAAgAElEQVTr2AvVyNbvnNkz8CwiEzlZmQgLDpaOKyGdvk/F8dVT0W/MUviEfQCd8Aj4KQgODiCHy2JI9IRcEWelIfh9ED7EJ30RTyHG3wPe7/zhvm4lApKzkJORiMfPPZGUKYBELELih3DSVyAiohOkbYn4ySQzWDRiwkOk2cKSY6IQk5iA8ND3CIuMgzArCaFUt7SMb8RtKPmDkBr0FMN6NEP3Pv0xmMQ37tajNzZe9Cx5g8WpSVYmNy+cgR2XvYtTi5VlBBgBRkCpBORiTdCT5TRr1IMHD5Q6ONo5DUlVWn9WmQzCygLqfbtDtHKrTJorTSPqzRsAblVL00Sx6i6saoDlPsRdhAT0VwkxVkd/+29HfFAJPT8qEetxAi17T0SWGskQRFbkKtVvh127tsPVrOCfb+Kb6+jwyxKsPXAZ7V1L58ctSwYSdR24NWgMnnYITt9PJ0HdJbi7629M2nAEqRlpMGs1HIfGVMXmkzfgH8/F6FECHD2wGEcXjiKG1Uto69jC/dYVqUrXN8/G2blB4Do1wZF/9qKOzf8TekSV/wmzjd5g44mn+LtZ3ggkJHnCLoz9aw3C4jLBM7LHXPdj+Dn1X7SavAWGxIR1IYZyvVc7scefD3FCFFJyDNG8jhme3fUCr/UI3Ny9HBY6sp/oSLRtMGfrRYyuaY69S0bj99/mo0eH83i07jekmNXC+9BYjJ8wARlvb8H9+DmkiizQc/wvaFvVDNtmL4BR05/w+OJVODbrglG9O0ItLRbnDm3DNa8o2Lg2w/iJA5By/ygOvcrC1ImjEHB5O85GW6OLVQC27jsEtRtvkZ46E9P6/bgxpmX5nLO2GAFGQL4E5LLSSlWuVauWNCySMoVGA2jUqJEyVfiib04XstrqYKdcfcjpW/XxowEFRnmgq62zqukpd9x5vZMjyMerq95W8ffgiI2qYd8dT3id2oqMlzdwydOfLBUK4HlpG6ZOnYrlG88iPavg6mpWaiDWzpgFn3gJssNeYNaSTQhPU/yBQG6KN4a2rIv+v22FTgU7EJsVrk1aYOKwPujesgleH7+OGNfuWDCmB6o1n4Br13dDJ/Qmjp6LxNrrvnhxdjMsPtqMVdv+iufX9sHwQyA8AvP5S5OhTZ47E88PbERAYq5LCocfhU3rdkO34xwEhPpgZB0edu44AroYnSLUwPwj13Ho9y7kFgihUa4prty+juq8cHB/+hVeF1Yg/O4jvEuWr3uLuoERhgwfBH2y+uoVLsbTa2ewcNUmaJhaIc77PAYMn4L3GlbQynqOjj3G4H1mNm6f3Y2/Fu6BnnoSVsyYiiMPfHBk3jiM3vcU5Z0scdl9Jn5bfwkRr5/iHMmQlkkmjcEv7+LMnZfgmVnDUFsLhpZ2KG+p3O/p7z37ZfnzHKEA2dnZ0ldOTsG/z6KNTQy/m4ewYPe/hRcnx1KEAgEEwv8ffqb95ojIVoWKiEiQiX9WTZd+V9HX7sNXkUL9YhQkohwhhCXmryAlS9mNmBx+lz5r5FnIEavOvS/lsApUl5vRSk/b09z0ypTKlSuDxmdVGSlnBY21S5Wqjnqj2kBd8lKwLK9OVsPUVCCOq6kG+tiVnVXWvNvEyYrF4c2riXHqjgwTNzSpUg5vji1FrxlHpK44T4/MxMQ1FyDId18FaZE4tn0vApOJ0Rrjh+0HTuNDRv5S8n8YxMa1ce5VCBKDrsIu7AH2nr2F3SsWY8vNAJibaROfzoI6ZCckIFvLmrgUkNPeTvXhYpJbyLZ6VTIhtiahj9TBzy74w2dWuy+GVEnAtpPPpG4AHBJY/gNfjOqOFaGjpgtbErIuM5ukFyaGM9/IFk5kFyRPTCo5wYKnDS1tDZJZrAb0jO2gSdwLMhXxI0CMDwkJ7JTHotEvy7B4wlBk+D1DmtFPWLl8EZYsnYc6kR54FZn7o9T/z1VYtnQJGhrkwPvpM/z7IhSjxs3EvJl/YXaHpnjr/Zj8gBVk61CrNTmEZEYmCD3Qu4VqxCjNig/FzrULQQ/NLli0BIfv+BRU/OMVIVlR3r99NZ6EqGBkko86ioV8jP+5Eng8nvRVv1lf3AtMKHxMCf5YsngbgguNMCNG6PPr2Hm+8HMi/EgfdKpjC8saP8OH/J1TWdCvDka6Pyy8LyVclQizcOnYTtwPSoE+OUexa8k4/DRoJqIyCv79ykO9bVO6oN2YrVDRpOKlHnKirwf6t2kKXR0d8Kys0HLYH3gT+/XRel45iL0nHyI3qXfRu094ex8r1h5BUtGryLyk3IxWqimNjdqs2ac9Opkr/60G6Uqvsg9fFapf1SrQmjWp0I/kfVGjRSOo71Wee8KlVuSkrnoh1om8B/5Z++dr/n8rWYHdlr4rYjRlJkXhtscb1B45Dg2s1HD50n2Ev3uKdevW4erzQLzxeo50oYq4YOQbMScrHmfct2HNxp14lyKAg60F0rIEJJWsCfFljSXJunL1NjQ2Rsr7u9jrfp7sSpBT41xfEhd4Hub+1gv/PI4vMsch02cj+NIB+CcKIdEzx0+O+ti7fSWWrFiELZdvoWXLTtAo6F1R5PZlXVCcnIh9O/ch3bkR6tp9+bWsSYzo7LRw+H9IRSwxQiO4ZjA2yv07Cn3nh+S4MMSTFWZTcyMYqIvhHRAMviAFL/zfwtjAEtp6PKRmZiA5Iw7+gR8+U10MfpbiV92/xi4rIQTuO7fi/psQJJDT/X92boH1dyIKLZ6dGotDuzfhaYgyfz4LVe3TRfpM8/mpGLj2MhKin4EX/RgHbrwiz3s67p8/jbVr12L/mcvgS8S4dnAtli5eiVVrtsMnOo34Wyfgwpld2Lh1F96Q91Q4Ej6uHd6N7fuPIv6zyZqQrCKqaWmgimEmVpG/m/wS+eYhdmxei607jyMoMR1iYkBePLABDx/cwc4TVxDl54ET5y7i5tWT2LTdHcFh73H90A64n7wIWe4v0AlZjU7DsWDFClw9tAY5Hpdw1isUR+d2RZ1W7eDm7IC9jyNwYftfqFreCPoGNuj0+woyyU7G6iFt0IL4fFeuWA5ODX/G3VCSHCLqNcZ0awRzYwOUr9wY66+/RMijA2hcrQEeR0kQcnENuG698eLSSizadxP3Dk5Hy67T8SFbNb8j89+3or4Xk+/W2ROGwMeuI0JT0hD75BJM/E9jxrIjiPnwDgd37kVkugQZIS+wevcpRAc/x/o1q7Bi5WrsPXEDMVGBOHn0FB49von1GzfhRWgM6ToZJzduwMuIDOQkhWPfPwfhTVLWHyITxeUrV2H95v2IUhJHuX5t0wxJLVu2lLK/d+9eUe9BqcvVqVMHnTp1UmqIq68OgjDhjBwCmsYg++9NXy0m6w80fm4MtQ2rFOoWkH8MHay1UM1SC68jlfNDOaqKLtpYfT2BRJ6+UVFR0nS0ycnJOHHiBFxcXPIPReHvJTpWGD13FTTvrMXoDWvwsHM9aKlrolLP6bi+aTJEiSEITtCHgQZxG/hMOGpaUNcVIyIlBeHvQ5CthC1D04p10LdbGyR/CEUkTw+LthxGt9Z1kWG7AIs3HIe4Wnf8NSIG1joaKN93PH4N2YyE0CQYDeiIfbs2Y/PB86RsN3Soa43sLr1gVJFMfnQ46NC1M6ra/P+0vYljPQztmEr8fgEjp58xY8ZYuARxUN7aBnXX/APzTVvw+H0c2i/+B7P6NEBWQDqGdBLASId+DXJQtWl7CA1IqCSeLlp17g17WzLBIT+cfft3JrE9Ze/PSm8TJzMcf/VrgeXq+rCq6ID9/2yEdb55XdXW/dHtxC2MblgFYl0ttJgxH03NOaDTzxdnVqPW5kBoVW6H7u1+Roa6HybOXwjHw/OgaVsRW5cPRm2eL2w3j0C7Js3haMGDFokAJdE1QsefamLS32MxNF2Ifxb2/OK5UdYbiYYeuoybhV8rc+B39wLeR5If0DQuls+bgD1nX0DDsCr+Ij+mXQokdAtFP5ef0XLPXQy3CUWn0Qvw6+rd6F1Lye5YBGTYi1s4ItZAoq4T2jdwQmzAfRw8dAwCTU14bN+J96LDKB8eQVbEsxHqF0AODqaQlciJWPosGc2dTREkNEIn0k7s7bPYpZeEoGfX8TDFEPsnd0De9CaLJFzoPLA/9u9ZC99R/9/hjH56El1GzYd5tepA9D/YcP4h7u2fhwMb5sBDXBVNOw9CTWKazpi4FhUbN4eAHGZcuYqLBvXc8PrpU4Rp38T8TlVk/jgYVayMCtp8YiAnwoBsa0dncnHm0l04cf3RZNoOdD9xD8Ns3qF/l9k41rkdRDnpSMx2xNELJ7FqzBCs3n4aA8RXcDHVFddeHcIjEud3998bUPOPZhCQ7XEx3bUQ5UBCXCZsfp6Aqf1IWX4bHNo6kbgZKXfhRNYws6I8cedBIH57MAE2eiT2uHND9GldG0sePCHRSXSx8e81sOs4HI5+9/HHCnLmod5EfEhKR1Z6DN4HRyK+fDqWTfsFGm7NYM33w7wD9xDwYDm2z52HrjX7wtkqCOvXbcJvJGtoZEwcRMI0BL4NBL+k3i6lBCBXo5XqRrMs0dSuVBRhuNLIBe3btycum6qZmUsKgugmNVzJH5YiwmBptG0KtdXELYH3fYNNqp8c5UEzEzS9nwifCMUartRg3UxCXGlRi+Y74ufn9ylkW7du3XDu3Dk4Ozt/p5YCPiZZgeq17weXzaew8+QjLBw+GHunLUS7lmegoWWOXtOXooorebzi/fFrVxJSSs8Uk5atRZtWVbCkd32cd7aGrkSumyuFQuDZ1yErrAUTc2hWb4u1e9p+WUffGdNWbfx0zahlV6wjrzwZs3jLp//PWbbgi7q2jciP9icXdjW0Gzkb7T6VKI/RS1aCeHN/Ep0qbbB1QZtP79uM+hN57yYtyOvHEpu3uX3Rj6zeGDo1xqkb3mQiQVvUhJGZCVk1yvW3nr3nNnL0rKRd6du5Ye2hC5galwiJphasy9lCjayEUOny+xqMqWMKXWNLWJqSugNn4mrzQUgmK3FaJmawN6VGfWOcvnKLXJPA1FAHadlcYvPz0HXmGtQmW7Q6RqoT1YTDj8HqMV2wg+zIcKuNxK7ubnh+fAHcr4Si/9BfEOV1GesWb0W93Z/fSUpChJSEeBI+TESMFSGSk5LAL8wvQkpNsfKBrGTeERhBTxyKqzc80aKfPSzUM3H52SuyEpaI0JAYLBz7KyZv+wtT1y5HM+0PWPMgFIP/3IolvWojjcSdfUYO65k27Ix/9m/Gzknt8O+rQGSQYeQ+LWQSQhYPjd06YFrzu1i57wryItM+uXkR2eZNsW3vJki8D6NPvxXwjptL3FA00GHaBmwa1BB+59eCZ18VK9bvhu+GvlgQWQsHdk0hhl4HBJFVb8jBaBXERZOVOi20s8g966BVuRkaONqC//wO3vKt4E5cVlzIBKa8RjZJy8uHLhmrbd2fUNO5CqrY2eBiYiwC0iPJeeJhcLWrBIFzZey5+YK4CxW8t1xNXehpa0JDrEd2KPQ/GfoFS5bRKxIR6FqEnvb/k+VoEXcUutL/cQPri4GZVGuPPk2r4EBsC8ydMQyZL89Cw8QKM5ZvRwvOLdRtMB5PIgqmneeZO2BEny7Y/9wDi7csRiUl4ZK70UrHRQ1IarjSlVdvb28kkS8UWQv166tGsqK0bt2ahB4tGOFR1v2Vuj1quI4ZDi0yy8w5eQ6i0KhSN5m/AQ75A1X/uRnU5s4AdOmfvfLFUIOD202M0fpBEl4pyHAd8dFg5RXRp5ZOfIYMGYIDBw6AGrDUN/vSpUtSdxdliHmtbjh/shEqljcl/mAm2HHyAjJ4Zqhgb45L/9Yhs98MqGubw6WyPdSzU3Dk31vIomcySApLGwcnGNU/is7B5DR5eTskxqSggqlqPAvKYKlKfapp6sCe+NAWJua2Xz5rWkamcCCv/4sGqjdoAls7azg42v//Mkn/a25fAV/GjeDCtJw98mrnHbvS1DZEJSfVilUs0TLFgPHzof/sIDZGC2BAViOfBbxHRmYmnjx5QLyL9MkE0hxiVYlEUtjNy3et4bB52D+xMQ7M6IUtt+7hkak2DnlkYzXZ+XKfN/VTaQ5yyIEqan2oQZPMLVMzsyCSZCM1JXeCwtXRgzb5bdMkExdkEuM8f98aOhgw6TfsGrAUmYY54NHPSSFhDp8Y8MSwiY5ABpf4a39cadTWM5KmxqXC1eJBV0sTanSywDMk/RAjT12DrHAW4hCdv98ivqd9Rb/1wLWzibi8bx0kTg3Q1q08Xt34fwNci4qoZhaEdZsPoaeuF3xEZhjqZIYAUuTd5WPYVzkTt32DUXVMDbjGemHVxTM4dsEcz0/9C32HPqhYwQpc9QycOnsYarcvk1q5Tzs16BJ8PfHo2Vu0qOtKFi+KqHQZKKZmbANbK31cOn8Bvav1gnpqKG7eewXbGmNhoUt2iLhiJJO/n5jouC9GIyIHefNc9emqdDpxFRJw0iHiEr9Y4m6iqctBQgZxK0qMQ9bnIRQlQgjo35+SXP0UYrRSUtRwbdWqFWig/1OnToFuwYpldLihXLlyUncAW1vbMvCIfaYidRUg8VI1unUGZ/ociF76QiKQjWM616UiNGf+RoKkNlU5JqbkG/lGY2P8/FD+huswV11sq120FdY8UHQCtGXLFulM9eDBg2SLxR8dO3bE5cuXUamS4ueXGnpmqOH2//zo9i7/D1dmbecK6893QHWMUK1m3Xz3XAd1TXNX06zNLVXueWAKlYSAPgnbVdB/sSQtqVQdrjpsKtfFsPbWONNoANZfmYA2tmTd0DwFI/6YDSthJLyCtWHMIyaQJAehb73whBcDi4pWsLTTxc0712Cm64OoeFl6Y5ackJq6Nm5vm4m2/+ohLe4Dmo2bhEpWgdDLDMH6FeuQRPSUTiZsndHYOgWz+48Ed9dG9OlWF3NWTUXbg6ZwajcUfYqogq5DM/zRZjt+2eyB3kM0ULd1J5Q7OQ/DOrYFh/8Brj1/Ry2L7+82FbG7ohcjkykH1xq48+wUFj3ThWvtlsS9YRyqWOoi0s4JtbRzD0xr2jbEvi0rMH/9dqzT08PIVSvRsbIVNpCeDIgr0PlDJ6FfbxCmDWmBCjmVMe/DHOIWsBo61Vti+XTiDmSriUmDOxJfXXf83KE52kkypElKOgwZgyueK3D00D00JAlKiH3+nxFNoyqYM3ckJm2ci/a3tpHscOnI0HDA6vF9UN40Cc72Gpg1tAPsNWl879zdG1fiLhJ/eh8mTdPDrP52yElLwKZZo7EtKRDqxB2pGfmb825XA5tnDsIzS3WkZOROXowcq8AumzxfXcdh17HtcNFX/LMkl4xYRXka6AoWdReIjo6GSFR85wi6aksjFNCVVepzSN0Qyrzce4CcbXsh8n4LCTmkUhKhCQw0Jv0CtCMbndrSubbKSgJZVfgnhI+pL1LIckCBdYPS6a3NxZEGRtJIAUVcYC3QXwaZZY4ZMwZHjhyRfubq6ip1FXB0dCxQll1gBBiB0hFIDfbAmEmz0WnOLgyuY4FNvw/CNa2WODW3F1b9PRVnbrwDV8cFo+bMxuDa+vhtRB88j6A/phx0mbMXXcTX8dvqY3Bp2AgZkUkYtng1urrlbZSXTrcS1Sbbtt6PriMoNteAtravjNo1XKBJDlS9evgAYXyyE2KoCYm5E+qQEGUhLx/gVTAfDVo0hYWWEC9ImSiBDmr9VA+8uLd4kaCJDo3cEOz9EBECSzSs6yg1yISZyXj85AnsazQjuyg6ECaE4tJ9Lzg3IBEirPUR88YLHv4hkJiZo0m9hjDUEOP53UvQcW2NauTzdBI67rFfDBoSbikBj+GbbYa2tSqRaBT3kW3iinouyo7Ak4EVA8jhK6fxuLRoSIluxX+/kgBvvR7Bj5wF0CDuEG51GsLekh46FiPG3xuP34WjGnn2At7FoWVbcr4lKwGPbz+CyMARlbT90H/UPIxauhVmomRUa9AKjmQywY8Nxs0n3rBxcgI/Lok8X7VQTpeLN0/uIzhJG63aN4GeEja1lWa05j1E7969QxZZlvby8kICCXFDV7fS00kg+nyiS7a3qWGqR2ZfDRs2lK7curnJx9csf98Kf3/nHiRxJGvPhasQ+wWS7iUQxxUM7cIx1ANHUwMcXW2ojxspVZPTuzvNCalwlUvT4a0YAf58m4an0cQhqbTGK1nFHVBRGzNddFHDqPR/UfTZHDZsGI4fPy4dYpUqVXD27FlmuJbmhrO6jAAjwAgUmUAOXt+9jBiDKmhdSzkuWkVWtQwWjH19BSOnrMS0HWfR0iHPS1p1B6J0ozU/GqFQCE9Pz/yXpQaqDolB9kMKdah2P1hg6BxyWhg2yp4FF1CrxBfuxgow2zeNhCshxitdeBUVcfX1o2/NAAcdzHXVQxUD2Xq95BC/4969e0uNVSrUcD1//nwBVwF6apW+6MSKCSPACDACjAAjwAjIloDKGa2yHR5rrawS8EwW4lhY7rbayiDii5OWz4XEQgMzyuW6P/zurAsrnvyjRdADWRcuXJAipYkr6OGsihUrSt/z+Xy0adMGDx8+xOnTp1UzRnBZfRiY3owAI8AIMAKMACHAjFb2GKg8ATFZcM2/5ko9mBXtBUFdV+iKKzVKqdAwWBcvXpS6CiQmJsLUNPd89uTJk7FhAz06wESeBDJFkYjKpCeEvxRHfeoq8x/wcc8/MPaeEWAEGIEfnIBs91F/cJhs+PIhUITQqvLpOF+r9PDf4cOHpT6ux44dk0YV6Nq1q9RtIM9gVYQi1PebJj2gcvXqVRIK6MkX3VaoUEGqIxWa3EMVkiPIgkuK8A2SBD4kPuNR4vqcRfzfxcgh4Vfyi3/GSeklQ3U72Gi3hjV5aXG/DAKVv05ZeH8hKgv+ZMdBQCZPs1+mFVB5rLMOnHXVSVg0DsZU+m+6UtHnnj7/n0uDBg1AMyD+F0UoTkEkP3diFpv9BPGCd18MU1fNHOV1aOoBwEyrPvTUFR/dRN7cgzJycDbiywCs1CNsMtlhY/LjEWArrT/ePWcjLiWB/FEFqI+ru7s76I8nFXmstIaGhkpdD/bs2YP3798jJCSkSKOg4eCMjIwwZ84cafSDsvbjLiInrSMzL8Ev/YDUUBWSrEHFFS2uLnTUzeCiNwSWvNbFra7U8qcj+HhKUtGuDCAuMtnkpHxR4pPSc5g6auhjo4X2JAPd0Ao6ygqpWCp2NCTi0aNHpc/9tWvXpG3RUImZJObk52JFcq3n+ZFPmzZN6nOurPThpRrwx8qZoigkCjwRmnEO6aJoZIkKHkwurB9NLo/Ed9UhYYhGQJ8Yr4Yass9kVVi/sr72PEkIb+IeNuoVmZjRcw30lVVIvFjdXJewJmaaGGHPQzcbHmg4RSb/bQLMaP1v3182OjkRSEtLw7hx46Qrr1Ts7e0RFhYm/b8sjVZqoO7fvx+HDh1CUFBQqUZjY2MjjTf766+/lgnjNSb7Dt6kbEFaTnypxp1XmcvhktVXW9QxWQJdtc+D28qkeZk2cp6kOu7qkwokkCwRRT2Q+DUNjNTh7qaP3iT8m56SAoJ/TbXCrr948QJbt26VHsh9+fJlYUW+ec3CwkIas3vo0KHo27cvrK3LxmHVDFE4IjLPISzzGskdQO59KUSTJBGw5tVFRd3+ZcJ4TSOTsRPhfIx6TQxVPjFQCzNSv8fDQA01DDSwpqoeWpPJGpP/JgFmtP437ysblZwIPH78GDSaAJXU1FTMmjULr1+//qI3WRmtdHWVGpm+vr4yHQ01XtevX4+2bdvCwIDG8lMtoVuiMdn34J2ylaysyj7dr66aEey0W8HZYAKJ8Kl6KzMzvFOxiq4y5XfkLuVt6kiiaywhP+i1ZBAKrpSqFFo9JSUFU6dOxZUrV6QrqrIQGnWGTi7Hjx8vi+bk1gZdXX2cMBnpOV+6PpS2Q2q8VjeaBEutJtJsYqoodDehF3V3ITsKMhEyMathpYVLjYxQTlv+B3RlorMCGpGQXK/Rj55Je/rw1BOBJKTm58IzMkTdabl/J/r2NtAnGRRVUZjRqop3hemkkgToASya3jX/9mR+ZUtrtFKjeOXKldLVVVkbrJ/rOmjQIGzbtg00A5iqSI4kDZ5J8xCd9UruKrnq94WT/hhiuKqGa79/eg56PU3Ba7LKKjch+SvPkjTKXclWqioJTTazYMECqTuArIXG+KYTNPqsW1qqVkY4CUQITNtLEg1cIQZroqyH/qk9W+36JG71PGK4qk44viQSk/sy8dMe9ITEIKeuL7IWssOwgvi9zqisOmOW9RC/114OiWqT4v8e/ifP48MLbwRfefS9KtLPjV3tYFKpPOrPngy9ctbQr6A6BqxqfFsXCSMrxAgol0B8fDyys7/vU0l9SEsqeQYr9UGVt1CjmEZE2LlzJ+gPu7Ilh6Rc9EyaSwxWb4Wo8jbtuHSl1VF/lNIN14C0HLjcJG4QqcXPDlgsWMQ46PYgCeebGqPzx5Bxxaovh8I05vHo0aMRGxsrh9YB6oN+5swZ0J0L6huryEOT3xqQBDnEYHWHb1qui9G3ypb2swj+M7Jwv4issi8gGQKVf0iPugO0fZCI5+FynKAl52DmsxTi58vBb8R4LVspd0p3x4WZfHx47IHna7YRQ/VxsRtLehsO+gq6+AAGlSxQbWAvVP91OHSslT/pYyutxb6drMKPTGDfvn3SDG7fEvoDrK5e/PkgTWe8YsUK6aEpRUr//v1Bx6WlpTw/MLEkGx6J0/Ah+40ihy7tq4p+f2K4jiY/asrZSqQrrC43FGCwfk5Wk4PLzU3R3lp595yqQ10BBg8eXCAigLwegjp16kj7pCnAlSl5K6yKMFg/H6cNrzZqGy8Hl6OptOFnER/thncT8Sri29+jslRwE3EVGO9Ismr+AJariCS4uT76d/gevChLhNC1Izs0h3fAol5NqGkq7/lhRqtMbytrjBEoOYGlS5di7ty5JW+gFDVp/FmaqpaG9VKGBKW743XqP8bpaHQAACAASURBVMroWtqnq34/OOuPU3j/wSScT6VrxGDNnzxDEZoQ379brc3Q0lI5P0C3bt2ShoyjK6GKFGq40lBxylxxDUjbpZAV1sK4WvNqoL7JOvKR4v/WqZt2ZTJB86dZDxUs1HCd6KT8HSV5Djvq/hN4rNxEVkgfyq2bKgM7ov2BLYoPlP5xRKp3CkFuqFnDjIDqEqAhrPIiEShDy5MnT2Lt2rXK6BoJAg+8ST2glL7zOg3nXycntiMVrsPu9yTrmzIMVjpSskXb6pZsIjOUBBz1M1W0wUr1pNEJ2rVrJzd3hO+xoIeuwvhfHoL5Xh1Zfk79xQPT98qyySK3NZMcMlSGwUoVnPQ4GWv9FDtBKjIYGRSMfvAUJzoMkavBStX0PXwJF/uNkYHGJWuCGa0l48ZqMQIyJTBy5Ei5HroqirLUNUHRIoEYAWn7iL+djI/KF3Mg9BBMZGZuit5iVi1x8cvR2Vj2snShjUrceV5Fchhm/puixQEtdV8fGxAKhejWrRuoO4yyhBqu1M9VGeKVtEDmUQKKO453abI/8PY9HW7GCLDKW7HPWn6dpvmn40OW8p67/PrI6j01WI+3HwxRpowiMHxHMb/TN3Gx7+jvlJLPxyU2WoVpSdi7dCZqV62KSo718NvO4s0c/Z9dx+X7vqCIU4PuomOHZtjl/UE+o2StMgIqTIAeDnn69KnSNaSZhtasWaNQPZKF3iS8lWxDepV0AKGZV0kgd9mEWiqKDoN8ZB/Wqij95i+ziKx+KXLK8OjRI5w7dy6/Ggp/v2vXLsTExCi037jsRySyU+niLctCYZGEHAJL3yOLporURhbJxT2ZxmClObmVKUk5OBKmOF9aRQw14s5DnOo5XGEGq3RM5D76nbyBK4PHQyzMDQGpiLHSPtRImJEFxe9MhFs75mDyvqeYsm4zZvdvh6SkZDSs5Yqodx64/fAZQqLSYFrOAmr8eDx5/BKZ2cm4//AJ1I0soZ0RgaUzJ2DP1SDYO5SHfTlLcNR1UL9mbUgifeDzIRPhb57hdXA0rO1swY8KwENPP5jb2CM97BXuvP6A8uWtkJOWgAd3rsLTJxhcAxOYkODCr+/cRpRYH5Z6HHg8vINkdVNY8HJw98ZteAYEQ8/KFoZaxT8kU3xGrAYjUDQCY8eOlaaEVbbQSAI05uykSZOgpib/Q0liiQCvU1aSVSfFGg5f40wzbmlxtWCqVedrRWR2nSYPcPclq05K/g2XDohEG+Kqc9HcQv6+rfQQ4++//64Sz3t0dDScnZ1BfVwVJS9TliBDRskySqtzijAADrq9iR+7/H8P78UKscZLybsKH4FdJX7kv5aniTZKvGZXWvQyq5/Dz8KdKXMR7x0sszaL01CcTwD5rRDBtkXj4lQrVdmSPa1ZH3CaLA9X7TgZY9s2lJ65rdoIiL53CB0m/w09ExOkkfAlrn1nY1V3M0wbQU7m2lcBJzkIofbd8GRuQzx+G4mYrHQcP+OGysNrYse2jeDV6AC9i+swdr833BzNEOr/Fl3//hf9JTcxc8MjHLx4AbFX9mDU8Rx4X16I1cN74UKkCCacTERpOePkwcVwnzUVWUPXYks/Z6yaOwVOk/ahTfgRjNvzEFaWuqgWKMK6Se0h/6/nUt0XVvkHIXD58mV4eHiozGhpUPctW7ZIDQt5S44kXWHhrYo6lnD+DRK79ZeiFi9xuTF0S760ma5K3HvBivN90/C7iy5J/ynfwzn0Wb9wQbFuGAVH+/8r27dvR48ePRQSTSAu+wGSBO+/pY5CPxOI+QjOOAQHvZFy7ZdPnvMpb8gqq6rIx9XWKSQMVlmXpwtX4f3lR0odxsu9h0k4rBHQtlBMRI6STTX46YhK58Pc3PT/QWIkYpw8vB8c5544e+U61k3pjIBLJxGaKgGHp43Rf23F2Q1TEHX3BTLr98fo9jVRufkYbFkzBeZfWJASqFeoj+P/XsTQxvZ4/cgXhZ0zzPK/g33nozD/6FVcv7oHFYMe4ZpPIe4FZPUoNSUBQm1tdBoyEr2buKpIKHGlPmescxUh4O3tLc2spUpC/f3ysn7JU6+wjNPybL5EbWeKkhCfXfy4hsXpLI7ESo0hcVlVSkjqTBrJQN6yZ4/itqSLMhaaKlZRk8YUoR+Zp8ifcVHGnVcmmehE48XKU6L4IvgoMLxVUcbye2DZP5CVGhyGN0f/Lcpw5VomIzwJPtv3ybWPzxsvmdFqYAxXM2P4eDxFXFYOJGIh4mPiiQtAFng8Xahz1cAlfg55OS64GpowJ0Fp9XRNgXSh1I+VilgsIsHNC45V08wSRjo60NHTQ06WABI1LkSkbHaOAOnEWJZKFh+pZL3UUEcTGkIRaVMMCcktrqbBAZ/EKRMKM8m/xOGao4aWw6dj6cQBeLh3Bf7efRppivFVLjgwdoURyEeA+tWpmtCkA4mJ8svOkzfedJJrXdWEGhV8sXyC3OeN9TjJsY4M1TsMsvStfH/IIyIi8PCh/ELxlPRZUlTUjuCM8yVVUW71aNIBgThJbu3Thne/z5Rr+yVqnCTxeBgnKFFVVan0euc/xF1Stml/Szo27wMnkB6umPMAJXMPULPA0CkjcWXicvQfGIbyBhz4ZdtifdsmWL/YHaNGvsIH7/tw6bwM5Y0L326yt7dH9OWjWLLSGuM72XyTlZ1LNfIl747pE4cgw/cF1CzaQbNSQ7RzTcH0IYNQTTMC4VZ10K5GVXg3csLs/Ssw+qEuPN+nobpIAPe1a/AoSRsc4q8mTk2T87zym0NhHzICZYJAeno6LCwsiqQrzRLGJ+kCi5MJjAZXpwkFVFGi+bdhp92tSKpRTjS2rSpkFCuSwt8olEG2canHglrhX9kFatKDewYGBtDQ0CjwWWEX0tLSEBgYWNhHSr329u1bpfav7M5zJHzIM8XEM5KZSuVEIEY4WQEuq5ISGAxfkppVVSQ1KAa++46i/rypclephAexAHPHmmjXuj40idlraumGcRNGo27LTmjvYAGxhh7q9huN2cO7Qp+sshqYlUOt2rVhoqcNQ2s7NP2pOlzdasJaVwuWtlVRo2pFGJtbok6tOrAyMYStsxtqO9tDi7gVOFSthXo/NcJP5L22cTmMnTQabpVcULdePfTu0hW62ZkwqVYPM+fPQe1yJqhcuwHK6WqiarOOGN69FVyq1UDbVnUhSEpDpdrN8cfUX2ClV7QvWbnTZx380AQePHiAf/75B5mZqrcSQXWigd+LIvQkeJ8+fRAcHCz1DaRB27+XEYzGRH2ZvLkozSu8TI4kE456A4rU74wZM7Bq1Sr4+Pigfv360nF/7xDbFO80RKSo3g95QJIQI5x0YKRZtA24Zs2a4c6dOwgKCkLdunWlxjuX+/W6Hz58wLZt24rEVZGFqM4tW7aEtbV1kbo9ceIEwsPDYWtr+93nPK/BRIEnQjMvk/3AvP3HInWlkEI5knhY81oVqa+///5bOpnV19f/7nNOG6QbqXtC+AhTwec9h/hv97fTLtK4i1uIuleJxeJv/j0Ut83Pyye8fgfPdftL04TM62rqa8G5Xze5J6hhGbFkfutYg4xA0Qhs3boVEyZMKFphBZeiqWjzXBfCwsLwLV9EGvng6NH/x32kRisdV6tWrdC8efNCNc8grgE3YoYW+pmyL/LU9NHOMjck071793Dz5s2vqnTjxg3QEE55UrNmTamxT+Puli9fvtB6nBPRID4IhX6m7IvBvSxRQVddOgGhqX2/JfRz+mzkSefOnaXG6/z58wut1qtXL3KAV/X8mKmy9Pnt169foXrnvzh+/PhPxvesWbNQjyyg9OzZM3+xL96HZBzFq5Qd3yyjrA/tdZqgltHiInVfo0YNUD98+mwPGzZMGm+3NlmQ+pq8IBOhuufl627ztb6/e91QHZJult8tVpICS5YswaVLl9CmTRtMnDiRnP8xL0kzX61zolVPhN/x/Ornyvpg4KNTsGoo32gcJXMPUBYR1i8jwAgonABdVVq0aFGR+6XbxrT8smXLoKWlhdmzZ4Mac506dSpyG6pSkK6GF2fsL1++BH2tXLlSuhI3btw46Q9X9erVVWVIRdKDZmgrzrhpozQqAH3RleeGDRuiQ4cOGDFiBExINJmyJNTgoCuKXxPqDpMntBxdWefxeBgzZozUaB80aNDXqqr8dXrP7t+//1U9qRsQldDQUOnzQcdPXWPmzJkjHfvXJqlfbbCMfkB3DL61Q/b48WPkvVavXg1HR0cMHTpUOqF1cnIqo6NWDbWZ0aoa96FMa+Fx/TheheaegK/gVAtNmtQBr9hhPsV44f4nhl0W4umhVdDV+HKbUSzIwO1LZxAitMKgPj+DR4h53/0XMSa10cbNvkzz+68qT7fI6MvPj8RYlvFKg6ozo/FIaYpS6i9Jf8x/JKHjjo+Pl479cwOvrDCgz2xx0svSzF60/Pr166GpqYmZM2dKDfcBA4rmYqJKXGi2suKMXUAOPdPX9OnTpT7t1IClh+2+tsugSmMtjS5Lly5FZGTR0j5T45auTlNGdDJLJ3HTpk2TxgeuVatWsdWgB54y4uKKXU8RFZ4tX4+uZ+WbkpsZrYq4k//xPvYt/Q2XUpxQ044Hr1erMGrtQczrVa/gqMMfo3Gv5Zh/bA/aViy4XSIkcXvjU4SFRpTITo7GhgWT/9feecBXUaV//3d7SW+kkgohCQkExBBKKOKCSpOlSjMK664uvSgisPaCK5ZFQX0XRHQVpSi74LuwAiJNUHqTFiAQIKSS3v/n3JiYQG5y783M3LnkOX4QMnPmnOd8Z3LvM895Cn5Md4My7AAe6+KN71Yuxt4Oz5HSeidpQY/w7f5Ro0aZHZMnaa9rneH+btxi069fP5OvYERExB2+XWqFAU4qdxZEn2N2XDmciIqKanTtvBjDyZO/V/Tia+VfRtzqxhPX84BTR2zcb7Gxe87X9MMPP9SrKMW3ycPDw/HSSy+ZFJiW9qLCLeoxMTEm1xg/Pz9HvO02ycz9uLl7RI8ePUy/9wEBATaN0xIuSmf567m1euvWrfDw8LBJac08cRpZJ+SXeYXfv7LC37I7iXgzBVdal84cik93M58t1gLiBuKDDxYhQGdBOGp5MY78chC6wGhEBXmIuGQaWmgCPB1ZpxGz8Nn0aIzqNhgp11j6s5sX8Nazz+PfR0/DLTgai5n/5pYF0/HzoV8xbdhIzF+2Ev3dU/H84ldx5GwxHnl2CRKYYJVZ5zH7kUE4XajFjNeWYFh8uElcXq2pSqPHsPsT8PaS9zDmsxdql1FZlIP1K97BR2u+Q6HCD398eh5mPpiAFx5NQrZPAk6yl9KXkxOxbOUmuLFH68CR6xgx+mFc3L4BJ8p98cbyD9HFz1loLE2ON2LECLzxxhv1/AKbvEiiDnw7q6ZxxW3NmjVmZ+Z+ijwqnPu7cesSdwVoajtcp/SGt64DCgp3mh3XXicijL8HoPEv48b8FWfMmGF6Nrllaf78+QgMDDQpbo21uSyJ/5uHZZRsvUZYJxUMv6UOaM/Kczd2z/kl3IIcFhZmUs6nTZtmUtAbU1S5Qu8I7YknnsDgwYPNisqtZV999ZXpPFdUuU8nD0TkvyfmskgEGPrjdN5nKKkUN62YWaEbOeGsal17lvvZ8ywP5hp3feA7J/ylhq/74YcfNgUgmrMYurEUlDCwXTOZ+nCbW2dTx7mC3lh+be4+UTcrBVfk+WeipZ+PTc3fks8LrrSeOfoztDGTsejRPnBx84Mne2jLC9Jx7NR5Vtdbj6j2sfBg0ftZVy/i3BVWvpEpIu3ax6Dywj7M/esUePWfguf/Mhy+ilwWbalGbGQoMi6exM0qT0QGOJkiVY06PXLgjI5tgpCbdhqnLmdD5+SH2OhQaJQVuMy+QK+wbAG+4VGI8HFpyfdXsrXvX/0CHvqvDikVfnitSyQqygvgERaKkcERWP/FKry9ahcWjB6PdzYtw9jZs9CnjQb/fPJv2KnqjNfnJ+BSVnVhiFuX0xA3dQGUX7yId1dswQPv/QU18Z0VVUq0HfIY0l+bifVHpteu7cz2z/HcexsxbtFCeKduxivTn0a/rttw6exxHMqLxCtzp8Ip7wD2bt+BB2b+DX0zPsELS5Zh8SvzkLJ4Dpau/wUrnuqN+g4J4qPjH/yWpgsSX5r6M3BfREtbUlISNm3aZPaLy9Jx5NJPp75zF8CcbNyqNn36dJPyZmkLMVrtO2Pp0M3qNypQD18r/Hq4Xx/3z7M01Rl/pvi2udxadHQ0+vTpUysWVzAasxZySzq/hvtv8gwKTWWL4ANrlZ4slZjgX7eCoAx2GlY7Dn8BaaxxRZX7qHOLMresN9XaOKtxn68O21gGAbm1F9rYXhGrqRc67hfNA1lbt25teqHjXPnLPLXmExDlt0jn7G56E3P1aAV1XipemPMk/vPTRZbwHwjp9RjWfTgRb015CptT0lixgHz0ePINjFT+fxw5fxmqL97FP3wD8FDmOjx70gu7/rUEG96ZidWlg/D17M54cswfkW9g6a+6jsaWpzpi+OTZuMkqIpaXafHo8x9gVGgqHkt+ETeYT6R317HY9NFckNra/AelqRFC7n0QU4bHY+eq17D0rdW45/nu2Lp2A1JY/ubMzGwE5RUgMjoWGrURcV0TEKzJw8HUAgybOQJDHurGhq/EvmWb4R6fhOQxY/DtmW9w8MRN8I+6uklJlO5t8PLM4Zj67vvozXLt8Xbx9DEofbogedQwOF3SY8WSSbicXV21ouvIqRjY4x5c2H4QxqAwjB09FuklW/BOaRL+zCydqd8sxcnL6SxrKKu/3tQiRTjPt975i5icGk/9Y8kXcY3M3LrWmIXN3NpaGweyF1N5WVr1KldWoY/b/C1rtgRVeHJ/bSWzQFU2UFnFsmlF6RWot2BHrM7Mligtoggq8KBGVsjG19fyKHKe5syWplW6oLAi15ZLRbtGo9RDYUWNSKkKMYi24DoDR7qI9/LILe886KqpHScp1nm3zSHK9/SBr9/EH9n2yrQl6/Hr4a1Yu3E/AsLjEBPhhT0frcDBPCP6DumL++/phABmdT20eS8SJi1E3w7tMHrBh1g6fZBZzmVKLYbOewc/vjsN3678ECfSKhHXIR4+ulysXb0OF1Iu4CZTYIfPfBrPPNKP1cyiJgUB94A2bLvwHkQF+6IkJwepR/fj52x/vPfZSvRu89trg0oNjaIQl1OuIl/jhLYeamzbvRe/nj+EdZu3WiimAvEjp6P1+a/x/enqqk1uHt7IzziBHb8cx4EtG3HDEIGgVtZ9AVs4ueDdpk6dKviYzR2Qp/7hyrTYzVUdCbVCXjmTDSoPFkRoWb5OW/k8EsJew5xF+ei1VSTTdYtiXJt1fVMXc+slt0zKrQ0b9rulUUzZIpwtS6klpgy3j93a0JtZgcV1x5vMn3e5NWcVEr3E++xp166daAqrd1w0vNo3nE7P3pi1LuK72Ynyydn7L+/g9IUL+M/f/wRVfh4q1K3QvnsikgYMx4I3pyE05xhmzP0Hbvq0QVRo/XQo3D+MNwWzRPDkvFVVlcyKWienocaI4EB+w6qQm1MA1+D26Mzz5CX/FU9OHIB7+0/E4ueScWH9+5i+8C1cL5SXNcPeD5UY83t6tcKBlfOQ0LkbPjmowdy//QVd7+2LJK9LGDN4PDKUfjCwKhSVwZ0wqZc/Xp8wEV/tK8QT82fC+fsP2BfZBGy/XMFK8OrgotexN3/mNaI1wGjQmv7Nm4KV6DUYDayYBXtkdT546enJuHY9F/4ebug0+E94MtETC4bch8eW78UTb72CeBcF9AZX6Hl/1pQqDQwGg6naj0qrRytDdQ0YXsBCrxNlw+E3yRv/i/sFyi3S1tKiAo2vrOmzGqU7wp0ebLqjRD0U7Glr55IsyWyTgnj+C/m0EH8dDCL/Gri5uYF/mcup8SAiqSzG7ppY9kIk/pe6NXz9DX2s6W5T30RvphyKomnYJE71RUalKR+xIzanQH8YfcQ3KtjC5t6nxTfCiH7XWkXEwsuYh19OnoPSV4GdBwqQ/EgMSqFCacY1XEu9BLh3QxXzUw1iVtfv1yzH6hA39OwUhRMrP8fTTz+BbesOwOePvwdHmGAqNUjoGo8z/92E81fDocpJQW66F0Jyf8BH2zIREhAI1WFudWUuCbbQp2ssJvDqhuN4tYHeX/7y6x1H56/Zhvm1R9tg68mRdfo8hLOTq38ctWgV6sarG1pFYN3Os7V9IwZPx0X2p6bN/+TfdcatPrps+5Xa86G9krFnR3L1z3M/RcpvZxZ+sr22jz3+wYM3uKWHp8uRQ7v//vsltYa1c5mCM/nVifztvX53bTB8dX0kEWNGWydTpSAUyqPIwLJYF+i4y4LIjRceqClaIfJUFg3fs2dP9O/f36K+ze3krA5Fa30vnC3Y3NyhBLneW9sWXlrx07GFMeVwRIQRa8/Kp/Lfpo5ugjCkQaQnYHMZV3OilhbnIrRjL3SK8DW9XBm8w/HggI7ISktFGQvSeWL+bMSEx+C+SGekZlbivuEj0blNFDp17YQundqgKD0L/qFd0GNgf8TpWE1zY2tMf2oMS9Qdic7tgpjvoQadE3ogwM0A/0734b52lSz6OhcuQfdhzozhaBvFIlTTLiKPbXnMeOEldA8Td+vDHAc6TgQsJcCjrr/77jvkMLcKezZudeLRw3UzB4gtj0KhYvZNluqs9JTYUzU5/j0e82BUBTXZT4gOrVjAU2pBBQ5lsLdqezdfLVbHu9buaogpjqurK/Nxz8T+/fvFnMbisVevXi1pWjK92g/XirejvIo5+9ux8V2FePcZcGKKtBStbysd3jzBgk9k0PzZrsLyjuK6woi9TM82YTi+8muxp7Fq/LZDe+OeOU9ZdY0tnamMqy3U6BoiIDABnjrp3XffFXhU64bjEdTbt0tvea6sKsGezKeQWXrBOoEF7M2tTt29P7AqKKW50x9jOYk7bM2wr7WVWRa+6euFoSxzgFTtJkuMzgN17d14TtGNGzeCv6xJ2Y7nLsb5gu+knPKOuTy1YUjyXnHHcbEOcCe9Cftz8Plp+6f8+t8Ab/RjGQ0cueWev4i1D45B7rnqrDtyWEuvl2egy/wZoosiN08T0RdMExABORLg5RB5In57NZ5fkldssUdTKnSIdJnIAurFi+ZtbF1GljEg1m2GpAorlyfOTYNvu9l5J4j5G0qpsPJ1e3t746OPPrqj4ERj90iMc/PmzZNcYeXriHGdAW9tGzGWZNGY/PeM/75J2bjjydvcusmCb+3ZIgP06Onj+OHZbhGhiBk91J4o683t1tYf0ROlCTQkpVU2t50EackEeO1yXsvbHkFZPM/m+++/j4EDB9rtFrTS9WbblVMkz2XJU1wleL4KN02MXdbOLT6jI412mRvMLSC9r7fkcysUClPFsNjYWMnnrplw5syZpqT49mhKhRbRrk9CZ4egLJ4rtqP7U5L5btfl66NTYgXznZbED6WhG8vyI6+Kl8Z3u6HphT4WO2k8XEItzykt9Px1x+swcRScgsTNulIzn+A+rbaCKbieyqooXUNxTkbtH7DMAWqD7QmAbZWFriMC9iDAfVt5JPP//vc/5OZKk8+Rp7b6+9//DmuKCYjFxk0TxbI9OONmySGWG0T8ACW9ygWJnq8zhbW9WEtqclwtC3560E+PsyUVOJkpnX+rgims13p7WlVMoMnFWNlh0KBBJneU69el3eLkxSD4zgZ/UbRXM7C0al7aaFwv3oWKKmnuO1dYO7j+GcHG4fZaNjp5aKBgGV123GA+vVIm9mHZAvYxN5hEb8e3stbcPJ27G0rTM3Bl1y92u598YucQb/xh2ZvQOEnz8m03n1aupOZdvYAbx34yAef/Li2o76itZ/k3nXyq6xgHdR8Ao6cvC+xqOTWd7fok2nnyvPJzLPd6eT0pjCo/VvHM3c6SiT/9nj17THXfr169KupkvPY1r1A0adIkUeexdvDLRetwNGc5+zKvf/+tHaex/jqlEd293oIrU5Tl0IoqqjCO+fxtkCDCmiusV5nC6m9F9SuxGPFyl7xM7sGDB8Waot64U6ZMwZIlS2RTiS677DD2Zc5HaaW4FaO4whrn+gRCnOpma5EEeYOTLDyeh5ePsHKx7LkXvemV2P8Hb9zLFOa7rZUXFWPTqMk4v2mX3ZaW9OI03LtglmTzS6q0lhXm4+axfchOOYX0Ez+jqoLXIbK8aZ2c4RHRHq06dDP9rdbJMGmx5cuhnr8RqGI5IYoqriGdWR0yS6u/vK4VH7pDafHQtGbRrtUvLVGuU1ihAhfRE2Pb6ybx6Orx48ebqmXxfMVCN152dMGCBXj88ceFHlqQ8TJK9+JM3ifM6npGkPFqBuFR06HG+xDqPBKuannlDOXpqIftzcam1GIwLUbQdZsGUyvQmvnz/ZTkIQuFtWaBFy9exPDhw0VVXJVKJSZPnozly5eznM/ip/ay5ubllLGiKFkLWbUscbKH8NywUc4TZaOw1rBZwBTXVw4zxVXMynDMJeGX/t7ofBcqrDUc037chw0jJ6EkXfogt9hHh+D+j5awDKTS+SpLorTyAgHX9m9D6r4tKLiRZs3vs9m+7qFt0brnQPjEiJ9nzqwQdKJZBMqr8nG5YD2yy07iSlG1xd2aAV3U3myLLRbhzmPhrA6TPJDGGllt7ZucnGyKcM7OzrZ1iHrX8YCrbt264csvv5Sk6lVzhC6rzMWlgq9xpmAtyipLmjMUezYULJ2VOyJdJyDYIE0FJFsFPsDcBBK2sawCxUxxFcoQpVXgnwnueDxcmi08a9fOFddly5bhvffeQ3ExU9oFbNztZtGiRbLbUbh9iYeyF+Jq8b47XtZv72fpzzzgylMTxny22datTHeo/nWpCOOO3QKyBN5VYe8lg1lu2EXRzuhyFyusNc/C9b0/46sHx6H8VvM+Jy19tngZ6pgxD+CBz5ZZfIlQHUVXWrnCmrprM859GU+9uQAADqBJREFU96VQMv8+DntjDu75AML/MApK9d1n+hcemFxGrMKF/E9Z2pf1zLrAPrAEaEGGBBYR+ye4qMWNyuVb9xs2bGhQYm7Nee211wSPij5y5IjJ7/SLL75AhZW7EzWCqlQqU3aCuXPnSpZMvUFINhysZDkt+fNyMu9fpqurrNDkqpVVD6asjpe9sno7mrd+LcCco+z3o6gZVlf25T2vowuei3FhL3bysjDevl7+89dff43FixebrK7N3WHgzzzfrZg9ezbi4uIamk52x26V/4pzeavYS/w+q57zugvhz7yXNoJ9Hj7Kypv3lN0abxfoSlEFXmQ5XD8+xdwDhXhJY/6rb3VwxazIlhUPY1JcH2CKa574imvMIw/igc+lV1j5syOq0lqclY6DK15FcRazGojY3IIjEP/4s6bynNTkT+BozstIKfxecEF1Sie0cx6DMOfxgo9dM2BgYCDS0szvFjz33HN4+eWXRZn/zJkz+PTTT8HzXPKUQZa0oUOHmqK0eaUrnof1bmjn8v4fS85eyF540pDagIU+0nko+9pWwoWlFQrUP+TwS377TAFSCsrxj8vMAplrgUWKWVWntnMylSx+O94xK//wF0P+osZfEm1p3O3l2WeflbRQhi1ymrsmv/wSrhR+i5LKbFws3GGuW73jfvo4uLGXdm99AkuplWjRNXLqlFtWhbnsJe1jW4sQuKjwdnsXzGhhymrde8gV17VDJ7Jqo+JVH2s/YRAGrFpqt0dHNKW1KOMGDn/yOoqybkqyOO4uEDdhDjSUbUAS3rZMklt2Cnsz57APYvF+obhcIcYklj7pRVtEbPIargTy7XpzTUyltWZOboEqKqoO3OCVtHbu3FlPnIiICJP/Hm86nc4uuSjN8RHyOPeF5oUJbm8qhTy3wG+X09qfi1nQSjmzRHF312mH78wuMZd9WUc4q00ZhZwcwKra1PpLS0tRVlaGH3/8EZs3V5c+Xb9+/R0BiklJ7Pc9Pt40HM+96ubmBoPBIPiOR1PyinGeZ9GorKp2l0gv+REZJfUjxZ1UgbW+qjyVlgLS+RaKs16ggD/krM06cou9mFbhaH4Fjl25zWWEPeTj2IsZb0leWowLMZhe0gz8fy28lRUWYftfn8HxVea/p2xB5NTaE8PW/hPeneLYzrb9njNRlNaijOs4vGoxijLTbWFj8zUe4VGIHTsdGiPLBUdNVgRyy05jd+ZM5psorL9aQ4vk22PBJsX1hYZON+tYYWFhbbnV9PR0TJgwAcePH68dUwqltVkLoIuJgAMT4L9z5eX1rc28NKyzs7MDr4pEb4wAz6yR2UBgYpDBPsVIGpNVLufKi0uQfuAQDixe2uzMAm4Rfujw6CjE/flR6H287L5EUZTWn959hgVciZuuxxw5z4gY5iA8BVonx64tbG59jnicK6x7MmeJntbldjZhxn6Ic3+WqbDCf7jx3JJjx469o+wpKa233wX6mQgQASJABOxBoJwFNaYfOIyDb3+IShYPce7f9XflzMnk1T4EXm3D4du5A2KSx0hWOMCcPHWPC27jvbT9GxQyS6u9Wtb5k8g4cQABCf3sJQLNW4dAeVWeySVA7DyEDUHnfrMKFkHb3nUOC3YULlCPK6zjxo2rVVijoqJw+vTphkSgY0SACBABIkAE7EJAzQpoBCQlmv5UMbcybn3l7dpPB3H+31vqyaT3cEOX2U+ajjkF+sM5qDpHvl0Eb2RSQZXWkrxspGz/1ur8q43IZ9Op1L3/ZblcE6HWt6zoQZtgiXgRj/o+c+tD5sMqff64mmVdKNiC1sbBcNcIUzKSB0HVtbD26tULb7zxhimNFDUiQASIABEgAnIkoGDZbXy73mMSjf8dP+1PchSzSZmUTfawosPlHzaislyaknSNicVzwd78rdJWY/3onLgEbpWfxtmCTeJOYsHoZ/NWsGCG5j+XWVlZGDFiRK2FlSusPN+pn5+fBVJQFyJABIgAESACRKA5BARTWsuLC5C6Z2tzZBH02os7/8MUaFbfmJpdCLA4Z1bRaIVd5r590jRWXSuvvHmVlfLz8zFkyJDaSP2ePXtizZo18Pf3v306+pkIEAEiQASIABEQgYBgSutF5ssqp8YzF6Qf3ScnkVqULDy91bXiI7JZ8695HzNZbEvSztNLDRgwALt37zatJzExEevWrau1sPKykOrfUoDU/C2bhZMgRIAIEAEiQATuEgKC+LRWlJUi91LzLFli8Mw6ewx+nXuJMTSN2QSB07eWN9FD2tNcgc4pO8F8W62rjFNQUGCqIFWT5DwhIQGbNm2Cp6dn7QJCQkJMVbIOHTqEhQsXSrswmo0IEAEiQASIQAshIIjSyrfhcy+flx2yrJRTspOpJQhUXHGdJYWWNkevJVyzSg5apbTm5ORg8ODBtQpr165dsWXLFvC8kLe3QYMGgf+hRgSIABEgAkSACIhDQDD3AHHEa96olayiSsGNK80bRAZXv/jiixg9ejQ+/vhj8OT2cm8FFanMh1Tc0r22MLhestfiy3iWgGHDhmHXrl2ma7iF1ZzCavGg1JEIEAEiQASIABGwmYAgltbLLOhJjq28uBDZF07AyTdIjuLVyrR27VpUsMS/5hrfdv7mm2/w1VdfYfHixYiJiTGlXerduzdFrpuD1sDxkspcli82E1pl41U9bty4YcrDumPHDtMo3MLKy0g2ZGFtYBo6RASIABEgAkSACIhAQBCltbwwXwTRWs6QycnJ4L6TlrRz586B/9m4cSOio6PB/SmnT58OnuA+NDTUkiFE75OSv0b0OWyZ4FbZddwqPwtvbeNKq5OTEwIDA01T9OjRwxR0VdeH1Za56RoiQASIABEgAkSgeQQEUVqbJwJdbSuBU6dO4erVq+DpmKZOnSobpbWoMsvWJcniOl7HfOnSpeAvE/xlwNfXVxZykRBEgAgQASJABFoyAVJaZXD3uWJUVmY++X1GRgbS0tJqJfXx8THlB504cSLi4+PRrx+VrBX6Nrq4uKBv375CD0vjEQEiQASIABEgAjYSEERpVekNNk5Pl3ECP//8c6MgnnnmGaxcuRJckZo1axbat2+PPn36NHoNnSQCRIAIEAEiQASIwN1EQBClNaTPUFz+8TvZcVEzZdojNFp2clkr0NChQ/Hwww87TH17pUJj7RKpPxEgAkSACBABIkAEGiVwV6e8Ump1cPIPbhSAI5zs3r27wyisnGeUy2RZYnVWe8KokncmCVmCI6GIABEgAkSACMiAgCBKq1KthWtQuAyWU18Ez9Ao2clEAtmPgEHlQ0qr/fDTzESACBABIkAEmkVAEKVVpdHCPaxdswQR42LPyA5iDEtjNkFAr2zFlMM7q0Y1cZnopz01MaLPQRMQASJABIgAESAC4hAQRGnlooX0HiKOhDaOavDygU9sVxuvpsuaQ8BJHQIXtfy24f0MlA2gOfeVriUCRIAIEAEiYE8CgimtGqMLWifKJ/VSSM+BUDGfVmr2IRDh/Ih9JjYzq4+uHVOk25o5S4eJABEgAkSACBABuRMQTGnlCw1m1lal2v6R48ZWAfCJS5Q7+7taPk9tZ/joImWzxrbOE6BS6GUjDwlCBIgAESACRIAIWEdAUKVV5+aFkF4PQaFUWSeFwL1bJ/4BGqOzwKPScNYQUCmMaOM83ppLROvLraxciaZGBIgAESACRIAIOC4BQZVWjiHs/pEweLWyGxH30Ejmy5pgt/lp4t8JeGnvQYDe/spiW6Y8qxRUAIOeTSJABIgAESACjkxAcKWVw+gwfhb0Hl6Sc3ELaYPYcTOgdXaTfG6a8E4C3Noa774QSoX9LO9++jhmZe1yp3B0hAgQASJABIgAEXAoAqIorUYff3RKngedu6dkMHie2A4T50DrJL9US5JBkOFEGqU7unm9BAX7T+rmo4tCgucS8mWVGjzNRwSIABEgAkRABAKKKtZEGNc0ZFHmDRxa8SqKszPFmsI0rmtQGDpNeg4qHQXaiAq6GYNnlO7Dnoz5qGL/SdG4wtrda5kUU9EcRIAIEAEiQASIgAQERFVaufxFGdeR8v06XD+yV/jlKBQISrwfEQPGUHor4ekKPuLNkt34Ket5VFSVCz523QH9dLFI8Hqb2XbVos5DgxMBIkAEiAARIALSERBdaeVLqaqswNV9W3Hlp+9RePOaIKtzC45AUPcH4NuhmyDj0SDSEEgv2YGzeZ8jo/Sc4BNqlDoEswIC0a7TKPBKcLo0IBEgAkSACBAB+xKQRGmtWWJpfi7Sj+7F1f3bUJCeZtPKa5RVr8iOUOuNNo1BF9mXQHlVAU7eegdXi3ajtLJIEGG8tOGIdElGK12SIOPRIESACBABIkAEiIC8CEiqtNYsvSQvGyU5Wci/dhE3ju0zHc6/dhllhQX16PBALqOXr+lYULcB0Ll4gAd5kbJaD5PD/pBXfgEpBV8grWgvSirr33tLF+WpDQVPaeWtS4Ra4WTpZdSPCBABIkAEiAARcDACdlFaG2KUf/UiSovy6p0yuHvD4O3fUHc6dhcRuFV+FiUVN3GzeDdulh41rexWeRoqqyrrrdKocodWWV00Isb1z+yc0lQ0gCpd3UUPAy2FCBABIkAEiIAZArJRWs3IR4dbKIH0kh9YwFZxvdW7adrDqApqoURo2USACBABIkAEWjYBUlpb9v2n1RMBIkAEiAARIAJEwCEIiFJcwCFWTkISASJABIgAESACRIAIOAwBUlod5laRoESACBABIkAEiAARaLkESGltufeeVk4EiAARIAJEgAgQAYchQEqrw9wqEpQIEAEiQASIABEgAi2XACmtLffe08qJABEgAkSACBABIuAwBEhpdZhbRYISASJABIgAESACRKDlEiClteXee1o5ESACRIAIEAEiQAQchgAprQ5zq0hQIkAEiAARIAJEgAi0XAKktLbce08rJwJEgAgQASJABIiAwxAgpdVhbhUJSgSIABEgAkSACBCBlkuAlNaWe+9p5USACBABIkAEiAARcBgC/wctbi8LbFG4qAAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "\n",
    "  def __init__(self, emb_dims, no_of_cont, lin_layer_sizes,\n",
    "               output_size, emb_dropout, lin_layer_dropouts):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    emb_dims: List of two element tuples\n",
    "      This list will contain a two element tuple for each\n",
    "      categorical feature. The first element of a tuple will\n",
    "      denote the number of unique values of the categorical\n",
    "      feature. The second element will denote the embedding\n",
    "      dimension to be used for that feature.\n",
    "\n",
    "    no_of_cont: Integer\n",
    "      The number of continuous features in the data.\n",
    "\n",
    "    lin_layer_sizes: List of integers.\n",
    "      The size of each linear layer. The length will be equal\n",
    "      to the total number\n",
    "      of linear layers in the network.\n",
    "\n",
    "    output_size: Integer\n",
    "      The size of the final output.\n",
    "\n",
    "    emb_dropout: Float\n",
    "      The dropout to be used after the embedding layers.\n",
    "\n",
    "    lin_layer_dropouts: List of floats\n",
    "      The dropouts to be used after each linear layer.\n",
    "    \"\"\"\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    # Embedding layers\n",
    "    self.emb_layers = nn.ModuleList([nn.Embedding(x, y)\n",
    "                                     for x, y in emb_dims])\n",
    "\n",
    "    no_of_embs = sum([y for x, y in emb_dims])\n",
    "    self.no_of_embs = no_of_embs\n",
    "    self.no_of_cont = no_of_cont\n",
    "\n",
    "    # Linear Layers\n",
    "    first_lin_layer = nn.Linear(self.no_of_embs + self.no_of_cont,\n",
    "                                lin_layer_sizes[0])\n",
    "\n",
    "    self.lin_layers =\\\n",
    "     nn.ModuleList([first_lin_layer] +\\\n",
    "          [nn.Linear(lin_layer_sizes[i], lin_layer_sizes[i + 1])\n",
    "           for i in range(len(lin_layer_sizes) - 1)])\n",
    "    \n",
    "    for lin_layer in self.lin_layers:\n",
    "      nn.init.kaiming_normal_(lin_layer.weight.data)\n",
    "\n",
    "    # Output Layer\n",
    "    self.output_layer = nn.Linear(lin_layer_sizes[-1],\n",
    "                                  output_size)\n",
    "    nn.init.kaiming_normal_(self.output_layer.weight.data)\n",
    "\n",
    "    # Batch Norm Layers\n",
    "    self.first_bn_layer = nn.BatchNorm1d(self.no_of_cont)\n",
    "    self.bn_layers = nn.ModuleList([nn.BatchNorm1d(size)\n",
    "                                    for size in lin_layer_sizes])\n",
    "\n",
    "    # Dropout Layers\n",
    "    self.emb_dropout_layer = nn.Dropout(emb_dropout)\n",
    "    self.droput_layers = nn.ModuleList([nn.Dropout(size)\n",
    "                                  for size in lin_layer_dropouts])\n",
    "\n",
    "  def forward(self, cont_data, cat_data):\n",
    "\n",
    "    if self.no_of_embs != 0:\n",
    "      x = [emb_layer(cat_data[:, i])\n",
    "           for i,emb_layer in enumerate(self.emb_layers)]\n",
    "      x = torch.cat(x, 1)\n",
    "      x = self.emb_dropout_layer(x)\n",
    "\n",
    "    if self.no_of_cont != 0:\n",
    "      normalized_cont_data = self.first_bn_layer(cont_data)\n",
    "\n",
    "      if self.no_of_embs != 0:\n",
    "        x = torch.cat([x, normalized_cont_data], 1) \n",
    "      else:\n",
    "        x = normalized_cont_data\n",
    "\n",
    "    for lin_layer, dropout_layer, bn_layer in\\\n",
    "        zip(self.lin_layers, self.droput_layers, self.bn_layers):\n",
    "      \n",
    "      x = F.relu(lin_layer(x))\n",
    "      x = bn_layer(x)\n",
    "      x = dropout_layer(x)\n",
    "\n",
    "    x = self.output_layer(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Example Neural Net for MovieLens dataset (Users, Movies)\n",
    "\n",
    "lass EmbeddingNet(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, nh=10, p1=0.05, p2=0.5):\n",
    "        super().__init__()\n",
    "        (self.u, self.m) = [get_emb(*o) for o in [\n",
    "            (n_users, n_factors), (n_movies, n_factors)]]\n",
    "        self.lin1 = nn.Linear(n_factors*2, nh)\n",
    "        self.lin2 = nn.Linear(nh, 1)\n",
    "        self.drop1 = nn.Dropout(p1)\n",
    "        self.drop2 = nn.Dropout(p2)\n",
    "        \n",
    "    def forward(self, cats, conts):\n",
    "        users,movies = cats[:,0],cats[:,1]\n",
    "        x = self.drop1(torch.cat([self.u(users),self.m(movies)], dim=1))\n",
    "        x = self.drop2(F.relu(self.lin1(x)))\n",
    "        return F.sigmoid(self.lin2(x)) * (max_rating-min_rating+1) + min_rating-0.5\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created the basic data structure to run the training loop, we need to instantiate a model object of the FeedForwadNN class created earlier. This class requires a list of tuples, where each tuple represents a pair of total and the embedding dimension of a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4803, 71, 1609, 436]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims = [int(df_small[col].nunique()) for col in categorical_features]\n",
    "cat_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4803, 50), (71, 36), (1609, 50), (436, 50)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dims = [(x, min(50, (x + 1) // 2)) for x in cat_dims]\n",
    "emb_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The hidden layer dimension is 50 and 100 for the first and second layers respectively. The embedding dropout used is 0.04. The hidden layer dropouts are 0.001 and 0.01. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = FeedForwardNN(emb_dims, no_of_cont=len(dataset.cont_cols), \n",
    "                      lin_layer_sizes=[50, 100],\n",
    "                      output_size=1, emb_dropout=0.04,\n",
    "                      lin_layer_dropouts=[0.001,0.01])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardNN(\n",
       "  (emb_layers): ModuleList(\n",
       "    (0): Embedding(4803, 50)\n",
       "    (1): Embedding(71, 36)\n",
       "    (2): Embedding(1609, 50)\n",
       "    (3): Embedding(436, 50)\n",
       "  )\n",
       "  (lin_layers): ModuleList(\n",
       "    (0): Linear(in_features=186, out_features=50, bias=True)\n",
       "    (1): Linear(in_features=50, out_features=100, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (first_bn_layer): BatchNorm1d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn_layers): ModuleList(\n",
       "    (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (emb_dropout_layer): Dropout(p=0.04)\n",
       "  (droput_layers): ModuleList(\n",
       "    (0): Dropout(p=0.001)\n",
       "    (1): Dropout(p=0.01)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardNN(\n",
       "  (emb_layers): ModuleList(\n",
       "    (0): Embedding(4803, 50)\n",
       "    (1): Embedding(71, 36)\n",
       "    (2): Embedding(1609, 50)\n",
       "    (3): Embedding(436, 50)\n",
       "  )\n",
       "  (lin_layers): ModuleList(\n",
       "    (0): Linear(in_features=186, out_features=50, bias=True)\n",
       "    (1): Linear(in_features=50, out_features=100, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (first_bn_layer): BatchNorm1d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn_layers): ModuleList(\n",
       "    (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (emb_dropout_layer): Dropout(p=0.04)\n",
       "  (droput_layers): ModuleList(\n",
       "    (0): Dropout(p=0.001)\n",
       "    (1): Dropout(p=0.01)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'vote_average', 'vote_count', 'budget']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_epochs = 5\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = {'epoch': epoch + 1,\n",
    "#          'state_dict': model.state_dict(),\n",
    "#          'optim_dict' : optimizer.state_dict()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "11890\tTrain Epoch: 0 [64/4803 (1%)] Loss: 71.4264\n",
      "11890\tTrain Epoch: 0 [128/4803 (3%)] Loss: 86.3414\n",
      "11890\tTrain Epoch: 0 [192/4803 (4%)] Loss: 85.2336\n",
      "11890\tTrain Epoch: 0 [256/4803 (5%)] Loss: 65.9389\n",
      "11890\tTrain Epoch: 0 [320/4803 (7%)] Loss: 72.7590\n",
      "11890\tTrain Epoch: 0 [384/4803 (8%)] Loss: 44.6330\n",
      "11890\tTrain Epoch: 0 [448/4803 (9%)] Loss: 45.0564\n",
      "11890\tTrain Epoch: 0 [512/4803 (11%)] Loss: 52.8659\n",
      "11890\tTrain Epoch: 0 [576/4803 (12%)] Loss: 82.5601\n",
      "11890\tTrain Epoch: 0 [640/4803 (13%)] Loss: 85.0812\n",
      "11890\tTrain Epoch: 0 [704/4803 (14%)] Loss: 18.3583\n",
      "11890\tTrain Epoch: 0 [768/4803 (16%)] Loss: 25.2109\n",
      "11890\tTrain Epoch: 0 [832/4803 (17%)] Loss: 11.4357\n",
      "11890\tTrain Epoch: 0 [896/4803 (18%)] Loss: 32.8379\n",
      "11890\tTrain Epoch: 0 [960/4803 (20%)] Loss: 18.2873\n",
      "11890\tTrain Epoch: 0 [1024/4803 (21%)] Loss: 20.8141\n",
      "11890\tTrain Epoch: 0 [1088/4803 (22%)] Loss: 26.5773\n",
      "11890\tTrain Epoch: 0 [1152/4803 (24%)] Loss: 62.1367\n",
      "11890\tTrain Epoch: 0 [1216/4803 (25%)] Loss: 53.6979\n",
      "11890\tTrain Epoch: 0 [1280/4803 (26%)] Loss: 13.1485\n",
      "11890\tTrain Epoch: 0 [1344/4803 (28%)] Loss: 19.5044\n",
      "11890\tTrain Epoch: 0 [1408/4803 (29%)] Loss: 34.6392\n",
      "11890\tTrain Epoch: 0 [1472/4803 (30%)] Loss: 19.5216\n",
      "11890\tTrain Epoch: 0 [1536/4803 (32%)] Loss: 34.8808\n",
      "11890\tTrain Epoch: 0 [1600/4803 (33%)] Loss: 32.0777\n",
      "11890\tTrain Epoch: 0 [1664/4803 (34%)] Loss: 54.3379\n",
      "11890\tTrain Epoch: 0 [1728/4803 (36%)] Loss: 34.5657\n",
      "11890\tTrain Epoch: 0 [1792/4803 (37%)] Loss: 260.9636\n",
      "11890\tTrain Epoch: 0 [1856/4803 (38%)] Loss: 42.1679\n",
      "11890\tTrain Epoch: 0 [1920/4803 (39%)] Loss: 46.9980\n",
      "11890\tTrain Epoch: 0 [1984/4803 (41%)] Loss: 68.5888\n",
      "11890\tTrain Epoch: 0 [2048/4803 (42%)] Loss: 67.5619\n",
      "11890\tTrain Epoch: 0 [2112/4803 (43%)] Loss: 16.8924\n",
      "11890\tTrain Epoch: 0 [2176/4803 (45%)] Loss: 48.6431\n",
      "11890\tTrain Epoch: 0 [2240/4803 (46%)] Loss: 59.8088\n",
      "11890\tTrain Epoch: 0 [2304/4803 (47%)] Loss: 35.2445\n",
      "11890\tTrain Epoch: 0 [2368/4803 (49%)] Loss: 35.4330\n",
      "11890\tTrain Epoch: 0 [2432/4803 (50%)] Loss: 24.8460\n",
      "11890\tTrain Epoch: 0 [2496/4803 (51%)] Loss: 11.6862\n",
      "11890\tTrain Epoch: 0 [2560/4803 (53%)] Loss: 34.3959\n",
      "11890\tTrain Epoch: 0 [2624/4803 (54%)] Loss: 23.9636\n",
      "11890\tTrain Epoch: 0 [2688/4803 (55%)] Loss: 165.3957\n",
      "11890\tTrain Epoch: 0 [2752/4803 (57%)] Loss: 23.0355\n",
      "11890\tTrain Epoch: 0 [2816/4803 (58%)] Loss: 30.1771\n",
      "11890\tTrain Epoch: 0 [2880/4803 (59%)] Loss: 35.9469\n",
      "11890\tTrain Epoch: 0 [2944/4803 (61%)] Loss: 35.5389\n",
      "11890\tTrain Epoch: 0 [3008/4803 (62%)] Loss: 50.2559\n",
      "11890\tTrain Epoch: 0 [3072/4803 (63%)] Loss: 114.6445\n",
      "11890\tTrain Epoch: 0 [3136/4803 (64%)] Loss: 51.4663\n",
      "11890\tTrain Epoch: 0 [3200/4803 (66%)] Loss: 43.4893\n",
      "11890\tTrain Epoch: 0 [3264/4803 (67%)] Loss: 22.7686\n",
      "11890\tTrain Epoch: 0 [3328/4803 (68%)] Loss: 24.9117\n",
      "11890\tTrain Epoch: 0 [3392/4803 (70%)] Loss: 133.0412\n",
      "11890\tTrain Epoch: 0 [3456/4803 (71%)] Loss: 89.9070\n",
      "11890\tTrain Epoch: 0 [3520/4803 (72%)] Loss: 12.5342\n",
      "11890\tTrain Epoch: 0 [3584/4803 (74%)] Loss: 25.7251\n",
      "11890\tTrain Epoch: 0 [3648/4803 (75%)] Loss: 109.1460\n",
      "11890\tTrain Epoch: 0 [3712/4803 (76%)] Loss: 50.9684\n",
      "11890\tTrain Epoch: 0 [3776/4803 (78%)] Loss: 81.0894\n",
      "11890\tTrain Epoch: 0 [3840/4803 (79%)] Loss: 23.3177\n",
      "11890\tTrain Epoch: 0 [3904/4803 (80%)] Loss: 74.2948\n",
      "11890\tTrain Epoch: 0 [3968/4803 (82%)] Loss: 82.1658\n",
      "11890\tTrain Epoch: 0 [4032/4803 (83%)] Loss: 12.6741\n",
      "11890\tTrain Epoch: 0 [4096/4803 (84%)] Loss: 38.9492\n",
      "11890\tTrain Epoch: 0 [4160/4803 (86%)] Loss: 1162.1802\n",
      "11890\tTrain Epoch: 0 [4224/4803 (87%)] Loss: 39.9159\n",
      "11890\tTrain Epoch: 0 [4288/4803 (88%)] Loss: 13.7893\n",
      "11890\tTrain Epoch: 0 [4352/4803 (89%)] Loss: 20.3650\n",
      "11890\tTrain Epoch: 0 [4416/4803 (91%)] Loss: 18.3211\n",
      "11890\tTrain Epoch: 0 [4480/4803 (92%)] Loss: 65.3902\n",
      "11890\tTrain Epoch: 0 [4544/4803 (93%)] Loss: 74.3466\n",
      "11890\tTrain Epoch: 0 [4608/4803 (95%)] Loss: 21.3388\n",
      "11890\tTrain Epoch: 0 [4672/4803 (96%)] Loss: 117.5208\n",
      "11890\tTrain Epoch: 0 [4736/4803 (97%)] Loss: 54.9927\n",
      "11890\tTrain Epoch: 0 [4800/4803 (99%)] Loss: 140.6900\n",
      "11890\tTrain Epoch: 0 [228/4803 (100%)] Loss: 228.8218\n",
      "Epoch 1/4\n",
      "11890\tTrain Epoch: 1 [64/4803 (1%)] Loss: 63.8325\n",
      "11890\tTrain Epoch: 1 [128/4803 (3%)] Loss: 358.9230\n",
      "11890\tTrain Epoch: 1 [192/4803 (4%)] Loss: 100.6880\n",
      "11890\tTrain Epoch: 1 [256/4803 (5%)] Loss: 126.5906\n",
      "11890\tTrain Epoch: 1 [320/4803 (7%)] Loss: 138.6900\n",
      "11890\tTrain Epoch: 1 [384/4803 (8%)] Loss: 63.0466\n",
      "11890\tTrain Epoch: 1 [448/4803 (9%)] Loss: 39.5351\n",
      "11890\tTrain Epoch: 1 [512/4803 (11%)] Loss: 37.8405\n",
      "11890\tTrain Epoch: 1 [576/4803 (12%)] Loss: 46.8726\n",
      "11890\tTrain Epoch: 1 [640/4803 (13%)] Loss: 19.3463\n",
      "11890\tTrain Epoch: 1 [704/4803 (14%)] Loss: 41.5406\n",
      "11890\tTrain Epoch: 1 [768/4803 (16%)] Loss: 254.5049\n",
      "11890\tTrain Epoch: 1 [832/4803 (17%)] Loss: 27.6615\n",
      "11890\tTrain Epoch: 1 [896/4803 (18%)] Loss: 27.4420\n",
      "11890\tTrain Epoch: 1 [960/4803 (20%)] Loss: 36.9539\n",
      "11890\tTrain Epoch: 1 [1024/4803 (21%)] Loss: 349.6671\n",
      "11890\tTrain Epoch: 1 [1088/4803 (22%)] Loss: 133.8306\n",
      "11890\tTrain Epoch: 1 [1152/4803 (24%)] Loss: 119.3954\n",
      "11890\tTrain Epoch: 1 [1216/4803 (25%)] Loss: 154.7836\n",
      "11890\tTrain Epoch: 1 [1280/4803 (26%)] Loss: 73.9056\n",
      "11890\tTrain Epoch: 1 [1344/4803 (28%)] Loss: 53.0015\n",
      "11890\tTrain Epoch: 1 [1408/4803 (29%)] Loss: 71.5221\n",
      "11890\tTrain Epoch: 1 [1472/4803 (30%)] Loss: 43.8311\n",
      "11890\tTrain Epoch: 1 [1536/4803 (32%)] Loss: 204.0838\n",
      "11890\tTrain Epoch: 1 [1600/4803 (33%)] Loss: 55.0243\n",
      "11890\tTrain Epoch: 1 [1664/4803 (34%)] Loss: 25.5306\n",
      "11890\tTrain Epoch: 1 [1728/4803 (36%)] Loss: 36.7667\n",
      "11890\tTrain Epoch: 1 [1792/4803 (37%)] Loss: 43.8883\n",
      "11890\tTrain Epoch: 1 [1856/4803 (38%)] Loss: 20.9869\n",
      "11890\tTrain Epoch: 1 [1920/4803 (39%)] Loss: 40.0756\n",
      "11890\tTrain Epoch: 1 [1984/4803 (41%)] Loss: 27.3129\n",
      "11890\tTrain Epoch: 1 [2048/4803 (42%)] Loss: 18.1773\n",
      "11890\tTrain Epoch: 1 [2112/4803 (43%)] Loss: 24.7444\n",
      "11890\tTrain Epoch: 1 [2176/4803 (45%)] Loss: 126.2953\n",
      "11890\tTrain Epoch: 1 [2240/4803 (46%)] Loss: 34.7331\n",
      "11890\tTrain Epoch: 1 [2304/4803 (47%)] Loss: 78.6315\n",
      "11890\tTrain Epoch: 1 [2368/4803 (49%)] Loss: 369.3657\n",
      "11890\tTrain Epoch: 1 [2432/4803 (50%)] Loss: 82.0049\n",
      "11890\tTrain Epoch: 1 [2496/4803 (51%)] Loss: 57.1747\n",
      "11890\tTrain Epoch: 1 [2560/4803 (53%)] Loss: 120.7468\n",
      "11890\tTrain Epoch: 1 [2624/4803 (54%)] Loss: 69.5538\n",
      "11890\tTrain Epoch: 1 [2688/4803 (55%)] Loss: 81.6016\n",
      "11890\tTrain Epoch: 1 [2752/4803 (57%)] Loss: 60.3682\n",
      "11890\tTrain Epoch: 1 [2816/4803 (58%)] Loss: 16.1116\n",
      "11890\tTrain Epoch: 1 [2880/4803 (59%)] Loss: 42.2041\n",
      "11890\tTrain Epoch: 1 [2944/4803 (61%)] Loss: 42.9316\n",
      "11890\tTrain Epoch: 1 [3008/4803 (62%)] Loss: 38.4740\n",
      "11890\tTrain Epoch: 1 [3072/4803 (63%)] Loss: 40.0772\n",
      "11890\tTrain Epoch: 1 [3136/4803 (64%)] Loss: 67.0978\n",
      "11890\tTrain Epoch: 1 [3200/4803 (66%)] Loss: 57.3541\n",
      "11890\tTrain Epoch: 1 [3264/4803 (67%)] Loss: 125.0578\n",
      "11890\tTrain Epoch: 1 [3328/4803 (68%)] Loss: 23.0188\n",
      "11890\tTrain Epoch: 1 [3392/4803 (70%)] Loss: 36.1958\n",
      "11890\tTrain Epoch: 1 [3456/4803 (71%)] Loss: 70.7310\n",
      "11890\tTrain Epoch: 1 [3520/4803 (72%)] Loss: 66.6399\n",
      "11890\tTrain Epoch: 1 [3584/4803 (74%)] Loss: 35.3949\n",
      "11890\tTrain Epoch: 1 [3648/4803 (75%)] Loss: 82.9592\n",
      "11890\tTrain Epoch: 1 [3712/4803 (76%)] Loss: 22.7403\n",
      "11890\tTrain Epoch: 1 [3776/4803 (78%)] Loss: 47.9491\n",
      "11890\tTrain Epoch: 1 [3840/4803 (79%)] Loss: 42.3815\n",
      "11890\tTrain Epoch: 1 [3904/4803 (80%)] Loss: 40.3518\n",
      "11890\tTrain Epoch: 1 [3968/4803 (82%)] Loss: 68.3570\n",
      "11890\tTrain Epoch: 1 [4032/4803 (83%)] Loss: 49.8327\n",
      "11890\tTrain Epoch: 1 [4096/4803 (84%)] Loss: 62.6718\n",
      "11890\tTrain Epoch: 1 [4160/4803 (86%)] Loss: 62.5505\n",
      "11890\tTrain Epoch: 1 [4224/4803 (87%)] Loss: 12.3126\n",
      "11890\tTrain Epoch: 1 [4288/4803 (88%)] Loss: 23.7740\n",
      "11890\tTrain Epoch: 1 [4352/4803 (89%)] Loss: 25.6756\n",
      "11890\tTrain Epoch: 1 [4416/4803 (91%)] Loss: 26.3146\n",
      "11890\tTrain Epoch: 1 [4480/4803 (92%)] Loss: 35.6497\n",
      "11890\tTrain Epoch: 1 [4544/4803 (93%)] Loss: 591.9727\n",
      "11890\tTrain Epoch: 1 [4608/4803 (95%)] Loss: 46.2275\n",
      "11890\tTrain Epoch: 1 [4672/4803 (96%)] Loss: 73.1101\n",
      "11890\tTrain Epoch: 1 [4736/4803 (97%)] Loss: 67.2879\n",
      "11890\tTrain Epoch: 1 [4800/4803 (99%)] Loss: 55.7741\n",
      "11890\tTrain Epoch: 1 [228/4803 (100%)] Loss: 225.7138\n",
      "Epoch 2/4\n",
      "11890\tTrain Epoch: 2 [64/4803 (1%)] Loss: 26.2369\n",
      "11890\tTrain Epoch: 2 [128/4803 (3%)] Loss: 152.0013\n",
      "11890\tTrain Epoch: 2 [192/4803 (4%)] Loss: 55.8181\n",
      "11890\tTrain Epoch: 2 [256/4803 (5%)] Loss: 72.5295\n",
      "11890\tTrain Epoch: 2 [320/4803 (7%)] Loss: 88.7828\n",
      "11890\tTrain Epoch: 2 [384/4803 (8%)] Loss: 43.1161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11890\tTrain Epoch: 2 [448/4803 (9%)] Loss: 70.6455\n",
      "11890\tTrain Epoch: 2 [512/4803 (11%)] Loss: 92.7028\n",
      "11890\tTrain Epoch: 2 [576/4803 (12%)] Loss: 33.2742\n",
      "11890\tTrain Epoch: 2 [640/4803 (13%)] Loss: 14.4710\n",
      "11890\tTrain Epoch: 2 [704/4803 (14%)] Loss: 37.7060\n",
      "11890\tTrain Epoch: 2 [768/4803 (16%)] Loss: 60.9734\n",
      "11890\tTrain Epoch: 2 [832/4803 (17%)] Loss: 50.3358\n",
      "11890\tTrain Epoch: 2 [896/4803 (18%)] Loss: 63.3250\n",
      "11890\tTrain Epoch: 2 [960/4803 (20%)] Loss: 29.6606\n",
      "11890\tTrain Epoch: 2 [1024/4803 (21%)] Loss: 34.0828\n",
      "11890\tTrain Epoch: 2 [1088/4803 (22%)] Loss: 80.1624\n",
      "11890\tTrain Epoch: 2 [1152/4803 (24%)] Loss: 29.1075\n",
      "11890\tTrain Epoch: 2 [1216/4803 (25%)] Loss: 61.3146\n",
      "11890\tTrain Epoch: 2 [1280/4803 (26%)] Loss: 253.4844\n",
      "11890\tTrain Epoch: 2 [1344/4803 (28%)] Loss: 20.7052\n",
      "11890\tTrain Epoch: 2 [1408/4803 (29%)] Loss: 26.8652\n",
      "11890\tTrain Epoch: 2 [1472/4803 (30%)] Loss: 27.8714\n",
      "11890\tTrain Epoch: 2 [1536/4803 (32%)] Loss: 491.3324\n",
      "11890\tTrain Epoch: 2 [1600/4803 (33%)] Loss: 15.3487\n",
      "11890\tTrain Epoch: 2 [1664/4803 (34%)] Loss: 141.2670\n",
      "11890\tTrain Epoch: 2 [1728/4803 (36%)] Loss: 33.2698\n",
      "11890\tTrain Epoch: 2 [1792/4803 (37%)] Loss: 49.1828\n",
      "11890\tTrain Epoch: 2 [1856/4803 (38%)] Loss: 27.8868\n",
      "11890\tTrain Epoch: 2 [1920/4803 (39%)] Loss: 37.0408\n",
      "11890\tTrain Epoch: 2 [1984/4803 (41%)] Loss: 53.2163\n",
      "11890\tTrain Epoch: 2 [2048/4803 (42%)] Loss: 132.5302\n",
      "11890\tTrain Epoch: 2 [2112/4803 (43%)] Loss: 17.1125\n",
      "11890\tTrain Epoch: 2 [2176/4803 (45%)] Loss: 17.1951\n",
      "11890\tTrain Epoch: 2 [2240/4803 (46%)] Loss: 19.9029\n",
      "11890\tTrain Epoch: 2 [2304/4803 (47%)] Loss: 63.9221\n",
      "11890\tTrain Epoch: 2 [2368/4803 (49%)] Loss: 24.0576\n",
      "11890\tTrain Epoch: 2 [2432/4803 (50%)] Loss: 17.6992\n",
      "11890\tTrain Epoch: 2 [2496/4803 (51%)] Loss: 151.1272\n",
      "11890\tTrain Epoch: 2 [2560/4803 (53%)] Loss: 44.4359\n",
      "11890\tTrain Epoch: 2 [2624/4803 (54%)] Loss: 33.8469\n",
      "11890\tTrain Epoch: 2 [2688/4803 (55%)] Loss: 106.9416\n",
      "11890\tTrain Epoch: 2 [2752/4803 (57%)] Loss: 1257.7773\n",
      "11890\tTrain Epoch: 2 [2816/4803 (58%)] Loss: 34.8800\n",
      "11890\tTrain Epoch: 2 [2880/4803 (59%)] Loss: 87.2060\n",
      "11890\tTrain Epoch: 2 [2944/4803 (61%)] Loss: 91.1503\n",
      "11890\tTrain Epoch: 2 [3008/4803 (62%)] Loss: 101.0586\n",
      "11890\tTrain Epoch: 2 [3072/4803 (63%)] Loss: 95.6380\n",
      "11890\tTrain Epoch: 2 [3136/4803 (64%)] Loss: 29.0028\n",
      "11890\tTrain Epoch: 2 [3200/4803 (66%)] Loss: 149.1119\n",
      "11890\tTrain Epoch: 2 [3264/4803 (67%)] Loss: 61.6817\n",
      "11890\tTrain Epoch: 2 [3328/4803 (68%)] Loss: 51.5756\n",
      "11890\tTrain Epoch: 2 [3392/4803 (70%)] Loss: 38.7537\n",
      "11890\tTrain Epoch: 2 [3456/4803 (71%)] Loss: 82.8650\n",
      "11890\tTrain Epoch: 2 [3520/4803 (72%)] Loss: 33.1825\n",
      "11890\tTrain Epoch: 2 [3584/4803 (74%)] Loss: 169.6710\n",
      "11890\tTrain Epoch: 2 [3648/4803 (75%)] Loss: 25.5683\n",
      "11890\tTrain Epoch: 2 [3712/4803 (76%)] Loss: 24.6094\n",
      "11890\tTrain Epoch: 2 [3776/4803 (78%)] Loss: 14.7192\n",
      "11890\tTrain Epoch: 2 [3840/4803 (79%)] Loss: 36.5813\n",
      "11890\tTrain Epoch: 2 [3904/4803 (80%)] Loss: 64.5785\n",
      "11890\tTrain Epoch: 2 [3968/4803 (82%)] Loss: 105.1897\n",
      "11890\tTrain Epoch: 2 [4032/4803 (83%)] Loss: 120.5284\n",
      "11890\tTrain Epoch: 2 [4096/4803 (84%)] Loss: 119.4468\n",
      "11890\tTrain Epoch: 2 [4160/4803 (86%)] Loss: 70.9604\n",
      "11890\tTrain Epoch: 2 [4224/4803 (87%)] Loss: 29.6173\n",
      "11890\tTrain Epoch: 2 [4288/4803 (88%)] Loss: 19.9645\n",
      "11890\tTrain Epoch: 2 [4352/4803 (89%)] Loss: 91.4811\n",
      "11890\tTrain Epoch: 2 [4416/4803 (91%)] Loss: 28.0151\n",
      "11890\tTrain Epoch: 2 [4480/4803 (92%)] Loss: 19.0765\n",
      "11890\tTrain Epoch: 2 [4544/4803 (93%)] Loss: 69.6675\n",
      "11890\tTrain Epoch: 2 [4608/4803 (95%)] Loss: 66.5676\n",
      "11890\tTrain Epoch: 2 [4672/4803 (96%)] Loss: 48.8018\n",
      "11890\tTrain Epoch: 2 [4736/4803 (97%)] Loss: 13.5280\n",
      "11890\tTrain Epoch: 2 [4800/4803 (99%)] Loss: 67.9403\n",
      "11890\tTrain Epoch: 2 [228/4803 (100%)] Loss: 222.9977\n",
      "Epoch 3/4\n",
      "11890\tTrain Epoch: 3 [64/4803 (1%)] Loss: 18.9501\n",
      "11890\tTrain Epoch: 3 [128/4803 (3%)] Loss: 20.7695\n",
      "11890\tTrain Epoch: 3 [192/4803 (4%)] Loss: 73.4331\n",
      "11890\tTrain Epoch: 3 [256/4803 (5%)] Loss: 50.0495\n",
      "11890\tTrain Epoch: 3 [320/4803 (7%)] Loss: 30.9180\n",
      "11890\tTrain Epoch: 3 [384/4803 (8%)] Loss: 27.2443\n",
      "11890\tTrain Epoch: 3 [448/4803 (9%)] Loss: 147.0430\n",
      "11890\tTrain Epoch: 3 [512/4803 (11%)] Loss: 62.0262\n",
      "11890\tTrain Epoch: 3 [576/4803 (12%)] Loss: 54.4634\n",
      "11890\tTrain Epoch: 3 [640/4803 (13%)] Loss: 64.7629\n",
      "11890\tTrain Epoch: 3 [704/4803 (14%)] Loss: 20.4965\n",
      "11890\tTrain Epoch: 3 [768/4803 (16%)] Loss: 25.7348\n",
      "11890\tTrain Epoch: 3 [832/4803 (17%)] Loss: 33.5733\n",
      "11890\tTrain Epoch: 3 [896/4803 (18%)] Loss: 17.6624\n",
      "11890\tTrain Epoch: 3 [960/4803 (20%)] Loss: 31.0982\n",
      "11890\tTrain Epoch: 3 [1024/4803 (21%)] Loss: 47.0805\n",
      "11890\tTrain Epoch: 3 [1088/4803 (22%)] Loss: 21.9017\n",
      "11890\tTrain Epoch: 3 [1152/4803 (24%)] Loss: 26.9565\n",
      "11890\tTrain Epoch: 3 [1216/4803 (25%)] Loss: 38.1055\n",
      "11890\tTrain Epoch: 3 [1280/4803 (26%)] Loss: 103.3401\n",
      "11890\tTrain Epoch: 3 [1344/4803 (28%)] Loss: 520.0629\n",
      "11890\tTrain Epoch: 3 [1408/4803 (29%)] Loss: 131.6136\n",
      "11890\tTrain Epoch: 3 [1472/4803 (30%)] Loss: 21.7338\n",
      "11890\tTrain Epoch: 3 [1536/4803 (32%)] Loss: 50.4145\n",
      "11890\tTrain Epoch: 3 [1600/4803 (33%)] Loss: 53.6055\n",
      "11890\tTrain Epoch: 3 [1664/4803 (34%)] Loss: 102.5261\n",
      "11890\tTrain Epoch: 3 [1728/4803 (36%)] Loss: 128.6564\n",
      "11890\tTrain Epoch: 3 [1792/4803 (37%)] Loss: 152.0548\n",
      "11890\tTrain Epoch: 3 [1856/4803 (38%)] Loss: 86.4059\n",
      "11890\tTrain Epoch: 3 [1920/4803 (39%)] Loss: 121.1056\n",
      "11890\tTrain Epoch: 3 [1984/4803 (41%)] Loss: 22.9457\n",
      "11890\tTrain Epoch: 3 [2048/4803 (42%)] Loss: 15.3015\n",
      "11890\tTrain Epoch: 3 [2112/4803 (43%)] Loss: 44.8285\n",
      "11890\tTrain Epoch: 3 [2176/4803 (45%)] Loss: 147.1000\n",
      "11890\tTrain Epoch: 3 [2240/4803 (46%)] Loss: 27.8097\n",
      "11890\tTrain Epoch: 3 [2304/4803 (47%)] Loss: 76.0399\n",
      "11890\tTrain Epoch: 3 [2368/4803 (49%)] Loss: 24.1086\n",
      "11890\tTrain Epoch: 3 [2432/4803 (50%)] Loss: 642.3293\n",
      "11890\tTrain Epoch: 3 [2496/4803 (51%)] Loss: 153.0636\n",
      "11890\tTrain Epoch: 3 [2560/4803 (53%)] Loss: 106.7707\n",
      "11890\tTrain Epoch: 3 [2624/4803 (54%)] Loss: 76.8293\n",
      "11890\tTrain Epoch: 3 [2688/4803 (55%)] Loss: 153.2609\n",
      "11890\tTrain Epoch: 3 [2752/4803 (57%)] Loss: 28.5862\n",
      "11890\tTrain Epoch: 3 [2816/4803 (58%)] Loss: 98.7466\n",
      "11890\tTrain Epoch: 3 [2880/4803 (59%)] Loss: 42.6325\n",
      "11890\tTrain Epoch: 3 [2944/4803 (61%)] Loss: 202.5349\n",
      "11890\tTrain Epoch: 3 [3008/4803 (62%)] Loss: 52.4665\n",
      "11890\tTrain Epoch: 3 [3072/4803 (63%)] Loss: 100.2814\n",
      "11890\tTrain Epoch: 3 [3136/4803 (64%)] Loss: 82.6268\n",
      "11890\tTrain Epoch: 3 [3200/4803 (66%)] Loss: 39.4680\n",
      "11890\tTrain Epoch: 3 [3264/4803 (67%)] Loss: 60.4754\n",
      "11890\tTrain Epoch: 3 [3328/4803 (68%)] Loss: 104.2606\n",
      "11890\tTrain Epoch: 3 [3392/4803 (70%)] Loss: 88.2642\n",
      "11890\tTrain Epoch: 3 [3456/4803 (71%)] Loss: 81.8255\n",
      "11890\tTrain Epoch: 3 [3520/4803 (72%)] Loss: 26.1695\n",
      "11890\tTrain Epoch: 3 [3584/4803 (74%)] Loss: 15.5411\n",
      "11890\tTrain Epoch: 3 [3648/4803 (75%)] Loss: 89.5819\n",
      "11890\tTrain Epoch: 3 [3712/4803 (76%)] Loss: 120.2219\n",
      "11890\tTrain Epoch: 3 [3776/4803 (78%)] Loss: 106.5391\n",
      "11890\tTrain Epoch: 3 [3840/4803 (79%)] Loss: 20.6827\n",
      "11890\tTrain Epoch: 3 [3904/4803 (80%)] Loss: 21.4814\n",
      "11890\tTrain Epoch: 3 [3968/4803 (82%)] Loss: 60.2135\n",
      "11890\tTrain Epoch: 3 [4032/4803 (83%)] Loss: 61.1370\n",
      "11890\tTrain Epoch: 3 [4096/4803 (84%)] Loss: 142.9400\n",
      "11890\tTrain Epoch: 3 [4160/4803 (86%)] Loss: 89.8036\n",
      "11890\tTrain Epoch: 3 [4224/4803 (87%)] Loss: 70.5880\n",
      "11890\tTrain Epoch: 3 [4288/4803 (88%)] Loss: 67.6750\n",
      "11890\tTrain Epoch: 3 [4352/4803 (89%)] Loss: 53.9049\n",
      "11890\tTrain Epoch: 3 [4416/4803 (91%)] Loss: 88.5224\n",
      "11890\tTrain Epoch: 3 [4480/4803 (92%)] Loss: 64.2844\n",
      "11890\tTrain Epoch: 3 [4544/4803 (93%)] Loss: 66.2076\n",
      "11890\tTrain Epoch: 3 [4608/4803 (95%)] Loss: 27.8950\n",
      "11890\tTrain Epoch: 3 [4672/4803 (96%)] Loss: 33.3620\n",
      "11890\tTrain Epoch: 3 [4736/4803 (97%)] Loss: 30.9555\n",
      "11890\tTrain Epoch: 3 [4800/4803 (99%)] Loss: 89.5759\n",
      "11890\tTrain Epoch: 3 [228/4803 (100%)] Loss: 38.3816\n",
      "Epoch 4/4\n",
      "11890\tTrain Epoch: 4 [64/4803 (1%)] Loss: 83.4158\n",
      "11890\tTrain Epoch: 4 [128/4803 (3%)] Loss: 33.1118\n",
      "11890\tTrain Epoch: 4 [192/4803 (4%)] Loss: 64.1520\n",
      "11890\tTrain Epoch: 4 [256/4803 (5%)] Loss: 21.3870\n",
      "11890\tTrain Epoch: 4 [320/4803 (7%)] Loss: 91.0257\n",
      "11890\tTrain Epoch: 4 [384/4803 (8%)] Loss: 49.1350\n",
      "11890\tTrain Epoch: 4 [448/4803 (9%)] Loss: 38.3293\n",
      "11890\tTrain Epoch: 4 [512/4803 (11%)] Loss: 56.1710\n",
      "11890\tTrain Epoch: 4 [576/4803 (12%)] Loss: 52.7099\n",
      "11890\tTrain Epoch: 4 [640/4803 (13%)] Loss: 44.5211\n",
      "11890\tTrain Epoch: 4 [704/4803 (14%)] Loss: 118.1032\n",
      "11890\tTrain Epoch: 4 [768/4803 (16%)] Loss: 12.4755\n",
      "11890\tTrain Epoch: 4 [832/4803 (17%)] Loss: 21.6748\n",
      "11890\tTrain Epoch: 4 [896/4803 (18%)] Loss: 21.3719\n",
      "11890\tTrain Epoch: 4 [960/4803 (20%)] Loss: 702.9022\n",
      "11890\tTrain Epoch: 4 [1024/4803 (21%)] Loss: 32.9323\n",
      "11890\tTrain Epoch: 4 [1088/4803 (22%)] Loss: 30.3156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11890\tTrain Epoch: 4 [1152/4803 (24%)] Loss: 30.7482\n",
      "11890\tTrain Epoch: 4 [1216/4803 (25%)] Loss: 66.1544\n",
      "11890\tTrain Epoch: 4 [1280/4803 (26%)] Loss: 76.7691\n",
      "11890\tTrain Epoch: 4 [1344/4803 (28%)] Loss: 30.4178\n",
      "11890\tTrain Epoch: 4 [1408/4803 (29%)] Loss: 52.8545\n",
      "11890\tTrain Epoch: 4 [1472/4803 (30%)] Loss: 35.4744\n",
      "11890\tTrain Epoch: 4 [1536/4803 (32%)] Loss: 37.5171\n",
      "11890\tTrain Epoch: 4 [1600/4803 (33%)] Loss: 27.8156\n",
      "11890\tTrain Epoch: 4 [1664/4803 (34%)] Loss: 116.3395\n",
      "11890\tTrain Epoch: 4 [1728/4803 (36%)] Loss: 20.6888\n",
      "11890\tTrain Epoch: 4 [1792/4803 (37%)] Loss: 60.8789\n",
      "11890\tTrain Epoch: 4 [1856/4803 (38%)] Loss: 43.7304\n",
      "11890\tTrain Epoch: 4 [1920/4803 (39%)] Loss: 23.7918\n",
      "11890\tTrain Epoch: 4 [1984/4803 (41%)] Loss: 21.0457\n",
      "11890\tTrain Epoch: 4 [2048/4803 (42%)] Loss: 22.7369\n",
      "11890\tTrain Epoch: 4 [2112/4803 (43%)] Loss: 393.9542\n",
      "11890\tTrain Epoch: 4 [2176/4803 (45%)] Loss: 51.3721\n",
      "11890\tTrain Epoch: 4 [2240/4803 (46%)] Loss: 91.8206\n",
      "11890\tTrain Epoch: 4 [2304/4803 (47%)] Loss: 43.8325\n",
      "11890\tTrain Epoch: 4 [2368/4803 (49%)] Loss: 75.9223\n",
      "11890\tTrain Epoch: 4 [2432/4803 (50%)] Loss: 169.8615\n",
      "11890\tTrain Epoch: 4 [2496/4803 (51%)] Loss: 49.5357\n",
      "11890\tTrain Epoch: 4 [2560/4803 (53%)] Loss: 99.7527\n",
      "11890\tTrain Epoch: 4 [2624/4803 (54%)] Loss: 44.4944\n",
      "11890\tTrain Epoch: 4 [2688/4803 (55%)] Loss: 31.6686\n",
      "11890\tTrain Epoch: 4 [2752/4803 (57%)] Loss: 91.0574\n",
      "11890\tTrain Epoch: 4 [2816/4803 (58%)] Loss: 19.1584\n",
      "11890\tTrain Epoch: 4 [2880/4803 (59%)] Loss: 42.7292\n",
      "11890\tTrain Epoch: 4 [2944/4803 (61%)] Loss: 52.9331\n",
      "11890\tTrain Epoch: 4 [3008/4803 (62%)] Loss: 69.7517\n",
      "11890\tTrain Epoch: 4 [3072/4803 (63%)] Loss: 21.1971\n",
      "11890\tTrain Epoch: 4 [3136/4803 (64%)] Loss: 156.2379\n",
      "11890\tTrain Epoch: 4 [3200/4803 (66%)] Loss: 38.8763\n",
      "11890\tTrain Epoch: 4 [3264/4803 (67%)] Loss: 65.6491\n",
      "11890\tTrain Epoch: 4 [3328/4803 (68%)] Loss: 50.3170\n",
      "11890\tTrain Epoch: 4 [3392/4803 (70%)] Loss: 50.2658\n",
      "11890\tTrain Epoch: 4 [3456/4803 (71%)] Loss: 137.0046\n",
      "11890\tTrain Epoch: 4 [3520/4803 (72%)] Loss: 32.6891\n",
      "11890\tTrain Epoch: 4 [3584/4803 (74%)] Loss: 19.7140\n",
      "11890\tTrain Epoch: 4 [3648/4803 (75%)] Loss: 66.0684\n",
      "11890\tTrain Epoch: 4 [3712/4803 (76%)] Loss: 40.1050\n",
      "11890\tTrain Epoch: 4 [3776/4803 (78%)] Loss: 134.6406\n",
      "11890\tTrain Epoch: 4 [3840/4803 (79%)] Loss: 33.5518\n",
      "11890\tTrain Epoch: 4 [3904/4803 (80%)] Loss: 41.9074\n",
      "11890\tTrain Epoch: 4 [3968/4803 (82%)] Loss: 38.1617\n",
      "11890\tTrain Epoch: 4 [4032/4803 (83%)] Loss: 38.4658\n",
      "11890\tTrain Epoch: 4 [4096/4803 (84%)] Loss: 22.0784\n",
      "11890\tTrain Epoch: 4 [4160/4803 (86%)] Loss: 15.9646\n",
      "11890\tTrain Epoch: 4 [4224/4803 (87%)] Loss: 69.1332\n",
      "11890\tTrain Epoch: 4 [4288/4803 (88%)] Loss: 34.0919\n",
      "11890\tTrain Epoch: 4 [4352/4803 (89%)] Loss: 38.8187\n",
      "11890\tTrain Epoch: 4 [4416/4803 (91%)] Loss: 29.8529\n",
      "11890\tTrain Epoch: 4 [4480/4803 (92%)] Loss: 16.3141\n",
      "11890\tTrain Epoch: 4 [4544/4803 (93%)] Loss: 99.2553\n",
      "11890\tTrain Epoch: 4 [4608/4803 (95%)] Loss: 13.4600\n",
      "11890\tTrain Epoch: 4 [4672/4803 (96%)] Loss: 27.5084\n",
      "11890\tTrain Epoch: 4 [4736/4803 (97%)] Loss: 38.4233\n",
      "11890\tTrain Epoch: 4 [4800/4803 (99%)] Loss: 37.6537\n",
      "11890\tTrain Epoch: 4 [228/4803 (100%)] Loss: 264.8557\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "since = time.time()\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(no_of_epochs):\n",
    "    running_loss = 0.0\n",
    "    i=0\n",
    "    print('Epoch {}/{}'.format(epoch, no_of_epochs - 1))\n",
    "    model.train()\n",
    "    pid = os.getpid()\n",
    "    for y, cont_x, cat_x in dataloader:\n",
    "        i += 1\n",
    "        cat_x = cat_x.to(device)\n",
    "        cont_x = cont_x.to(device)\n",
    "        y  = y.to(device)\n",
    "\n",
    "        # Forward Pass\n",
    "        preds = model(cont_x, cat_x)\n",
    "        loss = criterion(preds, y)\n",
    "        \n",
    "        # Backward Pass and Optimization\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        if batch_idx % 1000:    # print every n mini-batches         \n",
    "            print('{}\\tTrain Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.4f}'.format(\n",
    "                pid, epoch, i * len(cat_x), len(dataloader.dataset),\n",
    "                100. * i / len(dataloader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
